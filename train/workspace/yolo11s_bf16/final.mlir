#loc = loc(unknown)
#loc1 = loc("images")
module @yolo11s attributes {module.FLOPs = 3787969080 : i64, module.addr_mode = "basic", module.asymmetric = false, module.chip = "cv181x", module.cores = 1 : i64, module.devices = 1 : i64, module.high_precision = false, module.inputs = ["images"], module.mode = "BF16", module.outputs = ["/model.23/dfl/conv/Conv_output_0_Conv_f32", "/model.23/Sigmoid_output_0_Sigmoid_f32"], module.platform = "ONNX", module.q_group_size = 0 : i64, module.state = "TPU_ADDRESSED", module.top_run_mode = "STATIC", module.weight_file = "yolo11s_tpu_addressed_cv181x_bf16_weight.npz"} {
  module @yolo11s attributes {module.coeff_addr = 1099511627776 : i64, module.coeff_size = 18870352 : i64, module.device_id = 0 : i64, module.neuron_size = 2150400 : i64, module.private_size = 0 : i64, module.step = 0 : i64} {
    func.func @main(%arg0: tensor<1x3x224x320xf32> loc(unknown)) -> (tensor<1x1x4x1470xf32, 5497558138880 : i64>, tensor<1x4x1470xf32, 4398046511104 : i64>) {
      %0 = "top.Input"(%arg0) {channel_format = "nchw", do_preprocess = true, keep_aspect_ratio = true, keep_ratio_mode = "letterbox", mean = [0.000000e+00, 0.000000e+00, 0.000000e+00], pad_type = "center", pad_value = 0 : i64, pixel_format = "rgb", resize_dims = [224, 320], scale = [0.0039215688593685627, 0.0039215688593685627, 0.0039215688593685627]} : (tensor<1x3x224x320xf32>) -> tensor<1x3x224x320xf32, 3298534883328 : i64> loc(#loc1)
      %1:2 = call @subfunc_0(%0) : (tensor<1x3x224x320xf32, 3298534883328 : i64>) -> (tensor<1x1x4x1470xf32, 5497558138880 : i64>, tensor<1x4x1470xf32, 4398046511104 : i64>) loc(#loc)
      return %1#0, %1#1 : tensor<1x1x4x1470xf32, 5497558138880 : i64>, tensor<1x4x1470xf32, 4398046511104 : i64> loc(#loc)
    } loc(#loc)
    func.func @subfunc_0(%arg0: tensor<1x3x224x320xf32, 3298534883328 : i64> loc("images")) -> (tensor<1x1x4x1470xf32, 5497558138880 : i64>, tensor<1x4x1470xf32, 4398046511104 : i64>) attributes {id = 0 : i64, mode = #tpu<run_mode TPU_STATIC>, next_index = array<i32: -1>} {
      %0 = "top.None"() : () -> none loc(#loc)
      %1 = "tpu.Cast"(%arg0) {round_mode = #tpu<round_mode HalfAwayFromZero>, with_scale = true} : (tensor<1x3x224x320xf32, 3298534883328 : i64>) -> tensor<1x3x224x320xbf16, 0 : i64> loc(#loc2)
      %2 = "top.Weight"() : () -> tensor<1x32x9x3xbf16, 1099520998480 : i64> loc(#loc3)
      %3 = "top.Weight"() : () -> tensor<2x32x1x1xui16, 1099522697232 : i64> loc(#loc4)
      %4 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc5)
      %5 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc6)
      %6 = "tpu.Group"(%1) ({
        %535 = "tpu.Load"(%1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 5760, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [3], d_idx = [0], d_slice = [1], h_idx = [0, 7, 15, 23, 31, 39, 47, 55, 63, 71, 79, 87, 95, 103, 111, 119, 127, 135, 143, 151, 159, 167, 175, 183, 191, 199, 207, 215], h_slice = [8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], w_idx = [0], w_slice = [320], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x3x224x320xbf16, 0 : i64>) -> tensor<1x3x224x320xbf16> loc(#loc8)
        %536 = "tpu.Load"(%2) {do_bcast = false, ginfo = #tpu.lg<out_addr = 6784, out_size = 216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [3], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x9x3xbf16, 1099520998480 : i64>) -> tensor<1x32x9x3xbf16> loc(#loc9)
        %537 = "tpu.Load"(%3) {do_bcast = false, ginfo = #tpu.lg<out_addr = 7008, out_size = 16, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x32x1x1xui16, 1099522697232 : i64>) -> tensor<2x32x1x1xui16> loc(#loc10)
        %538 = "tpu.Load"(%4) {do_bcast = true, ginfo = #tpu.lg<out_addr = 5760, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc11)
        %539 = "tpu.Load"(%5) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6272, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc12)
        %540 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108], h_slice = [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [160], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x3x224x320xbf16>, tensor<1x32x9x3xbf16>, tensor<2x32x1x1xui16>) -> tensor<1x32x112x160xbf16> loc(#loc13)
        %541 = "tpu.LutBF16"(%540, %538, %539) {ginfo = #tpu.lg<out_addr = 16384, out_size = 5120, buffer_addr = 21504, buffer_size = 10240, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108], h_slice = [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [160], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x112x160xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x32x112x160xbf16> loc(#loc7)
        %542 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108], h_slice = [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [160], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x32x112x160xbf16>, none) -> tensor<1x32x112x160xbf16, 573440 : i64> loc(#loc7)
        "tpu.Yield"(%542) : (tensor<1x32x112x160xbf16, 573440 : i64>) -> () loc(#loc7)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 28 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [-2, 2], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x3x224x320xbf16, 0 : i64>) -> tensor<1x32x112x160xbf16, 573440 : i64> loc(#loc7)
      %7 = "top.Weight"() : () -> tensor<1x64x9x32xbf16, 1099521000976 : i64> loc(#loc14)
      %8 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099526697552 : i64> loc(#loc15)
      %9 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc16)
      %10 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc17)
      %11 = "tpu.Group"(%6) ({
        %535 = "tpu.Load"(%6) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 6400, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107], h_slice = [4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], w_idx = [0], w_slice = [160], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x112x160xbf16, 573440 : i64>) -> tensor<1x32x112x160xbf16> loc(#loc19)
        %536 = "tpu.Load"(%7) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [32], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x32xbf16, 1099521000976 : i64>) -> tensor<1x64x9x32xbf16> loc(#loc20)
        %537 = "tpu.Load"(%8) {do_bcast = false, ginfo = #tpu.lg<out_addr = 6912, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099526697552 : i64>) -> tensor<2x64x1x1xui16> loc(#loc21)
        %538 = "tpu.Load"(%9) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc22)
        %539 = "tpu.Load"(%10) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6400, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc23)
        %540 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [80], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x112x160xbf16>, tensor<1x64x9x32xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x56x80xbf16> loc(#loc24)
        %541 = "tpu.LutBF16"(%540, %538, %539) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2560, buffer_addr = 25088, buffer_size = 5120, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [80], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x56x80xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x56x80xbf16> loc(#loc18)
        %542 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [80], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x56x80xbf16>, none) -> tensor<1x64x56x80xbf16, 0 : i64> loc(#loc18)
        "tpu.Yield"(%542) : (tensor<1x64x56x80xbf16, 0 : i64>) -> () loc(#loc18)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 28 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [-2, 0, 1, 2], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [2], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x112x160xbf16, 573440 : i64>) -> tensor<1x64x56x80xbf16, 0 : i64> loc(#loc18)
      %12 = "top.Weight"() : () -> tensor<1x64x1x64xbf16, 1099530308432 : i64> loc(#loc25)
      %13 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099528347984 : i64> loc(#loc26)
      %14 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc27)
      %15 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc28)
      %16 = "tpu.Group"(%11) ({
        %535 = "tpu.Load"(%11) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52], h_slice = [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [80], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x56x80xbf16, 0 : i64>) -> tensor<1x64x56x80xbf16> loc(#loc30)
        %536 = "tpu.Load"(%12) {do_bcast = false, ginfo = #tpu.lg<out_addr = 5120, out_size = 1024, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x64xbf16, 1099530308432 : i64>) -> tensor<1x64x1x64xbf16> loc(#loc31)
        %537 = "tpu.Load"(%13) {do_bcast = false, ginfo = #tpu.lg<out_addr = 7168, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099528347984 : i64>) -> tensor<2x64x1x1xui16> loc(#loc32)
        %538 = "tpu.Load"(%14) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6144, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc33)
        %539 = "tpu.Load"(%15) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6656, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc34)
        %540 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 0, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52], h_slice = [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [80], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x56x80xbf16>, tensor<1x64x1x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x56x80xbf16> loc(#loc35)
        %541 = "tpu.LutBF16"(%540, %538, %539) {ginfo = #tpu.lg<out_addr = 16384, out_size = 5120, buffer_addr = 21504, buffer_size = 10240, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52], h_slice = [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [80], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x56x80xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x56x80xbf16> loc(#loc29)
        %542 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52], h_slice = [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [80], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x56x80xbf16>, none) -> tensor<1x64x56x80xbf16, 1576960 : i64> loc(#loc29)
        "tpu.Yield"(%542) : (tensor<1x64x56x80xbf16, 1576960 : i64>) -> () loc(#loc29)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 14 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [0, 1, 2], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x56x80xbf16, 0 : i64>) -> tensor<1x64x56x80xbf16, 1576960 : i64> loc(#loc29)
      %17 = "tpu.Slice"(%16, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 32, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x64x56x80xbf16, 1576960 : i64>, none, none, none, none) -> tensor<1x32x56x80xbf16, 1576960 : i64> loc(#loc36)
      %18 = "tpu.Slice"(%16, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 64, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 32, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x64x56x80xbf16, 1576960 : i64>, none, none, none, none) -> tensor<1x32x56x80xbf16, 1863680 : i64> loc(#loc37)
      %19 = "top.Weight"() {do_compress = true} : () -> tensor<1x16x9x32xbf16, 1099525860624 : i64> loc(#loc38)
      %20 = "top.Weight"() {do_compress = true} : () -> tensor<2x16x1x1xui16, 1099526215952 : i64> loc(#loc39)
      %21 = "tpu.Conv2D"(%18, %19, %20) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x56x80xbf16, 1863680 : i64>, tensor<1x16x9x32xbf16, 1099525860624 : i64>, tensor<2x16x1x1xui16, 1099526215952 : i64>) -> tensor<1x16x56x80xbf16, 0 : i64> loc(#loc40)
      %22 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc41)
      %23 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc42)
      %24 = "top.Weight"() : () -> tensor<1x32x9x16xbf16, 1099523596688 : i64> loc(#loc43)
      %25 = "top.Weight"() : () -> tensor<2x32x1x1xui16, 1099527919312 : i64> loc(#loc44)
      %26 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc45)
      %27 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc46)
      %28 = "tpu.Group"(%21) ({
        %535 = "tpu.Load"(%21) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 3200, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 7, 15, 23, 31, 39, 47], h_slice = [9, 10, 10, 10, 10, 10, 9], w_idx = [0], w_slice = [80], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x16x56x80xbf16, 0 : i64>) -> tensor<1x16x56x80xbf16> loc(#loc48)
        %536 = "tpu.Load"(%22) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7424, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc49)
        %537 = "tpu.Load"(%23) {do_bcast = true, ginfo = #tpu.lg<out_addr = 14464, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc50)
        %538 = "tpu.Load"(%24) {do_bcast = false, ginfo = #tpu.lg<out_addr = 13312, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [16], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x9x16xbf16, 1099523596688 : i64>) -> tensor<1x32x9x16xbf16> loc(#loc51)
        %539 = "tpu.Load"(%25) {do_bcast = false, ginfo = #tpu.lg<out_addr = 26624, out_size = 16, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x32x1x1xui16, 1099527919312 : i64>) -> tensor<2x32x1x1xui16> loc(#loc52)
        %540 = "tpu.LutBF16"(%535, %536, %537) {ginfo = #tpu.lg<out_addr = 16384, out_size = 3200, buffer_addr = 0, buffer_size = 6400, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 7, 15, 23, 31, 39, 47], h_slice = [9, 10, 10, 10, 10, 10, 9], w_idx = [0], w_slice = [80], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x16x56x80xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x16x56x80xbf16> loc(#loc53)
        %541 = "tpu.Load"(%26) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6400, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc54)
        %542 = "tpu.Load"(%27) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6912, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc55)
        %543 = "tpu.Conv2D"(%540, %538, %539) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 0, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 8, 16, 24, 32, 40, 48], h_slice = [8, 8, 8, 8, 8, 8, 8], w_idx = [0], w_slice = [80], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x56x80xbf16>, tensor<1x32x9x16xbf16>, tensor<2x32x1x1xui16>) -> tensor<1x32x56x80xbf16> loc(#loc56)
        %544 = "tpu.LutBF16"(%543, %541, %542) {ginfo = #tpu.lg<out_addr = 8192, out_size = 5120, buffer_addr = 16384, buffer_size = 10240, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 8, 16, 24, 32, 40, 48], h_slice = [8, 8, 8, 8, 8, 8, 8], w_idx = [0], w_slice = [80], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x56x80xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x32x56x80xbf16> loc(#loc47)
        %545 = "tpu.Store"(%544, %0) {ginfo = #tpu.lg<out_addr = 8192, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 8, 16, 24, 32, 40, 48], h_slice = [8, 8, 8, 8, 8, 8, 8], w_idx = [0], w_slice = [80], id = 10, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x32x56x80xbf16>, none) -> tensor<1x32x56x80xbf16, 1146880 : i64> loc(#loc47)
        "tpu.Yield"(%545) : (tensor<1x32x56x80xbf16, 1146880 : i64>) -> () loc(#loc47)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 10, -2, 8, 6, 7, -3, 9, 0, 1, 2], group_type = 0 : i64, hsecs = 7 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x16x56x80xbf16, 0 : i64>) -> tensor<1x32x56x80xbf16, 1146880 : i64> loc(#loc47)
      %29 = "top.Weight"() : () -> tensor<1x128x1x96xbf16, 1099522656272 : i64> loc(#loc57)
      %30 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099521242640 : i64> loc(#loc58)
      %31 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc59)
      %32 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc60)
      %33 = "tpu.Group"(%18, %28, %17) ({
        %535 = "tpu.Load"(%18) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [80], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x56x80xbf16, 1863680 : i64>) -> tensor<1x32x56x80xbf16> loc(#loc62)
        %536 = "tpu.Load"(%28) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [80], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x56x80xbf16, 1146880 : i64>) -> tensor<1x32x56x80xbf16> loc(#loc63)
        %537 = "tpu.Load"(%17) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [80], id = 2, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x56x80xbf16, 1576960 : i64>) -> tensor<1x32x56x80xbf16> loc(#loc64)
        %538 = "tpu.Add"(%535, %536) {do_relu = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [80], id = 3, stage = 1, slice_idx = 0, group_type = 0>, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x32x56x80xbf16>, tensor<1x32x56x80xbf16>) -> tensor<1x32x56x80xbf16> loc(#loc65)
        %539 = "tpu.Load"(%29) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 3072, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [96], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x96xbf16, 1099522656272 : i64>) -> tensor<1x128x1x96xbf16> loc(#loc66)
        %540 = "tpu.Load"(%30) {do_bcast = false, ginfo = #tpu.lg<out_addr = 21760, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099521242640 : i64>) -> tensor<2x128x1x1xui16> loc(#loc67)
        %541 = "tpu.Concat"(%537, %535, %538) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 4096, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [96], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [80], id = 6, stage = 1, slice_idx = 0, group_type = 0>, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x32x56x80xbf16>, tensor<1x32x56x80xbf16>, tensor<1x32x56x80xbf16>) -> tensor<1x96x56x80xbf16> loc(#loc68)
        %542 = "tpu.Load"(%31) {do_bcast = true, ginfo = #tpu.lg<out_addr = 13568, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc69)
        %543 = "tpu.Load"(%32) {do_bcast = true, ginfo = #tpu.lg<out_addr = 14080, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc70)
        %544 = "tpu.Conv2D"(%541, %539, %540) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [80], id = 9, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x96x56x80xbf16>, tensor<1x128x1x96xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x56x80xbf16> loc(#loc71)
        %545 = "tpu.LutBF16"(%544, %542, %543) {ginfo = #tpu.lg<out_addr = 3072, out_size = 5120, buffer_addr = 21824, buffer_size = 10240, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [80], id = 10, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x56x80xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x56x80xbf16> loc(#loc61)
        %546 = "tpu.Store"(%545, %0) {ginfo = #tpu.lg<out_addr = 3072, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [80], id = 11, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x56x80xbf16>, none) -> tensor<1x128x56x80xbf16, 0 : i64> loc(#loc61)
        "tpu.Yield"(%546) : (tensor<1x128x56x80xbf16, 0 : i64>) -> () loc(#loc61)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 3, 2, 11, -2, 6, 4, 5, -3, 9, 7, 8, -4, 10, 0, 1], group_type = 0 : i64, hsecs = 28 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x56x80xbf16, 1863680 : i64>, tensor<1x32x56x80xbf16, 1146880 : i64>, tensor<1x32x56x80xbf16, 1576960 : i64>) -> tensor<1x128x56x80xbf16, 0 : i64> loc(#loc61)
      %34 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099523264912 : i64> loc(#loc72)
      %35 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099523812112 : i64> loc(#loc73)
      %36 = "tpu.Conv2D"(%33, %34, %35) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x56x80xbf16, 0 : i64>, tensor<1x128x9x128xbf16, 1099523264912 : i64>, tensor<2x128x1x1xui16, 1099523812112 : i64>) -> tensor<1x128x28x40xbf16, 1146880 : i64> loc(#loc74)
      %37 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc75)
      %38 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc76)
      %39 = "tpu.LutBF16"(%36, %37, %38) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x28x40xbf16, 1146880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x28x40xbf16, 0 : i64> loc(#loc77)
      %40 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x1x128xbf16, 1099517227856 : i64> loc(#loc78)
      %41 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099525333776 : i64> loc(#loc79)
      %42 = "tpu.Conv2D"(%39, %40, %41) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x28x40xbf16, 0 : i64>, tensor<1x128x1x128xbf16, 1099517227856 : i64>, tensor<2x128x1x1xui16, 1099525333776 : i64>) -> tensor<1x128x28x40xbf16, 286720 : i64> loc(#loc80)
      %43 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc81)
      %44 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc82)
      %45 = "tpu.LutBF16"(%42, %43, %44) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x28x40xbf16, 286720 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x28x40xbf16, 0 : i64> loc(#loc83)
      %46 = "tpu.Slice"(%45, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 64, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x128x28x40xbf16, 0 : i64>, none, none, none, none) -> tensor<1x64x28x40xbf16, 0 : i64> loc(#loc84)
      %47 = "tpu.Slice"(%45, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 128, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 64, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x128x28x40xbf16, 0 : i64>, none, none, none, none) -> tensor<1x64x28x40xbf16, 143360 : i64> loc(#loc85)
      %48 = "top.Weight"() {do_compress = true} : () -> tensor<1x32x9x64xbf16, 1099523559824 : i64> loc(#loc86)
      %49 = "top.Weight"() {do_compress = true} : () -> tensor<2x32x1x1xui16, 1099523605904 : i64> loc(#loc87)
      %50 = "tpu.Conv2D"(%47, %48, %49) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16, 143360 : i64>, tensor<1x32x9x64xbf16, 1099523559824 : i64>, tensor<2x32x1x1xui16, 1099523605904 : i64>) -> tensor<1x32x28x40xbf16, 286720 : i64> loc(#loc88)
      %51 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc89)
      %52 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc90)
      %53 = "tpu.LutBF16"(%50, %51, %52) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x28x40xbf16, 286720 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x32x28x40xbf16, 1720320 : i64> loc(#loc91)
      %54 = "top.Weight"() : () -> tensor<1x64x9x32xbf16, 1099523623440 : i64> loc(#loc92)
      %55 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099525330448 : i64> loc(#loc93)
      %56 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc94)
      %57 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc95)
      %58 = "top.Weight"() : () -> tensor<1x256x1x192xbf16, 1099522555152 : i64> loc(#loc96)
      %59 = "top.Weight"() : () -> tensor<2x256x1x1xui16, 1099522654736 : i64> loc(#loc97)
      %60 = "tpu.Group"(%53, %47, %46) ({
        %535 = "tpu.Load"(%53) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16896, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25], h_slice = [3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 1720320 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc99)
        %536 = "tpu.Load"(%54) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [32], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x32xbf16, 1099523623440 : i64>) -> tensor<1x64x9x32xbf16> loc(#loc100)
        %537 = "tpu.Load"(%55) {do_bcast = false, ginfo = #tpu.lg<out_addr = 27264, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099525330448 : i64>) -> tensor<2x64x1x1xui16> loc(#loc101)
        %538 = "tpu.Load"(%56) {do_bcast = true, ginfo = #tpu.lg<out_addr = 18688, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc102)
        %539 = "tpu.Load"(%57) {do_bcast = true, ginfo = #tpu.lg<out_addr = 18176, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc103)
        %540 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x28x40xbf16>, tensor<1x64x9x32xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc104)
        %541 = "tpu.Load"(%47) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16896, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 143360 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc105)
        %542 = "tpu.LutBF16"(%540, %538, %539) {ginfo = #tpu.lg<out_addr = 20480, out_size = 1280, buffer_addr = 24576, buffer_size = 2560, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc106)
        %543 = "tpu.Load"(%46) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 0 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc107)
        %544 = "tpu.Add"(%541, %542) {do_relu = false, ginfo = #tpu.lg<out_addr = 19200, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 9, stage = 1, slice_idx = 0, group_type = 0>, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x64x28x40xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc108)
        %545 = "tpu.Load"(%58) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 12288, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [192], id = 10, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x256x1x192xbf16, 1099522555152 : i64>) -> tensor<1x256x1x192xbf16> loc(#loc109)
        %546 = "tpu.Load"(%59) {do_bcast = false, ginfo = #tpu.lg<out_addr = 27136, out_size = 128, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x256x1x1xui16, 1099522654736 : i64>) -> tensor<2x256x1x1xui16> loc(#loc110)
        %547 = "tpu.Concat"(%543, %541, %544) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [192], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 12, stage = 1, slice_idx = 0, group_type = 0>, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x64x28x40xbf16>, tensor<1x64x28x40xbf16>) -> tensor<1x192x28x40xbf16> loc(#loc111)
        %548 = "tpu.Conv2D"(%547, %545, %546) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 13, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x192x28x40xbf16>, tensor<1x256x1x192xbf16>, tensor<2x256x1x1xui16>) -> tensor<1x256x28x40xbf16> loc(#loc98)
        %549 = "tpu.Store"(%548, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 14, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x256x28x40xbf16>, none) -> tensor<1x256x28x40xbf16, 1146880 : i64> loc(#loc98)
        "tpu.Yield"(%549) : (tensor<1x256x28x40xbf16, 1146880 : i64>) -> () loc(#loc98)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 14, -2, 7, 6, -3, 9, 8, -4, 12, 10, 11, -5, 13, 0, 1, 2], group_type = 0 : i64, hsecs = 14 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x28x40xbf16, 1720320 : i64>, tensor<1x64x28x40xbf16, 143360 : i64>, tensor<1x64x28x40xbf16, 0 : i64>) -> tensor<1x256x28x40xbf16, 1146880 : i64> loc(#loc98)
      %61 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc112)
      %62 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc113)
      %63 = "tpu.LutBF16"(%60, %61, %62) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x28x40xbf16, 1146880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x256x28x40xbf16, 573440 : i64> loc(#loc114)
      %64 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x9x256xbf16, 1099523812880 : i64> loc(#loc115)
      %65 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099524993040 : i64> loc(#loc116)
      %66 = "tpu.Conv2D"(%63, %64, %65) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x28x40xbf16, 573440 : i64>, tensor<1x256x9x256xbf16, 1099523812880 : i64>, tensor<2x256x1x1xui16, 1099524993040 : i64>) -> tensor<1x256x14x20xbf16, 1146880 : i64> loc(#loc117)
      %67 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc118)
      %68 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc119)
      %69 = "tpu.LutBF16"(%66, %67, %68) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x14x20xbf16, 1146880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x256x14x20xbf16, 1290240 : i64> loc(#loc120)
      %70 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x256xbf16, 1099527263952 : i64> loc(#loc121)
      %71 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099523263632 : i64> loc(#loc122)
      %72 = "tpu.Conv2D"(%69, %70, %71) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x14x20xbf16, 1290240 : i64>, tensor<1x256x1x256xbf16, 1099527263952 : i64>, tensor<2x256x1x1xui16, 1099523263632 : i64>) -> tensor<1x256x14x20xbf16, 1146880 : i64> loc(#loc123)
      %73 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc124)
      %74 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc125)
      %75 = "tpu.LutBF16"(%72, %73, %74) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x14x20xbf16, 1146880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x256x14x20xbf16, 1505280 : i64> loc(#loc126)
      %76 = "tpu.Slice"(%75, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 128, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x256x14x20xbf16, 1505280 : i64>, none, none, none, none) -> tensor<1x128x14x20xbf16, 1505280 : i64> loc(#loc127)
      %77 = "tpu.Slice"(%75, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 256, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 128, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x256x14x20xbf16, 1505280 : i64>, none, none, none, none) -> tensor<1x128x14x20xbf16, 1576960 : i64> loc(#loc128)
      %78 = "top.Weight"() : () -> tensor<1x64x1x128xbf16, 1099523606032 : i64> loc(#loc129)
      %79 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099523812624 : i64> loc(#loc130)
      %80 = "top.Weight"() : () -> tensor<1x64x1x128xbf16, 1099522680848 : i64> loc(#loc131)
      %81 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099522554896 : i64> loc(#loc132)
      %82 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc133)
      %83 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc134)
      %84:2 = "tpu.Group"(%77) ({
        %535 = "tpu.Load"(%77) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x14x20xbf16, 1576960 : i64>) -> tensor<1x128x14x20xbf16> loc(#loc137)
        %536 = "tpu.Load"(%78) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2048, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [128], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x128xbf16, 1099523606032 : i64>) -> tensor<1x64x1x128xbf16> loc(#loc138)
        %537 = "tpu.Load"(%79) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24832, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099523812624 : i64>) -> tensor<2x64x1x1xui16> loc(#loc139)
        %538 = "tpu.Load"(%80) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2048, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [128], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x128xbf16, 1099522680848 : i64>) -> tensor<1x64x1x128xbf16> loc(#loc140)
        %539 = "tpu.Load"(%81) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16640, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099522554896 : i64>) -> tensor<2x64x1x1xui16> loc(#loc141)
        %540 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16>, tensor<1x64x1x128xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc142)
        %541 = "tpu.Load"(%82) {do_bcast = true, ginfo = #tpu.lg<out_addr = 5120, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc143)
        %542 = "tpu.Load"(%83) {do_bcast = true, ginfo = #tpu.lg<out_addr = 4608, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc144)
        %543 = "tpu.Conv2D"(%535, %538, %539) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 22528, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16>, tensor<1x64x1x128xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc135)
        %544 = "tpu.Store"(%543, %0) {ginfo = #tpu.lg<out_addr = 22528, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 9, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 1182720 : i64> loc(#loc135)
        %545 = "tpu.LutBF16"(%540, %541, %542) {ginfo = #tpu.lg<out_addr = 14336, out_size = 2304, buffer_addr = 24864, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 10, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc136)
        %546 = "tpu.Store"(%545, %0) {ginfo = #tpu.lg<out_addr = 14336, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 11, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 1146880 : i64> loc(#loc136)
        "tpu.Yield"(%544, %546) : (tensor<1x64x14x20xbf16, 1182720 : i64>, tensor<1x64x14x20xbf16, 1146880 : i64>) -> () loc(#loc790)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 11, -2, 8, 6, 7, -3, 10, 9, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x128x14x20xbf16, 1576960 : i64>) -> (tensor<1x64x14x20xbf16, 1182720 : i64>, tensor<1x64x14x20xbf16, 1146880 : i64>) loc(#loc790)
      %85 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc145)
      %86 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc146)
      %87 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099521168912 : i64> loc(#loc147)
      %88 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099521000720 : i64> loc(#loc148)
      %89 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc149)
      %90 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc150)
      %91:2 = "tpu.Group"(%84#0, %84#1) ({
        %535 = "tpu.Load"(%84#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 1182720 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc153)
        %536 = "tpu.Load"(%85) {do_bcast = true, ginfo = #tpu.lg<out_addr = 18688, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc154)
        %537 = "tpu.Load"(%86) {do_bcast = true, ginfo = #tpu.lg<out_addr = 19200, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc155)
        %538 = "tpu.Load"(%84#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 1146880 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc156)
        %539 = "tpu.Load"(%87) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099521168912 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc157)
        %540 = "tpu.Load"(%88) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12032, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099521000720 : i64>) -> tensor<2x64x1x1xui16> loc(#loc158)
        %541 = "tpu.LutBF16"(%535, %536, %537) {ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 20480, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc151)
        %542 = "tpu.Load"(%89) {do_bcast = true, ginfo = #tpu.lg<out_addr = 25088, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc159)
        %543 = "tpu.Load"(%90) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11520, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc160)
        %544 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 9, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 1290240 : i64> loc(#loc151)
        %545 = "tpu.Conv2D"(%538, %539, %540) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 10, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc161)
        %546 = "tpu.LutBF16"(%545, %542, %543) {ginfo = #tpu.lg<out_addr = 9216, out_size = 2304, buffer_addr = 12288, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc152)
        %547 = "tpu.Store"(%546, %0) {ginfo = #tpu.lg<out_addr = 9216, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 12, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 1254400 : i64> loc(#loc152)
        "tpu.Yield"(%544, %547) : (tensor<1x64x14x20xbf16, 1290240 : i64>, tensor<1x64x14x20xbf16, 1254400 : i64>) -> () loc(#loc791)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 12, -2, 10, 7, 8, 9, -3, 11, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 1182720 : i64>, tensor<1x64x14x20xbf16, 1146880 : i64>) -> (tensor<1x64x14x20xbf16, 1290240 : i64>, tensor<1x64x14x20xbf16, 1254400 : i64>) loc(#loc791)
      %92 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099526358096 : i64> loc(#loc162)
      %93 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099523264656 : i64> loc(#loc163)
      %94 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc164)
      %95 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc165)
      %96 = "tpu.Group"(%91#1, %84#1) ({
        %535 = "tpu.Load"(%91#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 1254400 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc167)
        %536 = "tpu.Load"(%92) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099526358096 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc168)
        %537 = "tpu.Load"(%93) {do_bcast = false, ginfo = #tpu.lg<out_addr = 14848, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099523264656 : i64>) -> tensor<2x64x1x1xui16> loc(#loc169)
        %538 = "tpu.Load"(%94) {do_bcast = true, ginfo = #tpu.lg<out_addr = 30976, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc170)
        %539 = "tpu.Load"(%95) {do_bcast = true, ginfo = #tpu.lg<out_addr = 14880, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc171)
        %540 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc172)
        %541 = "tpu.Load"(%84#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 1146880 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc156)
        %542 = "tpu.LutBF16"(%540, %538, %539) {ginfo = #tpu.lg<out_addr = 24576, out_size = 2304, buffer_addr = 9216, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc173)
        %543 = "tpu.Add"(%541, %542) {do_relu = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 8, stage = 1, slice_idx = 0, group_type = 0>, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc166)
        %544 = "tpu.Store"(%543, %0) {ginfo = #tpu.lg<out_addr = 28672, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 1218560 : i64> loc(#loc166)
        "tpu.Yield"(%544) : (tensor<1x64x14x20xbf16, 1218560 : i64>) -> () loc(#loc166)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 9, -2, 7, 6, -3, 8, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 1254400 : i64>, tensor<1x64x14x20xbf16, 1146880 : i64>) -> tensor<1x64x14x20xbf16, 1218560 : i64> loc(#loc166)
      %97 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099520924752 : i64> loc(#loc174)
      %98 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099517303632 : i64> loc(#loc175)
      %99 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc176)
      %100 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc177)
      %101 = "tpu.Group"(%96) ({
        %535 = "tpu.Load"(%96) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 1218560 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc179)
        %536 = "tpu.Load"(%97) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099520924752 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc180)
        %537 = "tpu.Load"(%98) {do_bcast = false, ginfo = #tpu.lg<out_addr = 9728, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099517303632 : i64>) -> tensor<2x64x1x1xui16> loc(#loc181)
        %538 = "tpu.Load"(%99) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc182)
        %539 = "tpu.Load"(%100) {do_bcast = true, ginfo = #tpu.lg<out_addr = 9216, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc183)
        %540 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc184)
        %541 = "tpu.LutBF16"(%540, %538, %539) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 25088, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc178)
        %542 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 1146880 : i64> loc(#loc178)
        "tpu.Yield"(%542) : (tensor<1x64x14x20xbf16, 1146880 : i64>) -> () loc(#loc178)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 1218560 : i64>) -> tensor<1x64x14x20xbf16, 1146880 : i64> loc(#loc178)
      %102 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099525869840 : i64> loc(#loc185)
      %103 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099525329680 : i64> loc(#loc186)
      %104 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc187)
      %105 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc188)
      %106 = "tpu.Group"(%101) ({
        %535 = "tpu.Load"(%101) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 1146880 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc190)
        %536 = "tpu.Load"(%102) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099525869840 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc191)
        %537 = "tpu.Load"(%103) {do_bcast = false, ginfo = #tpu.lg<out_addr = 9728, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099525329680 : i64>) -> tensor<2x64x1x1xui16> loc(#loc192)
        %538 = "tpu.Load"(%104) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc193)
        %539 = "tpu.Load"(%105) {do_bcast = true, ginfo = #tpu.lg<out_addr = 9216, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc194)
        %540 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc195)
        %541 = "tpu.LutBF16"(%540, %538, %539) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 25088, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc189)
        %542 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 1254400 : i64> loc(#loc189)
        "tpu.Yield"(%542) : (tensor<1x64x14x20xbf16, 1254400 : i64>) -> () loc(#loc189)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 1146880 : i64>) -> tensor<1x64x14x20xbf16, 1254400 : i64> loc(#loc189)
      %107 = "top.Weight"() : () -> tensor<1x128x1x128xbf16, 1099517269840 : i64> loc(#loc196)
      %108 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099523622928 : i64> loc(#loc197)
      %109 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc198)
      %110 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc199)
      %111 = "tpu.Group"(%96, %106, %91#0) ({
        %535 = "tpu.Load"(%96) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 1218560 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc179)
        %536 = "tpu.Load"(%106) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8704, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 1254400 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc201)
        %537 = "tpu.Load"(%91#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 2, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 1290240 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc202)
        %538 = "tpu.Add"(%535, %536) {do_relu = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc203)
        %539 = "tpu.Load"(%107) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4096, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [128], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x128xbf16, 1099517269840 : i64>) -> tensor<1x128x1x128xbf16> loc(#loc204)
        %540 = "tpu.Load"(%108) {do_bcast = false, ginfo = #tpu.lg<out_addr = 22784, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099523622928 : i64>) -> tensor<2x128x1x1xui16> loc(#loc205)
        %541 = "tpu.Concat"(%538, %537) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 4096, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>) -> tensor<1x128x14x20xbf16> loc(#loc206)
        %542 = "tpu.Load"(%109) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11008, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc207)
        %543 = "tpu.Load"(%110) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11520, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc208)
        %544 = "tpu.Conv2D"(%541, %539, %540) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 9, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16>, tensor<1x128x1x128xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x14x20xbf16> loc(#loc209)
        %545 = "tpu.LutBF16"(%544, %542, %543) {ginfo = #tpu.lg<out_addr = 4096, out_size = 4608, buffer_addr = 22848, buffer_size = 9216, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 10, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x14x20xbf16> loc(#loc200)
        %546 = "tpu.Store"(%545, %0) {ginfo = #tpu.lg<out_addr = 4096, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 11, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x14x20xbf16>, none) -> tensor<1x128x14x20xbf16, 1146880 : i64> loc(#loc200)
        "tpu.Yield"(%546) : (tensor<1x128x14x20xbf16, 1146880 : i64>) -> () loc(#loc200)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 3, 2, 11, -2, 6, 4, 5, -3, 9, 7, 8, -4, 10, 0, 1], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 1218560 : i64>, tensor<1x64x14x20xbf16, 1254400 : i64>, tensor<1x64x14x20xbf16, 1290240 : i64>) -> tensor<1x128x14x20xbf16, 1146880 : i64> loc(#loc200)
      %112 = "tpu.Concat"(%76, %77, %111) {axis = 1 : si32, do_relu = false, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x14x20xbf16, 1505280 : i64>, tensor<1x128x14x20xbf16, 1576960 : i64>, tensor<1x128x14x20xbf16, 1146880 : i64>) -> tensor<1x384x14x20xbf16, 1290240 : i64> loc(#loc210)
      %113 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x384xbf16, 1099523066512 : i64> loc(#loc211)
      %114 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099517260624 : i64> loc(#loc212)
      %115 = "tpu.Conv2D"(%112, %113, %114) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x384x14x20xbf16, 1290240 : i64>, tensor<1x256x1x384xbf16, 1099523066512 : i64>, tensor<2x256x1x1xui16, 1099517260624 : i64>) -> tensor<1x256x14x20xbf16, 1146880 : i64> loc(#loc213)
      %116 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc214)
      %117 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc215)
      %118 = "tpu.LutBF16"(%115, %116, %117) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x14x20xbf16, 1146880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x256x14x20xbf16, 1850800 : i64> loc(#loc216)
      %119 = "top.Weight"() {do_compress = true} : () -> tensor<1x512x9x256xbf16, 1099517336656 : i64> loc(#loc217)
      %120 = "top.Weight"() {do_compress = true} : () -> tensor<2x512x1x1xui16, 1099523810064 : i64> loc(#loc218)
      %121 = "tpu.Conv2D"(%118, %119, %120) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x14x20xbf16, 1850800 : i64>, tensor<1x512x9x256xbf16, 1099517336656 : i64>, tensor<2x512x1x1xui16, 1099523810064 : i64>) -> tensor<1x512x7x10xbf16, 1146880 : i64> loc(#loc219)
      %122 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc220)
      %123 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc221)
      %124 = "tpu.LutBF16"(%121, %122, %123) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x512x7x10xbf16, 1146880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x512x7x10xbf16, 1218560 : i64> loc(#loc222)
      %125 = "top.Weight"() {do_compress = true} : () -> tensor<1x512x1x512xbf16, 1099521243152 : i64> loc(#loc223)
      %126 = "top.Weight"() {do_compress = true} : () -> tensor<2x512x1x1xui16, 1099517225808 : i64> loc(#loc224)
      %127 = "tpu.Conv2D"(%124, %125, %126) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x512x7x10xbf16, 1218560 : i64>, tensor<1x512x1x512xbf16, 1099521243152 : i64>, tensor<2x512x1x1xui16, 1099517225808 : i64>) -> tensor<1x512x7x10xbf16, 1146880 : i64> loc(#loc225)
      %128 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc226)
      %129 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc227)
      %130 = "tpu.LutBF16"(%127, %128, %129) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x512x7x10xbf16, 1146880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x512x7x10xbf16, 1290240 : i64> loc(#loc228)
      %131 = "tpu.Slice"(%130, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 256, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x512x7x10xbf16, 1290240 : i64>, none, none, none, none) -> tensor<1x256x7x10xbf16, 1290240 : i64> loc(#loc229)
      %132 = "tpu.Slice"(%130, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 512, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 256, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x512x7x10xbf16, 1290240 : i64>, none, none, none, none) -> tensor<1x256x7x10xbf16, 1326080 : i64> loc(#loc230)
      %133 = "top.Weight"() : () -> tensor<1x128x1x256xbf16, 1099517160272 : i64> loc(#loc231)
      %134 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099524992528 : i64> loc(#loc232)
      %135 = "top.Weight"() : () -> tensor<1x128x1x256xbf16, 1099517094480 : i64> loc(#loc233)
      %136 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099521000208 : i64> loc(#loc234)
      %137:2 = "tpu.Group"(%132) ({
        %535 = "tpu.Load"(%133) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 8192, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [256], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x256xbf16, 1099517160272 : i64>) -> tensor<1x128x1x256xbf16> loc(#loc237)
        %536 = "tpu.Load"(%134) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20992, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099524992528 : i64>) -> tensor<2x128x1x1xui16> loc(#loc238)
        %537 = "tpu.Load"(%132) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x256x7x10xbf16, 1326080 : i64>) -> tensor<1x256x7x10xbf16> loc(#loc239)
        %538 = "tpu.Load"(%135) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 8192, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [256], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x256xbf16, 1099517094480 : i64>) -> tensor<1x128x1x256xbf16> loc(#loc240)
        %539 = "tpu.Load"(%136) {do_bcast = false, ginfo = #tpu.lg<out_addr = 21056, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099521000208 : i64>) -> tensor<2x128x1x1xui16> loc(#loc241)
        %540 = "tpu.Conv2D"(%537, %535, %536) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16>, tensor<1x128x1x256xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x7x10xbf16> loc(#loc235)
        %541 = "tpu.Store"(%540, %0) {ginfo = #tpu.lg<out_addr = 28672, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 6, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x7x10xbf16>, none) -> tensor<1x128x7x10xbf16, 1164800 : i64> loc(#loc235)
        %542 = "tpu.Conv2D"(%537, %538, %539) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 7, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16>, tensor<1x128x1x256xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x7x10xbf16> loc(#loc236)
        %543 = "tpu.Store"(%542, %0) {ginfo = #tpu.lg<out_addr = 24576, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 8, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x7x10xbf16>, none) -> tensor<1x128x7x10xbf16, 1146880 : i64> loc(#loc236)
        "tpu.Yield"(%541, %543) : (tensor<1x128x7x10xbf16, 1164800 : i64>, tensor<1x128x7x10xbf16, 1146880 : i64>) -> () loc(#loc792)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 8, -2, 7, 6, 0, 1, -3, 2], group_type = 0 : i64, hsecs = 1 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x256x7x10xbf16, 1326080 : i64>) -> (tensor<1x128x7x10xbf16, 1164800 : i64>, tensor<1x128x7x10xbf16, 1146880 : i64>) loc(#loc792)
      %138 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc242)
      %139 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc243)
      %140 = "tpu.LutBF16"(%137#0, %138, %139) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 1164800 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 1200640 : i64> loc(#loc244)
      %141 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc245)
      %142 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc246)
      %143 = "tpu.LutBF16"(%137#1, %141, %142) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 1146880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 1182720 : i64> loc(#loc247)
      %144 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099516766800 : i64> loc(#loc248)
      %145 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099522655760 : i64> loc(#loc249)
      %146 = "tpu.Conv2D"(%140, %144, %145) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 1200640 : i64>, tensor<1x128x9x128xbf16, 1099516766800 : i64>, tensor<2x128x1x1xui16, 1099522655760 : i64>) -> tensor<1x128x7x10xbf16, 1146880 : i64> loc(#loc250)
      %147 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc251)
      %148 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc252)
      %149 = "tpu.LutBF16"(%146, %147, %148) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 1146880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 1218560 : i64> loc(#loc253)
      %150 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099516258384 : i64> loc(#loc254)
      %151 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099516257872 : i64> loc(#loc255)
      %152 = "tpu.Conv2D"(%149, %150, %151) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 1218560 : i64>, tensor<1x128x9x128xbf16, 1099516258384 : i64>, tensor<2x128x1x1xui16, 1099516257872 : i64>) -> tensor<1x128x7x10xbf16, 1146880 : i64> loc(#loc256)
      %153 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc257)
      %154 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc258)
      %155 = "tpu.LutBF16"(%152, %153, %154) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 1146880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 1218560 : i64> loc(#loc259)
      %156 = "tpu.Add"(%140, %155) {do_relu = false, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x7x10xbf16, 1200640 : i64>, tensor<1x128x7x10xbf16, 1218560 : i64>) -> tensor<1x128x7x10xbf16, 1146880 : i64> loc(#loc260)
      %157 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099519695952 : i64> loc(#loc261)
      %158 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099516766288 : i64> loc(#loc262)
      %159 = "tpu.Conv2D"(%156, %157, %158) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 1146880 : i64>, tensor<1x128x9x128xbf16, 1099519695952 : i64>, tensor<2x128x1x1xui16, 1099516766288 : i64>) -> tensor<1x128x7x10xbf16, 1200640 : i64> loc(#loc263)
      %160 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc264)
      %161 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc265)
      %162 = "tpu.LutBF16"(%159, %160, %161) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 1200640 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 1218560 : i64> loc(#loc266)
      %163 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099522697872 : i64> loc(#loc267)
      %164 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099524994064 : i64> loc(#loc268)
      %165 = "tpu.Conv2D"(%162, %163, %164) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 1218560 : i64>, tensor<1x128x9x128xbf16, 1099522697872 : i64>, tensor<2x128x1x1xui16, 1099524994064 : i64>) -> tensor<1x128x7x10xbf16, 1200640 : i64> loc(#loc269)
      %166 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc270)
      %167 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc271)
      %168 = "tpu.LutBF16"(%165, %166, %167) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 1200640 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 1218560 : i64> loc(#loc272)
      %169 = "tpu.Add"(%156, %168) {do_relu = false, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x7x10xbf16, 1146880 : i64>, tensor<1x128x7x10xbf16, 1218560 : i64>) -> tensor<1x128x7x10xbf16, 1164800 : i64> loc(#loc273)
      %170 = "tpu.Concat"(%169, %143) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x7x10xbf16, 1164800 : i64>, tensor<1x128x7x10xbf16, 1182720 : i64>) -> tensor<1x256x7x10xbf16, 1164800 : i64> loc(#loc274)
      %171 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x256xbf16, 1099530176336 : i64> loc(#loc275)
      %172 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099525326608 : i64> loc(#loc276)
      %173 = "tpu.Conv2D"(%170, %171, %172) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16, 1164800 : i64>, tensor<1x256x1x256xbf16, 1099530176336 : i64>, tensor<2x256x1x1xui16, 1099525326608 : i64>) -> tensor<1x256x7x10xbf16, 1200640 : i64> loc(#loc277)
      %174 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc278)
      %175 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc279)
      %176 = "tpu.LutBF16"(%173, %174, %175) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x7x10xbf16, 1200640 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x256x7x10xbf16, 1146880 : i64> loc(#loc280)
      %177 = "tpu.Concat"(%131, %132, %176) {axis = 1 : si32, do_relu = false, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x256x7x10xbf16, 1290240 : i64>, tensor<1x256x7x10xbf16, 1326080 : i64>, tensor<1x256x7x10xbf16, 1146880 : i64>) -> tensor<1x768x7x10xbf16, 1182720 : i64> loc(#loc281)
      %178 = "top.Weight"() {do_compress = true} : () -> tensor<1x512x1x768xbf16, 1099521767440 : i64> loc(#loc282)
      %179 = "top.Weight"() {do_compress = true} : () -> tensor<2x512x1x1xui16, 1099525327632 : i64> loc(#loc283)
      %180 = "tpu.Conv2D"(%177, %178, %179) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x768x7x10xbf16, 1182720 : i64>, tensor<1x512x1x768xbf16, 1099521767440 : i64>, tensor<2x512x1x1xui16, 1099525327632 : i64>) -> tensor<1x512x7x10xbf16, 1290240 : i64> loc(#loc284)
      %181 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc285)
      %182 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc286)
      %183 = "tpu.LutBF16"(%180, %181, %182) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x512x7x10xbf16, 1290240 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x512x7x10xbf16, 1146880 : i64> loc(#loc287)
      %184 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x512xbf16, 1099526433360 : i64> loc(#loc288)
      %185 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099525330704 : i64> loc(#loc289)
      %186 = "tpu.Conv2D"(%183, %184, %185) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x512x7x10xbf16, 1146880 : i64>, tensor<1x256x1x512xbf16, 1099526433360 : i64>, tensor<2x256x1x1xui16, 1099525330704 : i64>) -> tensor<1x256x7x10xbf16, 1218560 : i64> loc(#loc290)
      %187 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc291)
      %188 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc292)
      %189 = "tpu.LutBF16"(%186, %187, %188) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x7x10xbf16, 1218560 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x256x7x10xbf16, 1254400 : i64> loc(#loc293)
      %190:3 = "tpu.Group"(%189) ({
        %535 = "tpu.Load"(%189) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x256x7x10xbf16, 1254400 : i64>) -> tensor<1x256x7x10xbf16> loc(#loc297)
        %536 = "tpu.Pool2D"(%535) {count_include_pad = false, do_relu = false, first_round_mode = #tpu<round_mode HalfAwayFromZero>, ginfo = #tpu.lg<out_addr = 0, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 1, stage = 1, slice_idx = 0, group_type = 0>, is_adaptive = false, keepdims = true, kernel_shape = [5, 5], pad_value = 0 : i64, pads = [2, 2, 2, 2], pool_mode = #tpu<pool_mode Max>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfAwayFromZero>, strides = [1, 1]} : (tensor<1x256x7x10xbf16>) -> tensor<1x256x7x10xbf16> loc(#loc294)
        %537 = "tpu.Store"(%536, %0) {ginfo = #tpu.lg<out_addr = 0, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 2, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x256x7x10xbf16>, none) -> tensor<1x256x7x10xbf16, 1290240 : i64> loc(#loc294)
        %538 = "tpu.Pool2D"(%536) {count_include_pad = false, do_relu = false, first_round_mode = #tpu<round_mode HalfAwayFromZero>, ginfo = #tpu.lg<out_addr = 8192, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 3, stage = 1, slice_idx = 0, group_type = 0>, is_adaptive = false, keepdims = true, kernel_shape = [5, 5], pad_value = 0 : i64, pads = [2, 2, 2, 2], pool_mode = #tpu<pool_mode Max>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfAwayFromZero>, strides = [1, 1]} : (tensor<1x256x7x10xbf16>) -> tensor<1x256x7x10xbf16> loc(#loc295)
        %539 = "tpu.Store"(%538, %0) {ginfo = #tpu.lg<out_addr = 8192, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 4, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x256x7x10xbf16>, none) -> tensor<1x256x7x10xbf16, 1326080 : i64> loc(#loc295)
        %540 = "tpu.Pool2D"(%538) {count_include_pad = false, do_relu = false, first_round_mode = #tpu<round_mode HalfAwayFromZero>, ginfo = #tpu.lg<out_addr = 24576, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 5, stage = 1, slice_idx = 0, group_type = 0>, is_adaptive = false, keepdims = true, kernel_shape = [5, 5], pad_value = 0 : i64, pads = [2, 2, 2, 2], pool_mode = #tpu<pool_mode Max>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfAwayFromZero>, strides = [1, 1]} : (tensor<1x256x7x10xbf16>) -> tensor<1x256x7x10xbf16> loc(#loc296)
        %541 = "tpu.Store"(%540, %0) {ginfo = #tpu.lg<out_addr = 24576, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 6, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x256x7x10xbf16>, none) -> tensor<1x256x7x10xbf16, 1361920 : i64> loc(#loc296)
        "tpu.Yield"(%537, %539, %541) : (tensor<1x256x7x10xbf16, 1290240 : i64>, tensor<1x256x7x10xbf16, 1326080 : i64>, tensor<1x256x7x10xbf16, 1361920 : i64>) -> () loc(#loc793)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 1, 6, -2, 3, 2, -3, 5, 4, 0], group_type = 0 : i64, hsecs = 1 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x256x7x10xbf16, 1254400 : i64>) -> (tensor<1x256x7x10xbf16, 1290240 : i64>, tensor<1x256x7x10xbf16, 1326080 : i64>, tensor<1x256x7x10xbf16, 1361920 : i64>) loc(#loc793)
      %191 = "tpu.Concat"(%189, %190#0, %190#1, %190#2) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x256x7x10xbf16, 1254400 : i64>, tensor<1x256x7x10xbf16, 1290240 : i64>, tensor<1x256x7x10xbf16, 1326080 : i64>, tensor<1x256x7x10xbf16, 1361920 : i64>) -> tensor<1x1024x7x10xbf16, 1254400 : i64> loc(#loc298)
      %192 = "top.Weight"() {do_compress = true} : () -> tensor<1x512x1x1024xbf16, 1099528436304 : i64> loc(#loc299)
      %193 = "top.Weight"() {do_compress = true} : () -> tensor<2x512x1x1xui16, 1099525331728 : i64> loc(#loc300)
      %194 = "tpu.Conv2D"(%191, %192, %193) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x1024x7x10xbf16, 1254400 : i64>, tensor<1x512x1x1024xbf16, 1099528436304 : i64>, tensor<2x512x1x1xui16, 1099525331728 : i64>) -> tensor<1x512x7x10xbf16, 1146880 : i64> loc(#loc301)
      %195 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc302)
      %196 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc303)
      %197 = "tpu.LutBF16"(%194, %195, %196) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x512x7x10xbf16, 1146880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x512x7x10xbf16, 1218560 : i64> loc(#loc304)
      %198 = "top.Weight"() {do_compress = true} : () -> tensor<1x512x1x512xbf16, 1099525334288 : i64> loc(#loc305)
      %199 = "top.Weight"() {do_compress = true} : () -> tensor<2x512x1x1xui16, 1099525858576 : i64> loc(#loc306)
      %200 = "tpu.Conv2D"(%197, %198, %199) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x512x7x10xbf16, 1218560 : i64>, tensor<1x512x1x512xbf16, 1099525334288 : i64>, tensor<2x512x1x1xui16, 1099525858576 : i64>) -> tensor<1x512x7x10xbf16, 1290240 : i64> loc(#loc307)
      %201 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc308)
      %202 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc309)
      %203 = "tpu.LutBF16"(%200, %201, %202) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x512x7x10xbf16, 1290240 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x512x7x10xbf16, 1146880 : i64> loc(#loc310)
      %204 = "tpu.Slice"(%203, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 256, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x512x7x10xbf16, 1146880 : i64>, none, none, none, none) -> tensor<1x256x7x10xbf16, 1146880 : i64> loc(#loc311)
      %205 = "tpu.Slice"(%203, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 512, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 256, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x512x7x10xbf16, 1146880 : i64>, none, none, none, none) -> tensor<1x256x7x10xbf16, 1182720 : i64> loc(#loc312)
      %206 = "top.Weight"() {do_compress = true} : () -> tensor<1x512x1x256xbf16, 1099525951760 : i64> loc(#loc313)
      %207 = "top.Weight"() {do_compress = true} : () -> tensor<2x512x1x1xui16, 1099526216016 : i64> loc(#loc314)
      %208 = "tpu.Conv2D"(%205, %206, %207) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16, 1182720 : i64>, tensor<1x512x1x256xbf16, 1099525951760 : i64>, tensor<2x512x1x1xui16, 1099526216016 : i64>) -> tensor<1x512x7x10xbf16, 1218560 : i64> loc(#loc315)
      %209 = "tpu.Reshape"(%208) {flatten_start_dim = -1 : i64, shape = [1, 4, 128, 70]} : (tensor<1x512x7x10xbf16, 1218560 : i64>) -> tensor<1x4x128x70xbf16, 1218560 : i64> loc(#loc316)
      %210 = "tpu.Slice"(%209, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 9223372036854775807, 32, 9223372036854775807], hasparamConvert_axes = [2], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x4x128x70xbf16, 1218560 : i64>, none, none, none, none) -> tensor<1x4x32x70xbf16, 1290240 : i64> loc(#loc317)
      %211 = "tpu.Slice"(%209, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 9223372036854775807, 64, 9223372036854775807], hasparamConvert_axes = [2], offset = [0, 0, 32, 0], steps = [1, 1, 1, 1]} : (tensor<1x4x128x70xbf16, 1218560 : i64>, none, none, none, none) -> tensor<1x4x32x70xbf16, 1308160 : i64> loc(#loc318)
      %212 = "tpu.Slice"(%209, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 9223372036854775807, 128, 9223372036854775807], hasparamConvert_axes = [2], offset = [0, 0, 64, 0], steps = [1, 1, 1, 1]} : (tensor<1x4x128x70xbf16, 1218560 : i64>, none, none, none, none) -> tensor<1x4x64x70xbf16, 1326080 : i64> loc(#loc319)
      %213 = "tpu.Permute"(%210, %0) {order = [0, 1, 3, 2]} : (tensor<1x4x32x70xbf16, 1290240 : i64>, none) -> tensor<1x4x70x32xbf16, 1218560 : i64> loc(#loc320)
      %214 = "tpu.Reshape"(%212) {flatten_start_dim = -1 : i64, shape = [1, 256, 7, 10]} : (tensor<1x4x64x70xbf16, 1326080 : i64>) -> tensor<1x256x7x10xbf16, 1326080 : i64> loc(#loc321)
      %215 = "tpu.MatMul"(%213, %211, %0, %0, %0) {do_relu = false, fuse_rq = false, hdim_is_batch = false, input_zp = 0 : i64, keep_dims = true, left_reuse = 1 : i64, left_transpose = false, multipliers = [1], output_transpose = false, quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, right_transpose = false, right_zp = 0 : i64, round_mode = #tpu<round_mode HalfAwayFromZero>, rshifts = [0]} : (tensor<1x4x70x32xbf16, 1218560 : i64>, tensor<1x4x32x70xbf16, 1308160 : i64>, none, none, none) -> tensor<1x4x70x70xbf16, 1236480 : i64> loc(#loc322)
      %216 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x3x3xbf16, 1099526353232 : i64> loc(#loc323)
      %217 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099526432336 : i64> loc(#loc324)
      %218 = "tpu.Conv2D"(%214, %216, %217) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 256 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16, 1326080 : i64>, tensor<1x256x3x3xbf16, 1099526353232 : i64>, tensor<2x256x1x1xui16, 1099526432336 : i64>) -> tensor<1x256x7x10xbf16, 1275680 : i64> loc(#loc325)
      %219 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099526695504 : i64> loc(#loc326)
      %220 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099526696016 : i64> loc(#loc327)
      %221 = "tpu.LutBF16"(%215, %219, %220) {const_val = 0.1767766922712326 : f64, do_relu = false, is_scalar = false, lut_mode = #tpu<lut_mode Slope>, max_range = 1.500000e+01 : f64, min_range = -1.500000e+01 : f64, relu_limit = -1.000000e+00 : f64} : (tensor<1x4x70x70xbf16, 1236480 : i64>, tensor<1x1x32x8xbf16, 1099526695504 : i64>, tensor<1x1x32x8xbf16, 1099526696016 : i64>) -> tensor<1x4x70x70xbf16, 1361920 : i64> loc(#loc328)
      %222 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528117584 : i64> loc(#loc329)
      %223 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099526697936 : i64> loc(#loc330)
      %224 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099526431824 : i64> loc(#loc331)
      %225 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099527920464 : i64> loc(#loc332)
      %226 = "tpu.Softmax"(%221, %222, %223, %224, %225, %0) {axis = 3 : si32, beta = 1.000000e+00 : f64, log = false, round_mode = #tpu<round_mode HalfAwayFromZero>} : (tensor<1x4x70x70xbf16, 1361920 : i64>, tensor<1x1x32x8xbf16, 1099528117584 : i64>, tensor<1x1x32x8xbf16, 1099526697936 : i64>, tensor<1x1x32x8xbf16, 1099526431824 : i64>, tensor<1x1x32x8xbf16, 1099527920464 : i64>, none) -> tensor<1x4x70x70xbf16, 1218560 : i64> loc(#loc333)
      %227 = "tpu.Permute"(%226, %0) {order = [0, 1, 3, 2]} : (tensor<1x4x70x70xbf16, 1218560 : i64>, none) -> tensor<1x4x70x70xbf16, 1361920 : i64> loc(#loc334)
      %228 = "tpu.MatMul"(%212, %227, %0, %0, %0) {do_relu = false, fuse_rq = false, hdim_is_batch = false, input_zp = 0 : i64, keep_dims = true, left_reuse = 1 : i64, left_transpose = false, multipliers = [1], output_transpose = false, quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, right_transpose = false, right_zp = 0 : i64, round_mode = #tpu<round_mode HalfAwayFromZero>, rshifts = [0]} : (tensor<1x4x64x70xbf16, 1326080 : i64>, tensor<1x4x70x70xbf16, 1361920 : i64>, none, none, none) -> tensor<1x4x64x70xbf16, 1218560 : i64> loc(#loc335)
      %229 = "tpu.Reshape"(%228) {flatten_start_dim = -1 : i64, shape = [1, 256, 7, 10]} : (tensor<1x4x64x70xbf16, 1218560 : i64>) -> tensor<1x256x7x10xbf16, 1218560 : i64> loc(#loc336)
      %230 = "tpu.Add"(%229, %218) {do_relu = false, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x256x7x10xbf16, 1218560 : i64>, tensor<1x256x7x10xbf16, 1275680 : i64>) -> tensor<1x256x7x10xbf16, 1311520 : i64> loc(#loc337)
      %231 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x256xbf16, 1099521037840 : i64> loc(#loc338)
      %232 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099526698960 : i64> loc(#loc339)
      %233 = "tpu.Conv2D"(%230, %231, %232) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16, 1311520 : i64>, tensor<1x256x1x256xbf16, 1099521037840 : i64>, tensor<2x256x1x1xui16, 1099526698960 : i64>) -> tensor<1x256x7x10xbf16, 1218560 : i64> loc(#loc340)
      %234 = "tpu.Add"(%205, %233) {do_relu = false, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x256x7x10xbf16, 1182720 : i64>, tensor<1x256x7x10xbf16, 1218560 : i64>) -> tensor<1x256x7x10xbf16, 1254400 : i64> loc(#loc341)
      %235 = "top.Weight"() {do_compress = true} : () -> tensor<1x512x1x256xbf16, 1099526699984 : i64> loc(#loc342)
      %236 = "top.Weight"() {do_compress = true} : () -> tensor<2x512x1x1xui16, 1099524994576 : i64> loc(#loc343)
      %237 = "tpu.Conv2D"(%234, %235, %236) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16, 1254400 : i64>, tensor<1x512x1x256xbf16, 1099526699984 : i64>, tensor<2x512x1x1xui16, 1099524994576 : i64>) -> tensor<1x512x7x10xbf16, 1290240 : i64> loc(#loc344)
      %238 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc345)
      %239 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc346)
      %240 = "tpu.LutBF16"(%237, %238, %239) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x512x7x10xbf16, 1290240 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x512x7x10xbf16, 1361920 : i64> loc(#loc347)
      %241 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x512xbf16, 1099526999504 : i64> loc(#loc348)
      %242 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099528342352 : i64> loc(#loc349)
      %243 = "tpu.Conv2D"(%240, %241, %242) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x512x7x10xbf16, 1361920 : i64>, tensor<1x256x1x512xbf16, 1099526999504 : i64>, tensor<2x256x1x1xui16, 1099528342352 : i64>) -> tensor<1x256x7x10xbf16, 1290240 : i64> loc(#loc350)
      %244 = "tpu.Add"(%234, %243) {do_relu = false, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x256x7x10xbf16, 1254400 : i64>, tensor<1x256x7x10xbf16, 1290240 : i64>) -> tensor<1x256x7x10xbf16, 1326080 : i64> loc(#loc351)
      %245 = "tpu.Concat"(%204, %244) {axis = 1 : si32, do_relu = false, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x256x7x10xbf16, 1146880 : i64>, tensor<1x256x7x10xbf16, 1326080 : i64>) -> tensor<1x512x7x10xbf16, 1218560 : i64> loc(#loc352)
      %246 = "top.Weight"() {do_compress = true} : () -> tensor<1x512x1x512xbf16, 1099527395024 : i64> loc(#loc353)
      %247 = "top.Weight"() {do_compress = true} : () -> tensor<2x512x1x1xui16, 1099528343888 : i64> loc(#loc354)
      %248 = "tpu.Conv2D"(%245, %246, %247) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x512x7x10xbf16, 1218560 : i64>, tensor<1x512x1x512xbf16, 1099527395024 : i64>, tensor<2x512x1x1xui16, 1099528343888 : i64>) -> tensor<1x512x7x10xbf16, 1420720 : i64> loc(#loc355)
      %249 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc356)
      %250 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc357)
      %251 = "tpu.LutBF16"(%248, %249, %250) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x512x7x10xbf16, 1420720 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x512x7x10xbf16, 1313200 : i64> loc(#loc358)
      %252 = "top.Weight"() : () -> tensor<1x512x2x2xbf16, 1099526218064 : i64> loc(#loc359)
      %253 = "tpu.Deconv"(%251, %252, %0) {dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 512 : i64, inserts = [0, 0], kernel_shape = [2, 2], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, strides = [2, 2], with_bias = false} : (tensor<1x512x7x10xbf16, 1313200 : i64>, tensor<1x512x2x2xbf16, 1099526218064 : i64>, none) -> tensor<1x512x14x20xbf16, 1564080 : i64> loc(#loc360)
      %254 = "tpu.Concat"(%253, %118) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x512x14x20xbf16, 1564080 : i64>, tensor<1x256x14x20xbf16, 1850800 : i64>) -> tensor<1x768x14x20xbf16, 1564080 : i64> loc(#loc361)
      %255 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x768xbf16, 1099529485392 : i64> loc(#loc362)
      %256 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099527919440 : i64> loc(#loc363)
      %257 = "tpu.Conv2D"(%254, %255, %256) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x768x14x20xbf16, 1564080 : i64>, tensor<1x256x1x768xbf16, 1099529485392 : i64>, tensor<2x256x1x1xui16, 1099527919440 : i64>) -> tensor<1x256x14x20xbf16, 1384880 : i64> loc(#loc364)
      %258 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc365)
      %259 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc366)
      %260 = "tpu.LutBF16"(%257, %258, %259) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x14x20xbf16, 1384880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x256x14x20xbf16, 1743280 : i64> loc(#loc367)
      %261 = "tpu.Slice"(%260, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 128, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x256x14x20xbf16, 1743280 : i64>, none, none, none, none) -> tensor<1x128x14x20xbf16, 1743280 : i64> loc(#loc368)
      %262 = "tpu.Slice"(%260, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 256, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 128, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x256x14x20xbf16, 1743280 : i64>, none, none, none, none) -> tensor<1x128x14x20xbf16, 1814960 : i64> loc(#loc369)
      %263 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x128xbf16, 1099516553296 : i64> loc(#loc370)
      %264 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099528118096 : i64> loc(#loc371)
      %265 = "tpu.Conv2D"(%262, %263, %264) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16, 1814960 : i64>, tensor<1x64x9x128xbf16, 1099516553296 : i64>, tensor<2x64x1x1xui16, 1099528118096 : i64>) -> tensor<1x64x14x20xbf16, 1384880 : i64> loc(#loc372)
      %266 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc373)
      %267 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc374)
      %268 = "tpu.LutBF16"(%265, %266, %267) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16, 1384880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x64x14x20xbf16, 1420720 : i64> loc(#loc375)
      %269 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x64xbf16, 1099528194896 : i64> loc(#loc376)
      %270 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099528343376 : i64> loc(#loc377)
      %271 = "tpu.Conv2D"(%268, %269, %270) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16, 1420720 : i64>, tensor<1x128x9x64xbf16, 1099528194896 : i64>, tensor<2x128x1x1xui16, 1099528343376 : i64>) -> tensor<1x128x14x20xbf16, 1456560 : i64> loc(#loc378)
      %272 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc379)
      %273 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc380)
      %274 = "tpu.LutBF16"(%271, %272, %273) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16, 1456560 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x14x20xbf16, 1384880 : i64> loc(#loc381)
      %275 = "tpu.Group"(%262, %274, %261) ({
        %535 = "tpu.Load"(%274) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 3328, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 5, 10], h_slice = [5, 5, 4], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x14x20xbf16, 1384880 : i64>) -> tensor<1x128x14x20xbf16> loc(#loc383)
        %536 = "tpu.Load"(%262) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 3328, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 5, 10], h_slice = [5, 5, 4], w_idx = [0], w_slice = [20], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x14x20xbf16, 1814960 : i64>) -> tensor<1x128x14x20xbf16> loc(#loc384)
        %537 = "tpu.Load"(%261) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 3328, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 5, 10], h_slice = [5, 5, 4], w_idx = [0], w_slice = [20], id = 2, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x14x20xbf16, 1743280 : i64>) -> tensor<1x128x14x20xbf16> loc(#loc385)
        %538 = "tpu.Add"(%536, %535) {do_relu = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 3328, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 5, 10], h_slice = [5, 5, 4], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x14x20xbf16>, tensor<1x128x14x20xbf16>) -> tensor<1x128x14x20xbf16> loc(#loc386)
        %539 = "tpu.Concat"(%537, %536, %538) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9984, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [384], d_idx = [0], d_slice = [1], h_idx = [0, 5, 10], h_slice = [5, 5, 4], w_idx = [0], w_slice = [20], id = 4, stage = 1, slice_idx = 0, group_type = 0>, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x14x20xbf16>, tensor<1x128x14x20xbf16>, tensor<1x128x14x20xbf16>) -> tensor<1x384x14x20xbf16> loc(#loc382)
        %540 = "tpu.Store"(%539, %0) {ginfo = #tpu.lg<out_addr = 0, out_size = 9984, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [384], d_idx = [0], d_slice = [1], h_idx = [0, 5, 10], h_slice = [5, 5, 4], w_idx = [0], w_slice = [20], id = 5, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x384x14x20xbf16>, none) -> tensor<1x384x14x20xbf16, 1528240 : i64> loc(#loc382)
        "tpu.Yield"(%540) : (tensor<1x384x14x20xbf16, 1528240 : i64>) -> () loc(#loc382)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 3, 2, 5, -2, 4, 0, -3, 1], group_type = 0 : i64, hsecs = 3 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x128x14x20xbf16, 1814960 : i64>, tensor<1x128x14x20xbf16, 1384880 : i64>, tensor<1x128x14x20xbf16, 1743280 : i64>) -> tensor<1x384x14x20xbf16, 1528240 : i64> loc(#loc382)
      %276 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x384xbf16, 1099525127696 : i64> loc(#loc387)
      %277 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099528346448 : i64> loc(#loc388)
      %278 = "tpu.Conv2D"(%275, %276, %277) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x384x14x20xbf16, 1528240 : i64>, tensor<1x256x1x384xbf16, 1099525127696 : i64>, tensor<2x256x1x1xui16, 1099528346448 : i64>) -> tensor<1x256x14x20xbf16, 1384880 : i64> loc(#loc389)
      %279 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc390)
      %280 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc391)
      %281 = "tpu.LutBF16"(%278, %279, %280) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x14x20xbf16, 1384880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x256x14x20xbf16, 1671600 : i64> loc(#loc392)
      %282 = "top.Weight"() : () -> tensor<1x256x2x2xbf16, 1099526213904 : i64> loc(#loc393)
      %283 = "tpu.Deconv"(%281, %282, %0) {dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 256 : i64, inserts = [0, 0], kernel_shape = [2, 2], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, strides = [2, 2], with_bias = false} : (tensor<1x256x14x20xbf16, 1671600 : i64>, tensor<1x256x2x2xbf16, 1099526213904 : i64>, none) -> tensor<1x256x28x40xbf16, 0 : i64> loc(#loc394)
      %284 = "tpu.Concat"(%283, %63) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x256x28x40xbf16, 0 : i64>, tensor<1x256x28x40xbf16, 573440 : i64>) -> tensor<1x512x28x40xbf16, 0 : i64> loc(#loc395)
      %285 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x1x512xbf16, 1099526222160 : i64> loc(#loc396)
      %286 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099528347472 : i64> loc(#loc397)
      %287 = "tpu.Conv2D"(%284, %285, %286) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x512x28x40xbf16, 0 : i64>, tensor<1x128x1x512xbf16, 1099526222160 : i64>, tensor<2x128x1x1xui16, 1099528347472 : i64>) -> tensor<1x128x28x40xbf16, 1384880 : i64> loc(#loc398)
      %288 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc399)
      %289 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc400)
      %290 = "tpu.LutBF16"(%287, %288, %289) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x28x40xbf16, 1384880 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x28x40xbf16, 0 : i64> loc(#loc401)
      %291 = "tpu.Slice"(%290, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 64, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x128x28x40xbf16, 0 : i64>, none, none, none, none) -> tensor<1x64x28x40xbf16, 0 : i64> loc(#loc402)
      %292 = "tpu.Slice"(%290, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 128, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 64, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x128x28x40xbf16, 0 : i64>, none, none, none, none) -> tensor<1x64x28x40xbf16, 143360 : i64> loc(#loc403)
      %293 = "top.Weight"() {do_compress = true} : () -> tensor<1x32x9x64xbf16, 1099526962128 : i64> loc(#loc404)
      %294 = "top.Weight"() {do_compress = true} : () -> tensor<2x32x1x1xui16, 1099526697808 : i64> loc(#loc405)
      %295 = "tpu.Conv2D"(%292, %293, %294) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16, 143360 : i64>, tensor<1x32x9x64xbf16, 1099526962128 : i64>, tensor<2x32x1x1xui16, 1099526697808 : i64>) -> tensor<1x32x28x40xbf16, 286720 : i64> loc(#loc406)
      %296 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc407)
      %297 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc408)
      %298 = "tpu.LutBF16"(%295, %296, %297) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x28x40xbf16, 286720 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x32x28x40xbf16, 358400 : i64> loc(#loc409)
      %299 = "top.Weight"() : () -> tensor<1x64x9x32xbf16, 1099528348240 : i64> loc(#loc410)
      %300 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099522654480 : i64> loc(#loc411)
      %301 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc412)
      %302 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc413)
      %303 = "top.Weight"() : () -> tensor<1x128x1x192xbf16, 1099528387152 : i64> loc(#loc414)
      %304 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099529484880 : i64> loc(#loc415)
      %305 = "tpu.Group"(%298, %292, %291) ({
        %535 = "tpu.Load"(%298) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20992, out_size = 1920, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 3, 7, 11, 15, 19, 23], h_slice = [5, 6, 6, 6, 6, 6, 5], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 358400 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc417)
        %536 = "tpu.Load"(%299) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [32], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x32xbf16, 1099528348240 : i64>) -> tensor<1x64x9x32xbf16> loc(#loc418)
        %537 = "tpu.Load"(%300) {do_bcast = false, ginfo = #tpu.lg<out_addr = 15936, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099522654480 : i64>) -> tensor<2x64x1x1xui16> loc(#loc419)
        %538 = "tpu.Load"(%301) {do_bcast = true, ginfo = #tpu.lg<out_addr = 23552, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc420)
        %539 = "tpu.Load"(%302) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24064, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc421)
        %540 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 6144, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x28x40xbf16>, tensor<1x64x9x32xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc422)
        %541 = "tpu.Load"(%292) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20992, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 143360 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc423)
        %542 = "tpu.LutBF16"(%540, %538, %539) {ginfo = #tpu.lg<out_addr = 12288, out_size = 2560, buffer_addr = 24576, buffer_size = 5120, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc424)
        %543 = "tpu.Load"(%291) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 0 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc425)
        %544 = "tpu.Add"(%541, %542) {do_relu = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 9, stage = 1, slice_idx = 0, group_type = 0>, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x64x28x40xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc426)
        %545 = "tpu.Load"(%303) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 6144, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [192], id = 10, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x192xbf16, 1099528387152 : i64>) -> tensor<1x128x1x192xbf16> loc(#loc427)
        %546 = "tpu.Load"(%304) {do_bcast = false, ginfo = #tpu.lg<out_addr = 15872, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099529484880 : i64>) -> tensor<2x128x1x1xui16> loc(#loc428)
        %547 = "tpu.Concat"(%543, %541, %544) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 7680, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [192], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 12, stage = 1, slice_idx = 0, group_type = 0>, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x64x28x40xbf16>, tensor<1x64x28x40xbf16>) -> tensor<1x192x28x40xbf16> loc(#loc429)
        %548 = "tpu.Conv2D"(%547, %545, %546) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 13, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x192x28x40xbf16>, tensor<1x128x1x192xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x28x40xbf16> loc(#loc416)
        %549 = "tpu.Store"(%548, %0) {ginfo = #tpu.lg<out_addr = 24576, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 14, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x28x40xbf16>, none) -> tensor<1x128x28x40xbf16, 430080 : i64> loc(#loc416)
        "tpu.Yield"(%549) : (tensor<1x128x28x40xbf16, 430080 : i64>) -> () loc(#loc416)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 14, -2, 7, 6, -3, 9, 8, -4, 12, 10, 11, -5, 13, 0, 1, 2], group_type = 0 : i64, hsecs = 7 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x28x40xbf16, 358400 : i64>, tensor<1x64x28x40xbf16, 143360 : i64>, tensor<1x64x28x40xbf16, 0 : i64>) -> tensor<1x128x28x40xbf16, 430080 : i64> loc(#loc416)
      %306 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc430)
      %307 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc431)
      %308 = "tpu.LutBF16"(%305, %306, %307) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x28x40xbf16, 430080 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x28x40xbf16, 0 : i64> loc(#loc432)
      %309 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099529878608 : i64> loc(#loc433)
      %310 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099530307408 : i64> loc(#loc434)
      %311 = "tpu.Conv2D"(%308, %309, %310) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x28x40xbf16, 0 : i64>, tensor<1x128x9x128xbf16, 1099529878608 : i64>, tensor<2x128x1x1xui16, 1099530307408 : i64>) -> tensor<1x128x14x20xbf16, 286720 : i64> loc(#loc435)
      %312 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x128xbf16, 1099523660304 : i64> loc(#loc436)
      %313 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099530316624 : i64> loc(#loc437)
      %314 = "tpu.Conv2D"(%308, %312, %313) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x28x40xbf16, 0 : i64>, tensor<1x64x9x128xbf16, 1099523660304 : i64>, tensor<2x64x1x1xui16, 1099530316624 : i64>) -> tensor<1x64x28x40xbf16, 358400 : i64> loc(#loc438)
      %315 = "top.Weight"() : () -> tensor<1x128x3x3xbf16, 1099525324304 : i64> loc(#loc439)
      %316 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099530316880 : i64> loc(#loc440)
      %317 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc441)
      %318 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc442)
      %319 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc443)
      %320 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc444)
      %321:3 = "tpu.Group"(%308, %311, %314) ({
        %535 = "tpu.Load"(%308) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 10240, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 5, 11, 17, 22], h_slice = [7, 8, 8, 7, 6], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x28x40xbf16, 0 : i64>) -> tensor<1x128x28x40xbf16> loc(#loc448)
        %536 = "tpu.Load"(%315) {do_bcast = false, ginfo = #tpu.lg<out_addr = 32000, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [3], w_idx = [0], w_slice = [3], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x3x3xbf16, 1099525324304 : i64>) -> tensor<1x128x3x3xbf16> loc(#loc449)
        %537 = "tpu.Load"(%316) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24320, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099530316880 : i64>) -> tensor<2x128x1x1xui16> loc(#loc450)
        %538 = "tpu.Load"(%311) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28416, out_size = 2048, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 3, 6, 9, 12], h_slice = [3, 3, 3, 3, 2], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x14x20xbf16, 286720 : i64>) -> tensor<1x128x14x20xbf16> loc(#loc451)
        %539 = "tpu.Load"(%317) {do_bcast = true, ginfo = #tpu.lg<out_addr = 19968, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc452)
        %540 = "tpu.Load"(%318) {do_bcast = true, ginfo = #tpu.lg<out_addr = 30464, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc453)
        %541 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 7680, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 128 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x28x40xbf16>, tensor<1x128x3x3xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x28x40xbf16> loc(#loc445)
        %542 = "tpu.Load"(%314) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 358400 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc454)
        %543 = "tpu.Load"(%319) {do_bcast = true, ginfo = #tpu.lg<out_addr = 31488, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc455)
        %544 = "tpu.Load"(%320) {do_bcast = true, ginfo = #tpu.lg<out_addr = 30976, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc456)
        %545 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 12288, out_size = 7680, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 10, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x28x40xbf16>, none) -> tensor<1x128x28x40xbf16, 716800 : i64> loc(#loc445)
        %546 = "tpu.LutBF16"(%538, %539, %540) {ginfo = #tpu.lg<out_addr = 10240, out_size = 2048, buffer_addr = 0, buffer_size = 4096, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 3, 6, 9, 12], h_slice = [3, 3, 3, 3, 2], w_idx = [0], w_slice = [20], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x14x20xbf16> loc(#loc446)
        %547 = "tpu.Store"(%546, %0) {ginfo = #tpu.lg<out_addr = 10240, out_size = 2048, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 3, 6, 9, 12], h_slice = [3, 3, 3, 3, 2], w_idx = [0], w_slice = [20], id = 12, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x14x20xbf16>, none) -> tensor<1x128x14x20xbf16, 501760 : i64> loc(#loc446)
        %548 = "tpu.LutBF16"(%542, %543, %544) {ginfo = #tpu.lg<out_addr = 24576, out_size = 3840, buffer_addr = 12288, buffer_size = 7680, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 13, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc447)
        %549 = "tpu.Store"(%548, %0) {ginfo = #tpu.lg<out_addr = 24576, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 14, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 573440 : i64> loc(#loc447)
        "tpu.Yield"(%545, %547, %549) : (tensor<1x128x28x40xbf16, 716800 : i64>, tensor<1x128x14x20xbf16, 501760 : i64>, tensor<1x64x28x40xbf16, 573440 : i64>) -> () loc(#loc794)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 14, -2, 11, 7, 8, 9, 10, -3, 13, 12, 0, 1, 2], group_type = 0 : i64, hsecs = 5 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x128x28x40xbf16, 0 : i64>, tensor<1x128x14x20xbf16, 286720 : i64>, tensor<1x64x28x40xbf16, 358400 : i64>) -> (tensor<1x128x28x40xbf16, 716800 : i64>, tensor<1x128x14x20xbf16, 501760 : i64>, tensor<1x64x28x40xbf16, 573440 : i64>) loc(#loc794)
      %322 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc457)
      %323 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc458)
      %324 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099522992784 : i64> loc(#loc459)
      %325 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099530317392 : i64> loc(#loc460)
      %326 = "top.Weight"() : () -> tensor<1x128x1x128xbf16, 1099530317648 : i64> loc(#loc461)
      %327 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099526698448 : i64> loc(#loc462)
      %328:3 = "tpu.Group"(%321#0, %321#1, %281, %321#2) ({
        %535 = "tpu.Load"(%321#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x28x40xbf16, 716800 : i64>) -> tensor<1x128x28x40xbf16> loc(#loc466)
        %536 = "tpu.Load"(%322) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11776, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc467)
        %537 = "tpu.Load"(%323) {do_bcast = true, ginfo = #tpu.lg<out_addr = 18944, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc468)
        %538 = "tpu.Load"(%321#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 19456, out_size = 768, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], h_slice = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x14x20xbf16, 501760 : i64>) -> tensor<1x128x14x20xbf16> loc(#loc469)
        %539 = "tpu.Load"(%281) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 1536, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], h_slice = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], w_idx = [0], w_slice = [20], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x256x14x20xbf16, 1671600 : i64>) -> tensor<1x256x14x20xbf16> loc(#loc470)
        %540 = "tpu.LutBF16"(%535, %536, %537) {ginfo = #tpu.lg<out_addr = 9216, out_size = 2560, buffer_addr = 26112, buffer_size = 5120, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x28x40xbf16> loc(#loc471)
        %541 = "tpu.Load"(%321#2) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25], h_slice = [3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 573440 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc472)
        %542 = "tpu.Load"(%324) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099522992784 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc473)
        %543 = "tpu.Load"(%325) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20224, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099530317392 : i64>) -> tensor<2x64x1x1xui16> loc(#loc474)
        %544 = "tpu.Concat"(%538, %539) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [384], d_idx = [0], d_slice = [1], h_idx = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], h_slice = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], w_idx = [0], w_slice = [20], id = 9, stage = 1, slice_idx = 0, group_type = 0>, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x14x20xbf16>, tensor<1x256x14x20xbf16>) -> tensor<1x384x14x20xbf16> loc(#loc463)
        %545 = "tpu.Load"(%326) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 4096, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [128], id = 10, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x128xbf16, 1099530317648 : i64>) -> tensor<1x128x1x128xbf16> loc(#loc475)
        %546 = "tpu.Load"(%327) {do_bcast = false, ginfo = #tpu.lg<out_addr = 31232, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099526698448 : i64>) -> tensor<2x128x1x1xui16> loc(#loc476)
        %547 = "tpu.Store"(%544, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [384], d_idx = [0], d_slice = [1], h_idx = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], h_slice = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], w_idx = [0], w_slice = [20], id = 12, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x384x14x20xbf16>, none) -> tensor<1x384x14x20xbf16, 1384880 : i64> loc(#loc463)
        %548 = "tpu.Conv2D"(%541, %542, %543) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 13, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc464)
        %549 = "tpu.Store"(%548, %0) {ginfo = #tpu.lg<out_addr = 24576, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 14, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 0 : i64> loc(#loc464)
        %550 = "tpu.Conv2D"(%540, %545, %546) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 15, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x28x40xbf16>, tensor<1x128x1x128xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x28x40xbf16> loc(#loc465)
        %551 = "tpu.Store"(%550, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26], h_slice = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [40], id = 16, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x28x40xbf16>, none) -> tensor<1x128x28x40xbf16, 143360 : i64> loc(#loc465)
        "tpu.Yield"(%547, %549, %551) : (tensor<1x384x14x20xbf16, 1384880 : i64>, tensor<1x64x28x40xbf16, 0 : i64>, tensor<1x128x28x40xbf16, 143360 : i64>) -> () loc(#loc795)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 16, -2, 9, 6, 7, 8, -3, 13, 10, 11, 12, -4, 15, 14, 0, 1, 2], group_type = 0 : i64, hsecs = 14 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x128x28x40xbf16, 716800 : i64>, tensor<1x128x14x20xbf16, 501760 : i64>, tensor<1x256x14x20xbf16, 1671600 : i64>, tensor<1x64x28x40xbf16, 573440 : i64>) -> (tensor<1x384x14x20xbf16, 1384880 : i64>, tensor<1x64x28x40xbf16, 0 : i64>, tensor<1x128x28x40xbf16, 143360 : i64>) loc(#loc795)
      %329 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x384xbf16, 1099527920976 : i64> loc(#loc477)
      %330 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099523808016 : i64> loc(#loc478)
      %331 = "tpu.Conv2D"(%328#0, %329, %330) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x384x14x20xbf16, 1384880 : i64>, tensor<1x256x1x384xbf16, 1099527920976 : i64>, tensor<2x256x1x1xui16, 1099523808016 : i64>) -> tensor<1x256x14x20xbf16, 430080 : i64> loc(#loc479)
      %332 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc480)
      %333 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc481)
      %334 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc482)
      %335 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc483)
      %336 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc484)
      %337 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc485)
      %338:3 = "tpu.Group"(%328#1, %328#2, %331) ({
        %535 = "tpu.Load"(%328#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 0 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc489)
        %536 = "tpu.Load"(%332) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7680, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc490)
        %537 = "tpu.Load"(%333) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7168, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc491)
        %538 = "tpu.Load"(%328#2) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x28x40xbf16, 143360 : i64>) -> tensor<1x128x28x40xbf16> loc(#loc492)
        %539 = "tpu.Load"(%334) {do_bcast = true, ginfo = #tpu.lg<out_addr = 5120, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc493)
        %540 = "tpu.Load"(%335) {do_bcast = true, ginfo = #tpu.lg<out_addr = 5632, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc494)
        %541 = "tpu.LutBF16"(%535, %536, %537) {ginfo = #tpu.lg<out_addr = 16384, out_size = 2560, buffer_addr = 8192, buffer_size = 5120, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc486)
        %542 = "tpu.Load"(%331) {do_bcast = false, ginfo = #tpu.lg<out_addr = 18944, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12], h_slice = [2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x256x14x20xbf16, 430080 : i64>) -> tensor<1x256x14x20xbf16> loc(#loc495)
        %543 = "tpu.Load"(%336) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6144, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc496)
        %544 = "tpu.Load"(%337) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6656, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc497)
        %545 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 10, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 1134000 : i64> loc(#loc486)
        %546 = "tpu.LutBF16"(%538, %539, %540) {ginfo = #tpu.lg<out_addr = 8192, out_size = 5120, buffer_addr = 21504, buffer_size = 10240, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x28x40xbf16> loc(#loc487)
        %547 = "tpu.Store"(%546, %0) {ginfo = #tpu.lg<out_addr = 8192, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 12, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x28x40xbf16>, none) -> tensor<1x128x28x40xbf16, 703920 : i64> loc(#loc487)
        %548 = "tpu.LutBF16"(%542, %543, %544) {ginfo = #tpu.lg<out_addr = 24576, out_size = 2560, buffer_addr = 0, buffer_size = 5120, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12], h_slice = [2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [20], id = 13, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x256x14x20xbf16> loc(#loc488)
        %549 = "tpu.Store"(%548, %0) {ginfo = #tpu.lg<out_addr = 24576, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12], h_slice = [2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [20], id = 14, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x256x14x20xbf16>, none) -> tensor<1x256x14x20xbf16, 990640 : i64> loc(#loc488)
        "tpu.Yield"(%545, %547, %549) : (tensor<1x64x28x40xbf16, 1134000 : i64>, tensor<1x128x28x40xbf16, 703920 : i64>, tensor<1x256x14x20xbf16, 990640 : i64>) -> () loc(#loc796)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 14, -2, 11, 7, 8, 9, 10, -3, 13, 12, 0, 1, 2], group_type = 0 : i64, hsecs = 7 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [-3, 1], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x28x40xbf16, 0 : i64>, tensor<1x128x28x40xbf16, 143360 : i64>, tensor<1x256x14x20xbf16, 430080 : i64>) -> (tensor<1x64x28x40xbf16, 1134000 : i64>, tensor<1x128x28x40xbf16, 703920 : i64>, tensor<1x256x14x20xbf16, 990640 : i64>) loc(#loc796)
      %339 = "top.Weight"() : () -> tensor<1x64x1x64xbf16, 1099525943568 : i64> loc(#loc498)
      %340 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099530350416 : i64> loc(#loc499)
      %341 = "top.Weight"() : () -> tensor<1x128x3x3xbf16, 1099527261648 : i64> loc(#loc500)
      %342 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099528194384 : i64> loc(#loc501)
      %343:2 = "tpu.Group"(%338#0, %338#1) ({
        %535 = "tpu.Load"(%338#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 1134000 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc504)
        %536 = "tpu.Load"(%339) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 1024, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x64xbf16, 1099525943568 : i64>) -> tensor<1x64x1x64xbf16> loc(#loc505)
        %537 = "tpu.Load"(%340) {do_bcast = false, ginfo = #tpu.lg<out_addr = 10816, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099530350416 : i64>) -> tensor<2x64x1x1xui16> loc(#loc506)
        %538 = "tpu.Load"(%338#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 10240, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 5, 11, 17, 22], h_slice = [7, 8, 8, 7, 6], w_idx = [0], w_slice = [40], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x28x40xbf16, 703920 : i64>) -> tensor<1x128x28x40xbf16> loc(#loc507)
        %539 = "tpu.Load"(%341) {do_bcast = false, ginfo = #tpu.lg<out_addr = 10240, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [3], w_idx = [0], w_slice = [3], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x3x3xbf16, 1099527261648 : i64>) -> tensor<1x128x3x3xbf16> loc(#loc508)
        %540 = "tpu.Load"(%342) {do_bcast = false, ginfo = #tpu.lg<out_addr = 10752, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099528194384 : i64>) -> tensor<2x128x1x1xui16> loc(#loc509)
        %541 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16>, tensor<1x64x1x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc502)
        %542 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 417200 : i64> loc(#loc502)
        %543 = "tpu.Conv2D"(%538, %539, %540) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 7680, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 128 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x28x40xbf16>, tensor<1x128x3x3xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x28x40xbf16> loc(#loc503)
        %544 = "tpu.Store"(%543, %0) {ginfo = #tpu.lg<out_addr = 12288, out_size = 7680, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x28x40xbf16>, none) -> tensor<1x128x28x40xbf16, 0 : i64> loc(#loc503)
        "tpu.Yield"(%542, %544) : (tensor<1x64x28x40xbf16, 417200 : i64>, tensor<1x128x28x40xbf16, 0 : i64>) -> () loc(#loc797)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 5 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [1], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x28x40xbf16, 1134000 : i64>, tensor<1x128x28x40xbf16, 703920 : i64>) -> (tensor<1x64x28x40xbf16, 417200 : i64>, tensor<1x128x28x40xbf16, 0 : i64>) loc(#loc797)
      %344 = "tpu.Slice"(%338#2, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 128, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x256x14x20xbf16, 990640 : i64>, none, none, none, none) -> tensor<1x128x14x20xbf16, 990640 : i64> loc(#loc510)
      %345 = "tpu.Slice"(%338#2, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 256, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 128, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x256x14x20xbf16, 990640 : i64>, none, none, none, none) -> tensor<1x128x14x20xbf16, 1062320 : i64> loc(#loc511)
      %346 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x128xbf16, 1099530350672 : i64> loc(#loc512)
      %347 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099530173776 : i64> loc(#loc513)
      %348 = "tpu.Conv2D"(%345, %346, %347) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16, 1062320 : i64>, tensor<1x64x9x128xbf16, 1099530350672 : i64>, tensor<2x64x1x1xui16, 1099530173776 : i64>) -> tensor<1x64x14x20xbf16, 569520 : i64> loc(#loc514)
      %349 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc515)
      %350 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc516)
      %351 = "top.Weight"() : () -> tensor<1x128x1x128xbf16, 1099517061712 : i64> loc(#loc517)
      %352 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099525329936 : i64> loc(#loc518)
      %353 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc519)
      %354 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc520)
      %355:2 = "tpu.Group"(%343#1, %348) ({
        %535 = "tpu.Load"(%343#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x28x40xbf16, 0 : i64>) -> tensor<1x128x28x40xbf16> loc(#loc523)
        %536 = "tpu.Load"(%349) {do_bcast = true, ginfo = #tpu.lg<out_addr = 10240, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc524)
        %537 = "tpu.Load"(%350) {do_bcast = true, ginfo = #tpu.lg<out_addr = 10752, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc525)
        %538 = "tpu.Load"(%351) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4096, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [128], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x128xbf16, 1099517061712 : i64>) -> tensor<1x128x1x128xbf16> loc(#loc526)
        %539 = "tpu.Load"(%352) {do_bcast = false, ginfo = #tpu.lg<out_addr = 11904, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099525329936 : i64>) -> tensor<2x128x1x1xui16> loc(#loc527)
        %540 = "tpu.LutBF16"(%535, %536, %537) {ginfo = #tpu.lg<out_addr = 4096, out_size = 5120, buffer_addr = 12288, buffer_size = 10240, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x28x40xbf16> loc(#loc528)
        %541 = "tpu.Load"(%348) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 640, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12], h_slice = [2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 569520 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc529)
        %542 = "tpu.Load"(%353) {do_bcast = true, ginfo = #tpu.lg<out_addr = 9216, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc530)
        %543 = "tpu.Load"(%354) {do_bcast = true, ginfo = #tpu.lg<out_addr = 9728, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc531)
        %544 = "tpu.Conv2D"(%540, %538, %539) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 9, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x28x40xbf16>, tensor<1x128x1x128xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x28x40xbf16> loc(#loc521)
        %545 = "tpu.Store"(%544, %0) {ginfo = #tpu.lg<out_addr = 12288, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 10, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x28x40xbf16>, none) -> tensor<1x128x28x40xbf16, 641200 : i64> loc(#loc521)
        %546 = "tpu.LutBF16"(%541, %542, %543) {ginfo = #tpu.lg<out_addr = 11264, out_size = 640, buffer_addr = 4096, buffer_size = 1280, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12], h_slice = [2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [20], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc522)
        %547 = "tpu.Store"(%546, %0) {ginfo = #tpu.lg<out_addr = 11264, out_size = 640, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12], h_slice = [2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [20], id = 12, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 605360 : i64> loc(#loc522)
        "tpu.Yield"(%545, %547) : (tensor<1x128x28x40xbf16, 641200 : i64>, tensor<1x64x14x20xbf16, 605360 : i64>) -> () loc(#loc798)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 12, -2, 9, 6, 7, 8, -3, 11, 10, 0, 1, 2], group_type = 0 : i64, hsecs = 7 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x128x28x40xbf16, 0 : i64>, tensor<1x64x14x20xbf16, 569520 : i64>) -> (tensor<1x128x28x40xbf16, 641200 : i64>, tensor<1x64x14x20xbf16, 605360 : i64>) loc(#loc798)
      %356 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x64xbf16, 1099519990864 : i64> loc(#loc532)
      %357 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099516257360 : i64> loc(#loc533)
      %358 = "tpu.Conv2D"(%355#1, %356, %357) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16, 605360 : i64>, tensor<1x128x9x64xbf16, 1099519990864 : i64>, tensor<2x128x1x1xui16, 1099516257360 : i64>) -> tensor<1x128x14x20xbf16, 0 : i64> loc(#loc534)
      %359 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc535)
      %360 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc536)
      %361 = "top.Weight"() : () -> tensor<1x4x1x128xbf16, 1099522553872 : i64> loc(#loc537)
      %362 = "top.Weight"() : () -> tensor<2x4x1x1xui16, 1099516256832 : i64> loc(#loc538)
      %363 = "tpu.Group"(%355#0) ({
        %535 = "tpu.Load"(%355#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 7680, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x28x40xbf16, 641200 : i64>) -> tensor<1x128x28x40xbf16> loc(#loc540)
        %536 = "tpu.Load"(%359) {do_bcast = true, ginfo = #tpu.lg<out_addr = 16384, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc541)
        %537 = "tpu.Load"(%360) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7680, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc542)
        %538 = "tpu.Load"(%361) {do_bcast = false, ginfo = #tpu.lg<out_addr = 32256, out_size = 256, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [128], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x4x1x128xbf16, 1099522553872 : i64>) -> tensor<1x4x1x128xbf16> loc(#loc543)
        %539 = "tpu.Load"(%362) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16352, out_size = 4, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x4x1x1xui16, 1099516256832 : i64>) -> tensor<2x4x1x1xui16> loc(#loc544)
        %540 = "tpu.LutBF16"(%535, %536, %537) {ginfo = #tpu.lg<out_addr = 0, out_size = 7680, buffer_addr = 16896, buffer_size = 15360, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x28x40xbf16> loc(#loc545)
        %541 = "tpu.Conv2D"(%540, %538, %539) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 15872, out_size = 480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x28x40xbf16>, tensor<1x4x1x128xbf16>, tensor<2x4x1x1xui16>) -> tensor<1x4x28x40xbf16> loc(#loc539)
        %542 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 15872, out_size = 480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x4x28x40xbf16>, none) -> tensor<1x4x28x40xbf16, 560560 : i64> loc(#loc539)
        "tpu.Yield"(%542) : (tensor<1x4x28x40xbf16, 560560 : i64>) -> () loc(#loc539)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 5 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x128x28x40xbf16, 641200 : i64>) -> tensor<1x4x28x40xbf16, 560560 : i64> loc(#loc539)
      %364 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc546)
      %365 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc547)
      %366 = "tpu.LutBF16"(%358, %364, %365) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16, 0 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x14x20xbf16, 569520 : i64> loc(#loc548)
      %367 = "tpu.Concat"(%343#0, %363) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x28x40xbf16, 417200 : i64>, tensor<1x4x28x40xbf16, 560560 : i64>) -> tensor<1x68x28x40xbf16, 417200 : i64> loc(#loc549)
      %368 = "tpu.Add"(%345, %366) {do_relu = false, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x14x20xbf16, 1062320 : i64>, tensor<1x128x14x20xbf16, 569520 : i64>) -> tensor<1x128x14x20xbf16, 641200 : i64> loc(#loc550)
      %369 = "tpu.Reshape"(%367) {flatten_start_dim = -1 : i64, shape = [1, 68, -1]} : (tensor<1x68x28x40xbf16, 417200 : i64>) -> tensor<1x68x1120xbf16, 417200 : i64> loc(#loc551)
      %370 = "tpu.Concat"(%344, %345, %368) {axis = 1 : si32, do_relu = false, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x14x20xbf16, 990640 : i64>, tensor<1x128x14x20xbf16, 1062320 : i64>, tensor<1x128x14x20xbf16, 641200 : i64>) -> tensor<1x384x14x20xbf16, 0 : i64> loc(#loc552)
      %371 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x384xbf16, 1099516060224 : i64> loc(#loc553)
      %372 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099526696528 : i64> loc(#loc554)
      %373 = "tpu.Conv2D"(%370, %371, %372) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x384x14x20xbf16, 0 : i64>, tensor<1x256x1x384xbf16, 1099516060224 : i64>, tensor<2x256x1x1xui16, 1099526696528 : i64>) -> tensor<1x256x14x20xbf16, 569520 : i64> loc(#loc555)
      %374 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc556)
      %375 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc557)
      %376 = "tpu.LutBF16"(%373, %374, %375) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x14x20xbf16, 569520 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x256x14x20xbf16, 712880 : i64> loc(#loc558)
      %377 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x9x256xbf16, 1099514880064 : i64> loc(#loc559)
      %378 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099514879040 : i64> loc(#loc560)
      %379 = "tpu.Conv2D"(%376, %377, %378) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x14x20xbf16, 712880 : i64>, tensor<1x256x9x256xbf16, 1099514880064 : i64>, tensor<2x256x1x1xui16, 1099514879040 : i64>) -> tensor<1x256x7x10xbf16, 856240 : i64> loc(#loc561)
      %380 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x256xbf16, 1099514584128 : i64> loc(#loc562)
      %381 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099517160016 : i64> loc(#loc563)
      %382 = "tpu.Conv2D"(%376, %380, %381) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x14x20xbf16, 712880 : i64>, tensor<1x64x9x256xbf16, 1099514584128 : i64>, tensor<2x64x1x1xui16, 1099517160016 : i64>) -> tensor<1x64x14x20xbf16, 892080 : i64> loc(#loc564)
      %383 = "top.Weight"() : () -> tensor<1x256x3x3xbf16, 1099514579520 : i64> loc(#loc565)
      %384 = "top.Weight"() : () -> tensor<2x256x1x1xui16, 1099522653456 : i64> loc(#loc566)
      %385 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc567)
      %386 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc568)
      %387 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc569)
      %388 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc570)
      %389:3 = "tpu.Group"(%376, %379, %382) ({
        %535 = "tpu.Load"(%376) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 10240, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x256x14x20xbf16, 712880 : i64>) -> tensor<1x256x14x20xbf16> loc(#loc574)
        %536 = "tpu.Load"(%383) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12800, out_size = 1024, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [3], w_idx = [0], w_slice = [3], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x256x3x3xbf16, 1099514579520 : i64>) -> tensor<1x256x3x3xbf16> loc(#loc575)
        %537 = "tpu.Load"(%384) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16128, out_size = 128, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x256x1x1xui16, 1099522653456 : i64>) -> tensor<2x256x1x1xui16> loc(#loc576)
        %538 = "tpu.Load"(%379) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 4], h_slice = [4, 3], w_idx = [0], w_slice = [10], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x256x7x10xbf16, 856240 : i64>) -> tensor<1x256x7x10xbf16> loc(#loc577)
        %539 = "tpu.Load"(%385) {do_bcast = true, ginfo = #tpu.lg<out_addr = 27904, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc578)
        %540 = "tpu.Load"(%386) {do_bcast = true, ginfo = #tpu.lg<out_addr = 31232, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc579)
        %541 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 256 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x14x20xbf16>, tensor<1x256x3x3xbf16>, tensor<2x256x1x1xui16>) -> tensor<1x256x14x20xbf16> loc(#loc571)
        %542 = "tpu.Load"(%382) {do_bcast = false, ginfo = #tpu.lg<out_addr = 25600, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 892080 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc580)
        %543 = "tpu.Load"(%387) {do_bcast = true, ginfo = #tpu.lg<out_addr = 31744, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc581)
        %544 = "tpu.Load"(%388) {do_bcast = true, ginfo = #tpu.lg<out_addr = 32256, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc582)
        %545 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 10, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x256x14x20xbf16>, none) -> tensor<1x256x14x20xbf16, 963760 : i64> loc(#loc571)
        %546 = "tpu.LutBF16"(%538, %539, %540) {ginfo = #tpu.lg<out_addr = 10240, out_size = 2560, buffer_addr = 0, buffer_size = 5120, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 4], h_slice = [4, 3], w_idx = [0], w_slice = [10], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x7x10xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x256x7x10xbf16> loc(#loc572)
        %547 = "tpu.Store"(%546, %0) {ginfo = #tpu.lg<out_addr = 10240, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 4], h_slice = [4, 3], w_idx = [0], w_slice = [10], id = 12, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x256x7x10xbf16>, none) -> tensor<1x256x7x10xbf16, 1277360 : i64> loc(#loc572)
        %548 = "tpu.LutBF16"(%542, %543, %544) {ginfo = #tpu.lg<out_addr = 13824, out_size = 2304, buffer_addr = 16384, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 13, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc573)
        %549 = "tpu.Store"(%548, %0) {ginfo = #tpu.lg<out_addr = 13824, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 14, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 927920 : i64> loc(#loc573)
        "tpu.Yield"(%545, %547, %549) : (tensor<1x256x14x20xbf16, 963760 : i64>, tensor<1x256x7x10xbf16, 1277360 : i64>, tensor<1x64x14x20xbf16, 927920 : i64>) -> () loc(#loc799)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 14, -2, 11, 7, 8, 9, 10, -3, 13, 12, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x256x14x20xbf16, 712880 : i64>, tensor<1x256x7x10xbf16, 856240 : i64>, tensor<1x64x14x20xbf16, 892080 : i64>) -> (tensor<1x256x14x20xbf16, 963760 : i64>, tensor<1x256x7x10xbf16, 1277360 : i64>, tensor<1x64x14x20xbf16, 927920 : i64>) loc(#loc799)
      %390 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc583)
      %391 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc584)
      %392 = "tpu.LutBF16"(%389#0, %390, %391) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x14x20xbf16, 963760 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x256x14x20xbf16, 569520 : i64> loc(#loc585)
      %393 = "tpu.Concat"(%389#1, %251) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x256x7x10xbf16, 1277360 : i64>, tensor<1x512x7x10xbf16, 1313200 : i64>) -> tensor<1x768x7x10xbf16, 1277360 : i64> loc(#loc586)
      %394 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x64xbf16, 1099514505792 : i64> loc(#loc587)
      %395 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099530173520 : i64> loc(#loc588)
      %396 = "tpu.Conv2D"(%389#2, %394, %395) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16, 927920 : i64>, tensor<1x64x9x64xbf16, 1099514505792 : i64>, tensor<2x64x1x1xui16, 1099530173520 : i64>) -> tensor<1x64x14x20xbf16, 963760 : i64> loc(#loc589)
      %397 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x1x256xbf16, 1099514440256 : i64> loc(#loc590)
      %398 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099514439744 : i64> loc(#loc591)
      %399 = "tpu.Conv2D"(%392, %397, %398) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x14x20xbf16, 569520 : i64>, tensor<1x128x1x256xbf16, 1099514440256 : i64>, tensor<2x128x1x1xui16, 1099514439744 : i64>) -> tensor<1x128x14x20xbf16, 0 : i64> loc(#loc592)
      %400 = "top.Weight"() {do_compress = true} : () -> tensor<1x512x1x768xbf16, 1099513653312 : i64> loc(#loc593)
      %401 = "top.Weight"() {do_compress = true} : () -> tensor<2x512x1x1xui16, 1099528385104 : i64> loc(#loc594)
      %402 = "tpu.Conv2D"(%393, %400, %401) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x768x7x10xbf16, 1277360 : i64>, tensor<1x512x1x768xbf16, 1099513653312 : i64>, tensor<2x512x1x1xui16, 1099528385104 : i64>) -> tensor<1x512x7x10xbf16, 569520 : i64> loc(#loc595)
      %403 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc596)
      %404 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc597)
      %405 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc598)
      %406 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc599)
      %407:2 = "tpu.Group"(%396, %399) ({
        %535 = "tpu.Load"(%396) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 963760 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc602)
        %536 = "tpu.Load"(%403) {do_bcast = true, ginfo = #tpu.lg<out_addr = 5632, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc603)
        %537 = "tpu.Load"(%404) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6144, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc604)
        %538 = "tpu.Load"(%399) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x14x20xbf16, 0 : i64>) -> tensor<1x128x14x20xbf16> loc(#loc605)
        %539 = "tpu.Load"(%405) {do_bcast = true, ginfo = #tpu.lg<out_addr = 4608, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc606)
        %540 = "tpu.Load"(%406) {do_bcast = true, ginfo = #tpu.lg<out_addr = 5120, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc607)
        %541 = "tpu.LutBF16"(%535, %536, %537) {ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 24576, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc600)
        %542 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 712880 : i64> loc(#loc600)
        %543 = "tpu.LutBF16"(%538, %539, %540) {ginfo = #tpu.lg<out_addr = 8192, out_size = 4608, buffer_addr = 22784, buffer_size = 9216, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x14x20xbf16> loc(#loc601)
        %544 = "tpu.Store"(%543, %0) {ginfo = #tpu.lg<out_addr = 8192, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x14x20xbf16>, none) -> tensor<1x128x14x20xbf16, 641200 : i64> loc(#loc601)
        "tpu.Yield"(%542, %544) : (tensor<1x64x14x20xbf16, 712880 : i64>, tensor<1x128x14x20xbf16, 641200 : i64>) -> () loc(#loc800)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 963760 : i64>, tensor<1x128x14x20xbf16, 0 : i64>) -> (tensor<1x64x14x20xbf16, 712880 : i64>, tensor<1x128x14x20xbf16, 641200 : i64>) loc(#loc800)
      %408 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc608)
      %409 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc609)
      %410 = "tpu.LutBF16"(%402, %408, %409) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x512x7x10xbf16, 569520 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x512x7x10xbf16, 0 : i64> loc(#loc610)
      %411 = "top.Weight"() : () -> tensor<1x64x1x64xbf16, 1099513645120 : i64> loc(#loc611)
      %412 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099526357840 : i64> loc(#loc612)
      %413 = "top.Weight"() : () -> tensor<1x128x3x3xbf16, 1099528192080 : i64> loc(#loc613)
      %414 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099530307920 : i64> loc(#loc614)
      %415:2 = "tpu.Group"(%407#0, %407#1) ({
        %535 = "tpu.Load"(%407#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 712880 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc617)
        %536 = "tpu.Load"(%411) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 1024, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x64xbf16, 1099513645120 : i64>) -> tensor<1x64x1x64xbf16> loc(#loc618)
        %537 = "tpu.Load"(%412) {do_bcast = false, ginfo = #tpu.lg<out_addr = 5184, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099526357840 : i64>) -> tensor<2x64x1x1xui16> loc(#loc619)
        %538 = "tpu.Load"(%407#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x14x20xbf16, 641200 : i64>) -> tensor<1x128x14x20xbf16> loc(#loc620)
        %539 = "tpu.Load"(%413) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [3], w_idx = [0], w_slice = [3], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x3x3xbf16, 1099528192080 : i64>) -> tensor<1x128x3x3xbf16> loc(#loc621)
        %540 = "tpu.Load"(%414) {do_bcast = false, ginfo = #tpu.lg<out_addr = 5120, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099530307920 : i64>) -> tensor<2x128x1x1xui16> loc(#loc622)
        %541 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x1x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc615)
        %542 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 179200 : i64> loc(#loc615)
        %543 = "tpu.Conv2D"(%538, %539, %540) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 128 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16>, tensor<1x128x3x3xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x14x20xbf16> loc(#loc616)
        %544 = "tpu.Store"(%543, %0) {ginfo = #tpu.lg<out_addr = 8192, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x14x20xbf16>, none) -> tensor<1x128x14x20xbf16, 71680 : i64> loc(#loc616)
        "tpu.Yield"(%542, %544) : (tensor<1x64x14x20xbf16, 179200 : i64>, tensor<1x128x14x20xbf16, 71680 : i64>) -> () loc(#loc801)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 712880 : i64>, tensor<1x128x14x20xbf16, 641200 : i64>) -> (tensor<1x64x14x20xbf16, 179200 : i64>, tensor<1x128x14x20xbf16, 71680 : i64>) loc(#loc801)
      %416 = "tpu.Slice"(%410, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 256, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x512x7x10xbf16, 0 : i64>, none, none, none, none) -> tensor<1x256x7x10xbf16, 0 : i64> loc(#loc623)
      %417 = "tpu.Slice"(%410, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 512, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 256, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x512x7x10xbf16, 0 : i64>, none, none, none, none) -> tensor<1x256x7x10xbf16, 35840 : i64> loc(#loc624)
      %418 = "top.Weight"() : () -> tensor<1x128x1x256xbf16, 1099513579584 : i64> loc(#loc625)
      %419 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099513579072 : i64> loc(#loc626)
      %420 = "top.Weight"() : () -> tensor<1x128x1x256xbf16, 1099516700752 : i64> loc(#loc627)
      %421 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099523263120 : i64> loc(#loc628)
      %422:2 = "tpu.Group"(%417) ({
        %535 = "tpu.Load"(%418) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 8192, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [256], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x256xbf16, 1099513579584 : i64>) -> tensor<1x128x1x256xbf16> loc(#loc631)
        %536 = "tpu.Load"(%419) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20992, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099513579072 : i64>) -> tensor<2x128x1x1xui16> loc(#loc632)
        %537 = "tpu.Load"(%417) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x256x7x10xbf16, 35840 : i64>) -> tensor<1x256x7x10xbf16> loc(#loc633)
        %538 = "tpu.Load"(%420) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 8192, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [256], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x256xbf16, 1099516700752 : i64>) -> tensor<1x128x1x256xbf16> loc(#loc634)
        %539 = "tpu.Load"(%421) {do_bcast = false, ginfo = #tpu.lg<out_addr = 21056, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099523263120 : i64>) -> tensor<2x128x1x1xui16> loc(#loc635)
        %540 = "tpu.Conv2D"(%537, %535, %536) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16>, tensor<1x128x1x256xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x7x10xbf16> loc(#loc629)
        %541 = "tpu.Store"(%540, %0) {ginfo = #tpu.lg<out_addr = 28672, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 6, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x7x10xbf16>, none) -> tensor<1x128x7x10xbf16, 235200 : i64> loc(#loc629)
        %542 = "tpu.Conv2D"(%537, %538, %539) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 7, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16>, tensor<1x128x1x256xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x7x10xbf16> loc(#loc630)
        %543 = "tpu.Store"(%542, %0) {ginfo = #tpu.lg<out_addr = 24576, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 8, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x7x10xbf16>, none) -> tensor<1x128x7x10xbf16, 217280 : i64> loc(#loc630)
        "tpu.Yield"(%541, %543) : (tensor<1x128x7x10xbf16, 235200 : i64>, tensor<1x128x7x10xbf16, 217280 : i64>) -> () loc(#loc802)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 8, -2, 7, 6, 0, 1, -3, 2], group_type = 0 : i64, hsecs = 1 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x256x7x10xbf16, 35840 : i64>) -> (tensor<1x128x7x10xbf16, 235200 : i64>, tensor<1x128x7x10xbf16, 217280 : i64>) loc(#loc802)
      %423 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc636)
      %424 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc637)
      %425 = "top.Weight"() : () -> tensor<1x128x1x128xbf16, 1099513251392 : i64> loc(#loc638)
      %426 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099516256848 : i64> loc(#loc639)
      %427 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc640)
      %428 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc641)
      %429:2 = "tpu.Group"(%415#1, %422#0) ({
        %535 = "tpu.Load"(%415#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x14x20xbf16, 71680 : i64>) -> tensor<1x128x14x20xbf16> loc(#loc644)
        %536 = "tpu.Load"(%423) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11008, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc645)
        %537 = "tpu.Load"(%424) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11520, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc646)
        %538 = "tpu.Load"(%425) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4096, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [128], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x128xbf16, 1099513251392 : i64>) -> tensor<1x128x1x128xbf16> loc(#loc647)
        %539 = "tpu.Load"(%426) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12032, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099516256848 : i64>) -> tensor<2x128x1x1xui16> loc(#loc648)
        %540 = "tpu.LutBF16"(%535, %536, %537) {ginfo = #tpu.lg<out_addr = 4096, out_size = 4608, buffer_addr = 12288, buffer_size = 9216, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x14x20xbf16> loc(#loc649)
        %541 = "tpu.Load"(%422#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4], h_slice = [4, 3], w_idx = [0], w_slice = [10], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x7x10xbf16, 235200 : i64>) -> tensor<1x128x7x10xbf16> loc(#loc650)
        %542 = "tpu.Load"(%427) {do_bcast = true, ginfo = #tpu.lg<out_addr = 10496, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc651)
        %543 = "tpu.Load"(%428) {do_bcast = true, ginfo = #tpu.lg<out_addr = 9984, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc652)
        %544 = "tpu.Conv2D"(%540, %538, %539) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 9, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16>, tensor<1x128x1x128xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x14x20xbf16> loc(#loc642)
        %545 = "tpu.Store"(%544, %0) {ginfo = #tpu.lg<out_addr = 12288, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 10, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x14x20xbf16>, none) -> tensor<1x128x14x20xbf16, 271040 : i64> loc(#loc642)
        %546 = "tpu.LutBF16"(%541, %542, %543) {ginfo = #tpu.lg<out_addr = 8704, out_size = 1280, buffer_addr = 4096, buffer_size = 2560, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4], h_slice = [4, 3], w_idx = [0], w_slice = [10], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x7x10xbf16> loc(#loc643)
        %547 = "tpu.Store"(%546, %0) {ginfo = #tpu.lg<out_addr = 8704, out_size = 1280, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4], h_slice = [4, 3], w_idx = [0], w_slice = [10], id = 12, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x7x10xbf16>, none) -> tensor<1x128x7x10xbf16, 253120 : i64> loc(#loc643)
        "tpu.Yield"(%545, %547) : (tensor<1x128x14x20xbf16, 271040 : i64>, tensor<1x128x7x10xbf16, 253120 : i64>) -> () loc(#loc803)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 12, -2, 9, 6, 7, 8, -3, 11, 10, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x128x14x20xbf16, 71680 : i64>, tensor<1x128x7x10xbf16, 235200 : i64>) -> (tensor<1x128x14x20xbf16, 271040 : i64>, tensor<1x128x7x10xbf16, 253120 : i64>) loc(#loc803)
      %430 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc653)
      %431 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc654)
      %432 = "tpu.LutBF16"(%422#1, %430, %431) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 217280 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 89600 : i64> loc(#loc655)
      %433 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099513284160 : i64> loc(#loc656)
      %434 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099513250880 : i64> loc(#loc657)
      %435 = "tpu.Conv2D"(%429#1, %433, %434) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 253120 : i64>, tensor<1x128x9x128xbf16, 1099513284160 : i64>, tensor<2x128x1x1xui16, 1099513250880 : i64>) -> tensor<1x128x7x10xbf16, 107520 : i64> loc(#loc658)
      %436 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc659)
      %437 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc660)
      %438 = "top.Weight"() : () -> tensor<1x4x1x128xbf16, 1099523809040 : i64> loc(#loc661)
      %439 = "top.Weight"() : () -> tensor<2x4x1x1xui16, 1099513250864 : i64> loc(#loc662)
      %440 = "tpu.Group"(%429#0) ({
        %535 = "tpu.Load"(%429#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x14x20xbf16, 271040 : i64>) -> tensor<1x128x14x20xbf16> loc(#loc664)
        %536 = "tpu.Load"(%436) {do_bcast = true, ginfo = #tpu.lg<out_addr = 16384, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc665)
        %537 = "tpu.Load"(%437) {do_bcast = true, ginfo = #tpu.lg<out_addr = 20480, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc666)
        %538 = "tpu.Load"(%438) {do_bcast = false, ginfo = #tpu.lg<out_addr = 4896, out_size = 256, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [128], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x4x1x128xbf16, 1099523809040 : i64>) -> tensor<1x4x1x128xbf16> loc(#loc667)
        %539 = "tpu.Load"(%439) {do_bcast = false, ginfo = #tpu.lg<out_addr = 5152, out_size = 4, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x4x1x1xui16, 1099513250864 : i64>) -> tensor<2x4x1x1xui16> loc(#loc668)
        %540 = "tpu.LutBF16"(%535, %536, %537) {ginfo = #tpu.lg<out_addr = 0, out_size = 4608, buffer_addr = 20992, buffer_size = 9216, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x14x20xbf16> loc(#loc669)
        %541 = "tpu.Conv2D"(%540, %538, %539) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 4608, out_size = 288, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16>, tensor<1x4x1x128xbf16>, tensor<2x4x1x1xui16>) -> tensor<1x4x14x20xbf16> loc(#loc663)
        %542 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 4608, out_size = 288, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x4x14x20xbf16>, none) -> tensor<1x4x14x20xbf16, 215040 : i64> loc(#loc663)
        "tpu.Yield"(%542) : (tensor<1x4x14x20xbf16, 215040 : i64>) -> () loc(#loc663)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x128x14x20xbf16, 271040 : i64>) -> tensor<1x4x14x20xbf16, 215040 : i64> loc(#loc663)
      %441 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc670)
      %442 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc671)
      %443 = "tpu.LutBF16"(%435, %441, %442) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 107520 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 271040 : i64> loc(#loc672)
      %444 = "tpu.Concat"(%415#0, %440) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x14x20xbf16, 179200 : i64>, tensor<1x4x14x20xbf16, 215040 : i64>) -> tensor<1x68x14x20xbf16, 179200 : i64> loc(#loc673)
      %445 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099512955952 : i64> loc(#loc674)
      %446 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099512955440 : i64> loc(#loc675)
      %447 = "tpu.Conv2D"(%443, %445, %446) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 271040 : i64>, tensor<1x128x9x128xbf16, 1099512955952 : i64>, tensor<2x128x1x1xui16, 1099512955440 : i64>) -> tensor<1x128x7x10xbf16, 288960 : i64> loc(#loc676)
      %448 = "tpu.Reshape"(%444) {flatten_start_dim = -1 : i64, shape = [1, 68, -1]} : (tensor<1x68x14x20xbf16, 179200 : i64>) -> tensor<1x68x280xbf16, 179200 : i64> loc(#loc677)
      %449 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc678)
      %450 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc679)
      %451 = "tpu.LutBF16"(%447, %449, %450) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 288960 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 107520 : i64> loc(#loc680)
      %452 = "tpu.Add"(%429#1, %451) {do_relu = false, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x7x10xbf16, 253120 : i64>, tensor<1x128x7x10xbf16, 107520 : i64>) -> tensor<1x128x7x10xbf16, 271040 : i64> loc(#loc681)
      %453 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099512660528 : i64> loc(#loc682)
      %454 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099526998992 : i64> loc(#loc683)
      %455 = "tpu.Conv2D"(%452, %453, %454) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 271040 : i64>, tensor<1x128x9x128xbf16, 1099512660528 : i64>, tensor<2x128x1x1xui16, 1099526998992 : i64>) -> tensor<1x128x7x10xbf16, 217280 : i64> loc(#loc684)
      %456 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc685)
      %457 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc686)
      %458 = "tpu.LutBF16"(%455, %456, %457) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 217280 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 288960 : i64> loc(#loc687)
      %459 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099512365616 : i64> loc(#loc688)
      %460 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099523622416 : i64> loc(#loc689)
      %461 = "tpu.Conv2D"(%458, %459, %460) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 288960 : i64>, tensor<1x128x9x128xbf16, 1099512365616 : i64>, tensor<2x128x1x1xui16, 1099523622416 : i64>) -> tensor<1x128x7x10xbf16, 217280 : i64> loc(#loc690)
      %462 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc691)
      %463 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc692)
      %464 = "tpu.LutBF16"(%461, %462, %463) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 217280 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 288960 : i64> loc(#loc693)
      %465 = "tpu.Add"(%452, %464) {do_relu = false, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x7x10xbf16, 271040 : i64>, tensor<1x128x7x10xbf16, 288960 : i64>) -> tensor<1x128x7x10xbf16, 71680 : i64> loc(#loc694)
      %466 = "tpu.Concat"(%465, %432) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x7x10xbf16, 71680 : i64>, tensor<1x128x7x10xbf16, 89600 : i64>) -> tensor<1x256x7x10xbf16, 71680 : i64> loc(#loc695)
      %467 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x256xbf16, 1099512234544 : i64> loc(#loc696)
      %468 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099512233520 : i64> loc(#loc697)
      %469 = "tpu.Conv2D"(%466, %467, %468) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16, 71680 : i64>, tensor<1x256x1x256xbf16, 1099512234544 : i64>, tensor<2x256x1x1xui16, 1099512233520 : i64>) -> tensor<1x256x7x10xbf16, 217280 : i64> loc(#loc698)
      %470 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc699)
      %471 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc700)
      %472 = "tpu.LutBF16"(%469, %470, %471) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x7x10xbf16, 217280 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x256x7x10xbf16, 253120 : i64> loc(#loc701)
      %473 = "tpu.Concat"(%416, %417, %472) {axis = 1 : si32, do_relu = false, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x256x7x10xbf16, 0 : i64>, tensor<1x256x7x10xbf16, 35840 : i64>, tensor<1x256x7x10xbf16, 253120 : i64>) -> tensor<1x768x7x10xbf16, 71680 : i64> loc(#loc702)
      %474 = "top.Weight"() {do_compress = true} : () -> tensor<1x512x1x768xbf16, 1099520138320 : i64> loc(#loc703)
      %475 = "top.Weight"() {do_compress = true} : () -> tensor<2x512x1x1xui16, 1099512231472 : i64> loc(#loc704)
      %476 = "tpu.Conv2D"(%473, %474, %475) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x768x7x10xbf16, 71680 : i64>, tensor<1x512x1x768xbf16, 1099520138320 : i64>, tensor<2x512x1x1xui16, 1099512231472 : i64>) -> tensor<1x512x7x10xbf16, 217280 : i64> loc(#loc705)
      %477 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc706)
      %478 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc707)
      %479 = "tpu.LutBF16"(%476, %477, %478) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x512x7x10xbf16, 217280 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x512x7x10xbf16, 0 : i64> loc(#loc708)
      %480 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x512xbf16, 1099511641648 : i64> loc(#loc709)
      %481 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099511641392 : i64> loc(#loc710)
      %482 = "tpu.Conv2D"(%479, %480, %481) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x512x7x10xbf16, 0 : i64>, tensor<1x64x9x512xbf16, 1099511641648 : i64>, tensor<2x64x1x1xui16, 1099511641392 : i64>) -> tensor<1x64x7x10xbf16, 217280 : i64> loc(#loc711)
      %483 = "top.Weight"() : () -> tensor<1x512x3x3xbf16, 1099511632176 : i64> loc(#loc712)
      %484 = "top.Weight"() : () -> tensor<2x512x1x1xui16, 1099511630128 : i64> loc(#loc713)
      %485 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc714)
      %486 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc715)
      %487:2 = "tpu.Group"(%479, %482) ({
        %535 = "tpu.Load"(%479) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [512], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x512x7x10xbf16, 0 : i64>) -> tensor<1x512x7x10xbf16> loc(#loc718)
        %536 = "tpu.Load"(%483) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 2048, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [512], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [3], w_idx = [0], w_slice = [3], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x512x3x3xbf16, 1099511632176 : i64>) -> tensor<1x512x3x3xbf16> loc(#loc719)
        %537 = "tpu.Load"(%484) {do_bcast = false, ginfo = #tpu.lg<out_addr = 11392, out_size = 256, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [512], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x512x1x1xui16, 1099511630128 : i64>) -> tensor<2x512x1x1xui16> loc(#loc720)
        %538 = "tpu.Load"(%482) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x7x10xbf16, 217280 : i64>) -> tensor<1x64x7x10xbf16> loc(#loc721)
        %539 = "tpu.Load"(%485) {do_bcast = true, ginfo = #tpu.lg<out_addr = 10368, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc722)
        %540 = "tpu.Load"(%486) {do_bcast = true, ginfo = #tpu.lg<out_addr = 10880, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc723)
        %541 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [512], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 512 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x512x7x10xbf16>, tensor<1x512x3x3xbf16>, tensor<2x512x1x1xui16>) -> tensor<1x512x7x10xbf16> loc(#loc716)
        %542 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [512], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x512x7x10xbf16>, none) -> tensor<1x512x7x10xbf16, 71680 : i64> loc(#loc716)
        %543 = "tpu.LutBF16"(%538, %539, %540) {ginfo = #tpu.lg<out_addr = 9216, out_size = 1152, buffer_addr = 21504, buffer_size = 2304, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x7x10xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x7x10xbf16> loc(#loc717)
        %544 = "tpu.Store"(%543, %0) {ginfo = #tpu.lg<out_addr = 9216, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x7x10xbf16>, none) -> tensor<1x64x7x10xbf16, 226240 : i64> loc(#loc717)
        "tpu.Yield"(%542, %544) : (tensor<1x512x7x10xbf16, 71680 : i64>, tensor<1x64x7x10xbf16, 226240 : i64>) -> () loc(#loc804)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 1 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x512x7x10xbf16, 0 : i64>, tensor<1x64x7x10xbf16, 217280 : i64>) -> (tensor<1x512x7x10xbf16, 71680 : i64>, tensor<1x64x7x10xbf16, 226240 : i64>) loc(#loc804)
      %488 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc724)
      %489 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc725)
      %490 = "tpu.LutBF16"(%487#0, %488, %489) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x512x7x10xbf16, 71680 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x512x7x10xbf16, 235200 : i64> loc(#loc726)
      %491 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x64xbf16, 1099528118352 : i64> loc(#loc727)
      %492 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099511629872 : i64> loc(#loc728)
      %493 = "tpu.Conv2D"(%487#1, %491, %492) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x7x10xbf16, 226240 : i64>, tensor<1x64x9x64xbf16, 1099528118352 : i64>, tensor<2x64x1x1xui16, 1099511629872 : i64>) -> tensor<1x64x7x10xbf16, 0 : i64> loc(#loc729)
      %494 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x1x512xbf16, 1099524996624 : i64> loc(#loc730)
      %495 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099511629360 : i64> loc(#loc731)
      %496 = "tpu.Conv2D"(%490, %494, %495) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x512x7x10xbf16, 235200 : i64>, tensor<1x128x1x512xbf16, 1099524996624 : i64>, tensor<2x128x1x1xui16, 1099511629360 : i64>) -> tensor<1x128x7x10xbf16, 8960 : i64> loc(#loc732)
      %497 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc733)
      %498 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc734)
      %499 = "tpu.LutBF16"(%493, %497, %498) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x7x10xbf16, 0 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x64x7x10xbf16, 26880 : i64> loc(#loc735)
      %500 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc736)
      %501 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc737)
      %502 = "tpu.LutBF16"(%496, %500, %501) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 8960 : i64>, tensor<1x1x32x8xbf16, 1099528345936 : i64>, tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x128x7x10xbf16, 35840 : i64> loc(#loc738)
      %503 = "top.Weight"() : () -> tensor<1x64x1x64xbf16, 1099517261648 : i64> loc(#loc739)
      %504 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099523807760 : i64> loc(#loc740)
      %505 = "top.Weight"() : () -> tensor<1x128x3x3xbf16, 1099530174032 : i64> loc(#loc741)
      %506 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099516059712 : i64> loc(#loc742)
      %507 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc743)
      %508 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc744)
      %509 = "top.Weight"() : () -> tensor<1x128x1x128xbf16, 1099517303888 : i64> loc(#loc745)
      %510 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099511628848 : i64> loc(#loc746)
      %511 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528345936 : i64> loc(#loc747)
      %512 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099522697360 : i64> loc(#loc748)
      %513 = "top.Weight"() : () -> tensor<1x4x1x128xbf16, 1099517302608 : i64> loc(#loc749)
      %514 = "top.Weight"() : () -> tensor<2x4x1x1xui16, 1099511628832 : i64> loc(#loc750)
      %515:2 = "tpu.Group"(%499, %502) ({
        %535 = "tpu.Load"(%499) {do_bcast = false, ginfo = #tpu.lg<out_addr = 4096, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x7x10xbf16, 26880 : i64>) -> tensor<1x64x7x10xbf16> loc(#loc753)
        %536 = "tpu.Load"(%503) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 1024, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x64xbf16, 1099517261648 : i64>) -> tensor<1x64x1x64xbf16> loc(#loc754)
        %537 = "tpu.Load"(%504) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099523807760 : i64>) -> tensor<2x64x1x1xui16> loc(#loc755)
        %538 = "tpu.Load"(%502) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x7x10xbf16, 35840 : i64>) -> tensor<1x128x7x10xbf16> loc(#loc756)
        %539 = "tpu.Load"(%505) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [3], w_idx = [0], w_slice = [3], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x3x3xbf16, 1099530174032 : i64>) -> tensor<1x128x3x3xbf16> loc(#loc757)
        %540 = "tpu.Load"(%506) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099516059712 : i64>) -> tensor<2x128x1x1xui16> loc(#loc758)
        %541 = "tpu.Conv2D"(%535, %536, %537) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x7x10xbf16>, tensor<1x64x1x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x7x10xbf16> loc(#loc751)
        %542 = "tpu.Load"(%507) {do_bcast = true, ginfo = #tpu.lg<out_addr = 12288, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc759)
        %543 = "tpu.Load"(%508) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc760)
        %544 = "tpu.Store"(%541, %0) {ginfo = #tpu.lg<out_addr = 8192, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 9, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x7x10xbf16>, none) -> tensor<1x64x7x10xbf16, 53760 : i64> loc(#loc751)
        %545 = "tpu.Conv2D"(%538, %539, %540) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 4096, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 10, stage = 1, slice_idx = 0, group_type = 0>, group = 128 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16>, tensor<1x128x3x3xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x7x10xbf16> loc(#loc761)
        %546 = "tpu.Load"(%509) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4096, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [128], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x128xbf16, 1099517303888 : i64>) -> tensor<1x128x1x128xbf16> loc(#loc762)
        %547 = "tpu.Load"(%510) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 12, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099511628848 : i64>) -> tensor<2x128x1x1xui16> loc(#loc763)
        %548 = "tpu.LutBF16"(%545, %542, %543) {ginfo = #tpu.lg<out_addr = 8192, out_size = 2304, buffer_addr = 16384, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 13, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x7x10xbf16> loc(#loc764)
        %549 = "tpu.Load"(%511) {do_bcast = true, ginfo = #tpu.lg<out_addr = 12288, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 14, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099528345936 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc765)
        %550 = "tpu.Load"(%512) {do_bcast = true, ginfo = #tpu.lg<out_addr = 16384, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 15, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099522697360 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc766)
        %551 = "tpu.Conv2D"(%548, %546, %547) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 4096, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 16, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16>, tensor<1x128x1x128xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x7x10xbf16> loc(#loc767)
        %552 = "tpu.Load"(%513) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 256, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [128], id = 17, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x4x1x128xbf16, 1099517302608 : i64>) -> tensor<1x4x1x128xbf16> loc(#loc768)
        %553 = "tpu.Load"(%514) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 4, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 18, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x4x1x1xui16, 1099511628832 : i64>) -> tensor<2x4x1x1xui16> loc(#loc769)
        %554 = "tpu.LutBF16"(%551, %549, %550) {ginfo = #tpu.lg<out_addr = 0, out_size = 2304, buffer_addr = 24576, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 19, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x7x10xbf16> loc(#loc770)
        %555 = "tpu.Conv2D"(%554, %552, %553) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16896, out_size = 144, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 20, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16>, tensor<1x4x1x128xbf16>, tensor<2x4x1x1xui16>) -> tensor<1x4x7x10xbf16> loc(#loc752)
        %556 = "tpu.Store"(%555, %0) {ginfo = #tpu.lg<out_addr = 16896, out_size = 144, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 21, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x4x7x10xbf16>, none) -> tensor<1x4x7x10xbf16, 62720 : i64> loc(#loc752)
        "tpu.Yield"(%544, %556) : (tensor<1x64x7x10xbf16, 53760 : i64>, tensor<1x4x7x10xbf16, 62720 : i64>) -> () loc(#loc805)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 21, -2, 10, 7, 8, 9, -3, 13, 11, 12, -4, 16, 14, 15, -5, 19, 17, 18, -6, 20, 0, 1, 2], group_type = 0 : i64, hsecs = 1 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x7x10xbf16, 26880 : i64>, tensor<1x128x7x10xbf16, 35840 : i64>) -> (tensor<1x64x7x10xbf16, 53760 : i64>, tensor<1x4x7x10xbf16, 62720 : i64>) loc(#loc805)
      %516 = "tpu.Concat"(%515#0, %515#1) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x7x10xbf16, 53760 : i64>, tensor<1x4x7x10xbf16, 62720 : i64>) -> tensor<1x68x7x10xbf16, 53760 : i64> loc(#loc771)
      %517 = "tpu.Reshape"(%516) {flatten_start_dim = -1 : i64, shape = [1, 68, -1]} : (tensor<1x68x7x10xbf16, 53760 : i64>) -> tensor<1x68x70xbf16, 53760 : i64> loc(#loc772)
      %518 = "tpu.Concat"(%369, %448, %517) {axis = 2 : si32, do_relu = false, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x68x1120xbf16, 417200 : i64>, tensor<1x68x280xbf16, 179200 : i64>, tensor<1x68x70xbf16, 53760 : i64>) -> tensor<1x68x1470xbf16, 217280 : i64> loc(#loc773)
      %519 = "tpu.Slice"(%518, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 64, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0], steps = [1, 1, 1]} : (tensor<1x68x1470xbf16, 217280 : i64>, none, none, none, none) -> tensor<1x64x1470xbf16, 217280 : i64> loc(#loc774)
      %520 = "tpu.Slice"(%518, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 68, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 64, 0], steps = [1, 1, 1]} : (tensor<1x68x1470xbf16, 217280 : i64>, none, none, none, none) -> tensor<1x4x1470xbf16, 405440 : i64> loc(#loc775)
      %521 = "tpu.Reshape"(%519) {flatten_start_dim = -1 : i64, shape = [1, 4, 16, 1470]} : (tensor<1x64x1470xbf16, 217280 : i64>) -> tensor<1x4x16x1470xbf16, 217280 : i64> loc(#loc776)
      %522 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099511628320 : i64> loc(#loc777)
      %523 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099511627808 : i64> loc(#loc778)
      %524 = "tpu.LutBF16"(%520, %522, %523) {bias = 0.000000e+00 : f64, log = false, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64, scale = 1.000000e+00 : f64} : (tensor<1x4x1470xbf16, 405440 : i64>, tensor<1x1x32x8xbf16, 1099511628320 : i64>, tensor<1x1x32x8xbf16, 1099511627808 : i64>) -> tensor<1x4x1470xbf16, 0 : i64> loc(#loc779)
      %525 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099528117584 : i64> loc(#loc780)
      %526 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099526697936 : i64> loc(#loc781)
      %527 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099526431824 : i64> loc(#loc782)
      %528 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099527920464 : i64> loc(#loc783)
      %529 = "tpu.Softmax"(%521, %525, %526, %527, %528, %0) {axis = 2 : si32, beta = 1.000000e+00 : f64, log = false, round_mode = #tpu<round_mode HalfAwayFromZero>} : (tensor<1x4x16x1470xbf16, 217280 : i64>, tensor<1x1x32x8xbf16, 1099528117584 : i64>, tensor<1x1x32x8xbf16, 1099526697936 : i64>, tensor<1x1x32x8xbf16, 1099526431824 : i64>, tensor<1x1x32x8xbf16, 1099527920464 : i64>, none) -> tensor<1x4x16x1470xbf16, 11760 : i64> loc(#loc784)
      %530 = "tpu.Permute"(%529, %0) {order = [0, 2, 1, 3]} : (tensor<1x4x16x1470xbf16, 11760 : i64>, none) -> tensor<1x16x4x1470xbf16, 199920 : i64> loc(#loc785)
      %531 = "top.Weight"() {do_compress = true} : () -> tensor<1x1x1x16xbf16, 1099511627776 : i64> loc(#loc786)
      %532 = "tpu.Conv2D"(%530, %531, %0) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = false} : (tensor<1x16x4x1470xbf16, 199920 : i64>, tensor<1x1x1x16xbf16, 1099511627776 : i64>, none) -> tensor<1x1x4x1470xbf16, 11760 : i64> loc(#loc787)
      %533 = "tpu.Cast"(%524) {round_mode = #tpu<round_mode HalfAwayFromZero>, with_scale = true} : (tensor<1x4x1470xbf16, 0 : i64>) -> tensor<1x4x1470xf32, 4398046511104 : i64> loc(#loc788)
      %534 = "tpu.Cast"(%532) {round_mode = #tpu<round_mode HalfAwayFromZero>, with_scale = true} : (tensor<1x1x4x1470xbf16, 11760 : i64>) -> tensor<1x1x4x1470xf32, 5497558138880 : i64> loc(#loc789)
      return %534, %533 : tensor<1x1x4x1470xf32, 5497558138880 : i64>, tensor<1x4x1470xf32, 4398046511104 : i64> loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("images/model.0/conv/Conv_output_0_Conv_bf16")
#loc3 = loc("/model.0/conv/Conv_output_0_Conv_filter_reordered")
#loc4 = loc("/model.0/conv/Conv_output_0_Conv_bias_reordered")
#loc5 = loc("/model.0/act/Mul_output_0_Mul/model.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc6 = loc("/model.0/act/Mul_output_0_Mul/model.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc7 = loc("/model.0/act/Mul_output_0_Mul")
#loc8 = loc("load_images/model.0/conv/Conv_output_0_Conv_bf16")
#loc9 = loc("load_/model.0/conv/Conv_output_0_Conv_filter_reordered")
#loc10 = loc("load_/model.0/conv/Conv_output_0_Conv_bias_reordered")
#loc11 = loc("load_/model.0/act/Mul_output_0_Mul/model.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc12 = loc("load_/model.0/act/Mul_output_0_Mul/model.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc13 = loc("/model.0/conv/Conv_output_0_Conv")
#loc14 = loc("/model.1/conv/Conv_output_0_Conv_filter_reordered")
#loc15 = loc("/model.1/conv/Conv_output_0_Conv_bias_reordered")
#loc16 = loc("/model.1/act/Mul_output_0_Mul/model.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc17 = loc("/model.1/act/Mul_output_0_Mul/model.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc18 = loc("/model.1/act/Mul_output_0_Mul")
#loc19 = loc("load_/model.0/act/Mul_output_0_Mul")
#loc20 = loc("load_/model.1/conv/Conv_output_0_Conv_filter_reordered")
#loc21 = loc("load_/model.1/conv/Conv_output_0_Conv_bias_reordered")
#loc22 = loc("load_/model.1/act/Mul_output_0_Mul/model.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc23 = loc("load_/model.1/act/Mul_output_0_Mul/model.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc24 = loc("/model.1/conv/Conv_output_0_Conv")
#loc25 = loc("/model.2/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc26 = loc("/model.2/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc27 = loc("/model.2/cv1/act/Mul_output_0_Mul/model.2/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc28 = loc("/model.2/cv1/act/Mul_output_0_Mul/model.2/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc29 = loc("/model.2/cv1/act/Mul_output_0_Mul")
#loc30 = loc("load_/model.1/act/Mul_output_0_Mul")
#loc31 = loc("load_/model.2/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc32 = loc("load_/model.2/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc33 = loc("load_/model.2/cv1/act/Mul_output_0_Mul/model.2/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc34 = loc("load_/model.2/cv1/act/Mul_output_0_Mul/model.2/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc35 = loc("/model.2/cv1/conv/Conv_output_0_Conv")
#loc36 = loc("/model.2/Split_output_0_Split")
#loc37 = loc("/model.2/Split_output_1_Split")
#loc38 = loc("/model.2/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc39 = loc("/model.2/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc40 = loc("/model.2/m.0/cv1/conv/Conv_output_0_Conv")
#loc41 = loc("/model.2/m.0/cv1/act/Mul_output_0_Mul/model.2/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc42 = loc("/model.2/m.0/cv1/act/Mul_output_0_Mul/model.2/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc43 = loc("/model.2/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc44 = loc("/model.2/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc45 = loc("/model.2/m.0/cv2/act/Mul_output_0_Mul/model.2/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc46 = loc("/model.2/m.0/cv2/act/Mul_output_0_Mul/model.2/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc47 = loc("/model.2/m.0/cv2/act/Mul_output_0_Mul")
#loc48 = loc("load_/model.2/m.0/cv1/conv/Conv_output_0_Conv")
#loc49 = loc("load_/model.2/m.0/cv1/act/Mul_output_0_Mul/model.2/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc50 = loc("load_/model.2/m.0/cv1/act/Mul_output_0_Mul/model.2/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc51 = loc("load_/model.2/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc52 = loc("load_/model.2/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc53 = loc("/model.2/m.0/cv1/act/Mul_output_0_Mul")
#loc54 = loc("load_/model.2/m.0/cv2/act/Mul_output_0_Mul/model.2/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc55 = loc("load_/model.2/m.0/cv2/act/Mul_output_0_Mul/model.2/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc56 = loc("/model.2/m.0/cv2/conv/Conv_output_0_Conv")
#loc57 = loc("/model.2/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc58 = loc("/model.2/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc59 = loc("/model.2/cv2/act/Mul_output_0_Mul/model.2/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc60 = loc("/model.2/cv2/act/Mul_output_0_Mul/model.2/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc61 = loc("/model.2/cv2/act/Mul_output_0_Mul")
#loc62 = loc("load_/model.2/Split_output_1_Split")
#loc63 = loc("load_/model.2/m.0/cv2/act/Mul_output_0_Mul")
#loc64 = loc("load_/model.2/Split_output_0_Split")
#loc65 = loc("/model.2/m.0/Add_output_0_Add")
#loc66 = loc("load_/model.2/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc67 = loc("load_/model.2/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc68 = loc("/model.2/Concat_output_0_Concat")
#loc69 = loc("load_/model.2/cv2/act/Mul_output_0_Mul/model.2/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc70 = loc("load_/model.2/cv2/act/Mul_output_0_Mul/model.2/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc71 = loc("/model.2/cv2/conv/Conv_output_0_Conv")
#loc72 = loc("/model.3/conv/Conv_output_0_Conv_filter_reordered")
#loc73 = loc("/model.3/conv/Conv_output_0_Conv_bias_reordered")
#loc74 = loc("/model.3/conv/Conv_output_0_Conv")
#loc75 = loc("/model.3/act/Mul_output_0_Mul/model.3/act/Mul_output_0_Mul_slope_table_bf16")
#loc76 = loc("/model.3/act/Mul_output_0_Mul/model.3/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc77 = loc("/model.3/act/Mul_output_0_Mul")
#loc78 = loc("/model.4/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc79 = loc("/model.4/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc80 = loc("/model.4/cv1/conv/Conv_output_0_Conv")
#loc81 = loc("/model.4/cv1/act/Mul_output_0_Mul/model.4/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc82 = loc("/model.4/cv1/act/Mul_output_0_Mul/model.4/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc83 = loc("/model.4/cv1/act/Mul_output_0_Mul")
#loc84 = loc("/model.4/Split_output_0_Split")
#loc85 = loc("/model.4/Split_output_1_Split")
#loc86 = loc("/model.4/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc87 = loc("/model.4/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc88 = loc("/model.4/m.0/cv1/conv/Conv_output_0_Conv")
#loc89 = loc("/model.4/m.0/cv1/act/Mul_output_0_Mul/model.4/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc90 = loc("/model.4/m.0/cv1/act/Mul_output_0_Mul/model.4/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc91 = loc("/model.4/m.0/cv1/act/Mul_output_0_Mul")
#loc92 = loc("/model.4/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc93 = loc("/model.4/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc94 = loc("/model.4/m.0/cv2/act/Mul_output_0_Mul/model.4/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc95 = loc("/model.4/m.0/cv2/act/Mul_output_0_Mul/model.4/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc96 = loc("/model.4/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc97 = loc("/model.4/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc98 = loc("/model.4/cv2/conv/Conv_output_0_Conv")
#loc99 = loc("load_/model.4/m.0/cv1/act/Mul_output_0_Mul")
#loc100 = loc("load_/model.4/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc101 = loc("load_/model.4/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc102 = loc("load_/model.4/m.0/cv2/act/Mul_output_0_Mul/model.4/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc103 = loc("load_/model.4/m.0/cv2/act/Mul_output_0_Mul/model.4/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc104 = loc("/model.4/m.0/cv2/conv/Conv_output_0_Conv")
#loc105 = loc("load_/model.4/Split_output_1_Split")
#loc106 = loc("/model.4/m.0/cv2/act/Mul_output_0_Mul")
#loc107 = loc("load_/model.4/Split_output_0_Split")
#loc108 = loc("/model.4/m.0/Add_output_0_Add")
#loc109 = loc("load_/model.4/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc110 = loc("load_/model.4/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc111 = loc("/model.4/Concat_output_0_Concat")
#loc112 = loc("/model.4/cv2/act/Mul_output_0_Mul/model.4/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc113 = loc("/model.4/cv2/act/Mul_output_0_Mul/model.4/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc114 = loc("/model.4/cv2/act/Mul_output_0_Mul")
#loc115 = loc("/model.5/conv/Conv_output_0_Conv_filter_reordered")
#loc116 = loc("/model.5/conv/Conv_output_0_Conv_bias_reordered")
#loc117 = loc("/model.5/conv/Conv_output_0_Conv")
#loc118 = loc("/model.5/act/Mul_output_0_Mul/model.5/act/Mul_output_0_Mul_slope_table_bf16")
#loc119 = loc("/model.5/act/Mul_output_0_Mul/model.5/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc120 = loc("/model.5/act/Mul_output_0_Mul")
#loc121 = loc("/model.6/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc122 = loc("/model.6/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc123 = loc("/model.6/cv1/conv/Conv_output_0_Conv")
#loc124 = loc("/model.6/cv1/act/Mul_output_0_Mul/model.6/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc125 = loc("/model.6/cv1/act/Mul_output_0_Mul/model.6/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc126 = loc("/model.6/cv1/act/Mul_output_0_Mul")
#loc127 = loc("/model.6/Split_output_0_Split")
#loc128 = loc("/model.6/Split_output_1_Split")
#loc129 = loc("/model.6/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc130 = loc("/model.6/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc131 = loc("/model.6/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc132 = loc("/model.6/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc133 = loc("/model.6/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc134 = loc("/model.6/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc135 = loc("/model.6/m.0/cv2/conv/Conv_output_0_Conv")
#loc136 = loc("/model.6/m.0/cv1/act/Mul_output_0_Mul")
#loc137 = loc("load_/model.6/Split_output_1_Split")
#loc138 = loc("load_/model.6/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc139 = loc("load_/model.6/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc140 = loc("load_/model.6/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc141 = loc("load_/model.6/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc142 = loc("/model.6/m.0/cv1/conv/Conv_output_0_Conv")
#loc143 = loc("load_/model.6/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc144 = loc("load_/model.6/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc145 = loc("/model.6/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc146 = loc("/model.6/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc147 = loc("/model.6/m.0/m/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc148 = loc("/model.6/m.0/m/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc149 = loc("/model.6/m.0/m/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/m/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc150 = loc("/model.6/m.0/m/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/m/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc151 = loc("/model.6/m.0/cv2/act/Mul_output_0_Mul")
#loc152 = loc("/model.6/m.0/m/m.0/cv1/act/Mul_output_0_Mul")
#loc153 = loc("load_/model.6/m.0/cv2/conv/Conv_output_0_Conv")
#loc154 = loc("load_/model.6/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc155 = loc("load_/model.6/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc156 = loc("load_/model.6/m.0/cv1/act/Mul_output_0_Mul")
#loc157 = loc("load_/model.6/m.0/m/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc158 = loc("load_/model.6/m.0/m/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc159 = loc("load_/model.6/m.0/m/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/m/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc160 = loc("load_/model.6/m.0/m/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/m/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc161 = loc("/model.6/m.0/m/m.0/cv1/conv/Conv_output_0_Conv")
#loc162 = loc("/model.6/m.0/m/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc163 = loc("/model.6/m.0/m/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc164 = loc("/model.6/m.0/m/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/m/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc165 = loc("/model.6/m.0/m/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/m/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc166 = loc("/model.6/m.0/m/m.0/Add_output_0_Add")
#loc167 = loc("load_/model.6/m.0/m/m.0/cv1/act/Mul_output_0_Mul")
#loc168 = loc("load_/model.6/m.0/m/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc169 = loc("load_/model.6/m.0/m/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc170 = loc("load_/model.6/m.0/m/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/m/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc171 = loc("load_/model.6/m.0/m/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/m/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc172 = loc("/model.6/m.0/m/m.0/cv2/conv/Conv_output_0_Conv")
#loc173 = loc("/model.6/m.0/m/m.0/cv2/act/Mul_output_0_Mul")
#loc174 = loc("/model.6/m.0/m/m.1/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc175 = loc("/model.6/m.0/m/m.1/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc176 = loc("/model.6/m.0/m/m.1/cv1/act/Mul_output_0_Mul/model.6/m.0/m/m.1/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc177 = loc("/model.6/m.0/m/m.1/cv1/act/Mul_output_0_Mul/model.6/m.0/m/m.1/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc178 = loc("/model.6/m.0/m/m.1/cv1/act/Mul_output_0_Mul")
#loc179 = loc("load_/model.6/m.0/m/m.0/Add_output_0_Add")
#loc180 = loc("load_/model.6/m.0/m/m.1/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc181 = loc("load_/model.6/m.0/m/m.1/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc182 = loc("load_/model.6/m.0/m/m.1/cv1/act/Mul_output_0_Mul/model.6/m.0/m/m.1/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc183 = loc("load_/model.6/m.0/m/m.1/cv1/act/Mul_output_0_Mul/model.6/m.0/m/m.1/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc184 = loc("/model.6/m.0/m/m.1/cv1/conv/Conv_output_0_Conv")
#loc185 = loc("/model.6/m.0/m/m.1/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc186 = loc("/model.6/m.0/m/m.1/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc187 = loc("/model.6/m.0/m/m.1/cv2/act/Mul_output_0_Mul/model.6/m.0/m/m.1/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc188 = loc("/model.6/m.0/m/m.1/cv2/act/Mul_output_0_Mul/model.6/m.0/m/m.1/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc189 = loc("/model.6/m.0/m/m.1/cv2/act/Mul_output_0_Mul")
#loc190 = loc("load_/model.6/m.0/m/m.1/cv1/act/Mul_output_0_Mul")
#loc191 = loc("load_/model.6/m.0/m/m.1/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc192 = loc("load_/model.6/m.0/m/m.1/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc193 = loc("load_/model.6/m.0/m/m.1/cv2/act/Mul_output_0_Mul/model.6/m.0/m/m.1/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc194 = loc("load_/model.6/m.0/m/m.1/cv2/act/Mul_output_0_Mul/model.6/m.0/m/m.1/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc195 = loc("/model.6/m.0/m/m.1/cv2/conv/Conv_output_0_Conv")
#loc196 = loc("/model.6/m.0/cv3/conv/Conv_output_0_Conv_filter_reordered")
#loc197 = loc("/model.6/m.0/cv3/conv/Conv_output_0_Conv_bias_reordered")
#loc198 = loc("/model.6/m.0/cv3/act/Mul_output_0_Mul/model.6/m.0/cv3/act/Mul_output_0_Mul_slope_table_bf16")
#loc199 = loc("/model.6/m.0/cv3/act/Mul_output_0_Mul/model.6/m.0/cv3/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc200 = loc("/model.6/m.0/cv3/act/Mul_output_0_Mul")
#loc201 = loc("load_/model.6/m.0/m/m.1/cv2/act/Mul_output_0_Mul")
#loc202 = loc("load_/model.6/m.0/cv2/act/Mul_output_0_Mul")
#loc203 = loc("/model.6/m.0/m/m.1/Add_output_0_Add")
#loc204 = loc("load_/model.6/m.0/cv3/conv/Conv_output_0_Conv_filter_reordered")
#loc205 = loc("load_/model.6/m.0/cv3/conv/Conv_output_0_Conv_bias_reordered")
#loc206 = loc("/model.6/m.0/Concat_output_0_Concat")
#loc207 = loc("load_/model.6/m.0/cv3/act/Mul_output_0_Mul/model.6/m.0/cv3/act/Mul_output_0_Mul_slope_table_bf16")
#loc208 = loc("load_/model.6/m.0/cv3/act/Mul_output_0_Mul/model.6/m.0/cv3/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc209 = loc("/model.6/m.0/cv3/conv/Conv_output_0_Conv")
#loc210 = loc("/model.6/Concat_output_0_Concat")
#loc211 = loc("/model.6/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc212 = loc("/model.6/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc213 = loc("/model.6/cv2/conv/Conv_output_0_Conv")
#loc214 = loc("/model.6/cv2/act/Mul_output_0_Mul/model.6/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc215 = loc("/model.6/cv2/act/Mul_output_0_Mul/model.6/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc216 = loc("/model.6/cv2/act/Mul_output_0_Mul")
#loc217 = loc("/model.7/conv/Conv_output_0_Conv_filter_reordered")
#loc218 = loc("/model.7/conv/Conv_output_0_Conv_bias_reordered")
#loc219 = loc("/model.7/conv/Conv_output_0_Conv")
#loc220 = loc("/model.7/act/Mul_output_0_Mul/model.7/act/Mul_output_0_Mul_slope_table_bf16")
#loc221 = loc("/model.7/act/Mul_output_0_Mul/model.7/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc222 = loc("/model.7/act/Mul_output_0_Mul")
#loc223 = loc("/model.8/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc224 = loc("/model.8/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc225 = loc("/model.8/cv1/conv/Conv_output_0_Conv")
#loc226 = loc("/model.8/cv1/act/Mul_output_0_Mul/model.8/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc227 = loc("/model.8/cv1/act/Mul_output_0_Mul/model.8/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc228 = loc("/model.8/cv1/act/Mul_output_0_Mul")
#loc229 = loc("/model.8/Split_output_0_Split")
#loc230 = loc("/model.8/Split_output_1_Split")
#loc231 = loc("/model.8/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc232 = loc("/model.8/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc233 = loc("/model.8/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc234 = loc("/model.8/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc235 = loc("/model.8/m.0/cv1/conv/Conv_output_0_Conv")
#loc236 = loc("/model.8/m.0/cv2/conv/Conv_output_0_Conv")
#loc237 = loc("load_/model.8/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc238 = loc("load_/model.8/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc239 = loc("load_/model.8/Split_output_1_Split")
#loc240 = loc("load_/model.8/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc241 = loc("load_/model.8/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc242 = loc("/model.8/m.0/cv1/act/Mul_output_0_Mul/model.8/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc243 = loc("/model.8/m.0/cv1/act/Mul_output_0_Mul/model.8/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc244 = loc("/model.8/m.0/cv1/act/Mul_output_0_Mul")
#loc245 = loc("/model.8/m.0/cv2/act/Mul_output_0_Mul/model.8/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc246 = loc("/model.8/m.0/cv2/act/Mul_output_0_Mul/model.8/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc247 = loc("/model.8/m.0/cv2/act/Mul_output_0_Mul")
#loc248 = loc("/model.8/m.0/m/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc249 = loc("/model.8/m.0/m/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc250 = loc("/model.8/m.0/m/m.0/cv1/conv/Conv_output_0_Conv")
#loc251 = loc("/model.8/m.0/m/m.0/cv1/act/Mul_output_0_Mul/model.8/m.0/m/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc252 = loc("/model.8/m.0/m/m.0/cv1/act/Mul_output_0_Mul/model.8/m.0/m/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc253 = loc("/model.8/m.0/m/m.0/cv1/act/Mul_output_0_Mul")
#loc254 = loc("/model.8/m.0/m/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc255 = loc("/model.8/m.0/m/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc256 = loc("/model.8/m.0/m/m.0/cv2/conv/Conv_output_0_Conv")
#loc257 = loc("/model.8/m.0/m/m.0/cv2/act/Mul_output_0_Mul/model.8/m.0/m/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc258 = loc("/model.8/m.0/m/m.0/cv2/act/Mul_output_0_Mul/model.8/m.0/m/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc259 = loc("/model.8/m.0/m/m.0/cv2/act/Mul_output_0_Mul")
#loc260 = loc("/model.8/m.0/m/m.0/Add_output_0_Add")
#loc261 = loc("/model.8/m.0/m/m.1/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc262 = loc("/model.8/m.0/m/m.1/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc263 = loc("/model.8/m.0/m/m.1/cv1/conv/Conv_output_0_Conv")
#loc264 = loc("/model.8/m.0/m/m.1/cv1/act/Mul_output_0_Mul/model.8/m.0/m/m.1/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc265 = loc("/model.8/m.0/m/m.1/cv1/act/Mul_output_0_Mul/model.8/m.0/m/m.1/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc266 = loc("/model.8/m.0/m/m.1/cv1/act/Mul_output_0_Mul")
#loc267 = loc("/model.8/m.0/m/m.1/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc268 = loc("/model.8/m.0/m/m.1/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc269 = loc("/model.8/m.0/m/m.1/cv2/conv/Conv_output_0_Conv")
#loc270 = loc("/model.8/m.0/m/m.1/cv2/act/Mul_output_0_Mul/model.8/m.0/m/m.1/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc271 = loc("/model.8/m.0/m/m.1/cv2/act/Mul_output_0_Mul/model.8/m.0/m/m.1/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc272 = loc("/model.8/m.0/m/m.1/cv2/act/Mul_output_0_Mul")
#loc273 = loc("/model.8/m.0/m/m.1/Add_output_0_Add")
#loc274 = loc("/model.8/m.0/Concat_output_0_Concat")
#loc275 = loc("/model.8/m.0/cv3/conv/Conv_output_0_Conv_filter_reordered")
#loc276 = loc("/model.8/m.0/cv3/conv/Conv_output_0_Conv_bias_reordered")
#loc277 = loc("/model.8/m.0/cv3/conv/Conv_output_0_Conv")
#loc278 = loc("/model.8/m.0/cv3/act/Mul_output_0_Mul/model.8/m.0/cv3/act/Mul_output_0_Mul_slope_table_bf16")
#loc279 = loc("/model.8/m.0/cv3/act/Mul_output_0_Mul/model.8/m.0/cv3/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc280 = loc("/model.8/m.0/cv3/act/Mul_output_0_Mul")
#loc281 = loc("/model.8/Concat_output_0_Concat")
#loc282 = loc("/model.8/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc283 = loc("/model.8/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc284 = loc("/model.8/cv2/conv/Conv_output_0_Conv")
#loc285 = loc("/model.8/cv2/act/Mul_output_0_Mul/model.8/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc286 = loc("/model.8/cv2/act/Mul_output_0_Mul/model.8/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc287 = loc("/model.8/cv2/act/Mul_output_0_Mul")
#loc288 = loc("/model.9/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc289 = loc("/model.9/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc290 = loc("/model.9/cv1/conv/Conv_output_0_Conv")
#loc291 = loc("/model.9/cv1/act/Mul_output_0_Mul/model.9/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc292 = loc("/model.9/cv1/act/Mul_output_0_Mul/model.9/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc293 = loc("/model.9/cv1/act/Mul_output_0_Mul")
#loc294 = loc("/model.9/m/MaxPool_output_0_MaxPool")
#loc295 = loc("/model.9/m_1/MaxPool_output_0_MaxPool")
#loc296 = loc("/model.9/m_2/MaxPool_output_0_MaxPool")
#loc297 = loc("load_/model.9/cv1/act/Mul_output_0_Mul")
#loc298 = loc("/model.9/Concat_output_0_Concat")
#loc299 = loc("/model.9/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc300 = loc("/model.9/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc301 = loc("/model.9/cv2/conv/Conv_output_0_Conv")
#loc302 = loc("/model.9/cv2/act/Mul_output_0_Mul/model.9/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc303 = loc("/model.9/cv2/act/Mul_output_0_Mul/model.9/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc304 = loc("/model.9/cv2/act/Mul_output_0_Mul")
#loc305 = loc("/model.10/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc306 = loc("/model.10/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc307 = loc("/model.10/cv1/conv/Conv_output_0_Conv")
#loc308 = loc("/model.10/cv1/act/Mul_output_0_Mul/model.10/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc309 = loc("/model.10/cv1/act/Mul_output_0_Mul/model.10/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc310 = loc("/model.10/cv1/act/Mul_output_0_Mul")
#loc311 = loc("/model.10/Split_output_0_Split")
#loc312 = loc("/model.10/Split_output_1_Split")
#loc313 = loc("/model.10/m/m.0/attn/qkv/conv/Conv_output_0_Conv_filter_reordered")
#loc314 = loc("/model.10/m/m.0/attn/qkv/conv/Conv_output_0_Conv_bias_reordered")
#loc315 = loc("/model.10/m/m.0/attn/qkv/conv/Conv_output_0_Conv")
#loc316 = loc("/model.10/m/m.0/attn/Reshape_output_0_Reshape")
#loc317 = loc("/model.10/m/m.0/attn/Split_output_0_Split")
#loc318 = loc("/model.10/m/m.0/attn/Split_output_1_Split")
#loc319 = loc("/model.10/m/m.0/attn/Split_output_2_Split")
#loc320 = loc("/model.10/m/m.0/attn/Transpose_output_0_Transpose")
#loc321 = loc("/model.10/m/m.0/attn/Reshape_2_output_0_Reshape")
#loc322 = loc("/model.10/m/m.0/attn/MatMul_output_0_MatMul")
#loc323 = loc("/model.10/m/m.0/attn/pe/conv/Conv_output_0_Conv_filter_reordered")
#loc324 = loc("/model.10/m/m.0/attn/pe/conv/Conv_output_0_Conv_bias_reordered")
#loc325 = loc("/model.10/m/m.0/attn/pe/conv/Conv_output_0_Conv")
#loc326 = loc("/model.10/m/m.0/attn/Mul_output_0_Mul/model.10/m/m.0/attn/Mul_output_0_Mul_slope_table_bf16")
#loc327 = loc("/model.10/m/m.0/attn/Mul_output_0_Mul/model.10/m/m.0/attn/Mul_output_0_Mul_slope_slope_table_bf16")
#loc328 = loc("/model.10/m/m.0/attn/Mul_output_0_Mul")
#loc329 = loc("/model.10/m/m.0/attn/Softmax_output_0_Softmax/model.10/m/m.0/attn/Softmax_output_0_Softmax_slope_table_bf16")
#loc330 = loc("/model.10/m/m.0/attn/Softmax_output_0_Softmax/model.10/m/m.0/attn/Softmax_output_0_Softmax_slope_slope_table_bf16")
#loc331 = loc("/model.10/m/m.0/attn/Softmax_output_0_Softmax/model.10/m/m.0/attn/Softmax_output_0_Softmax_pow_table_bf16")
#loc332 = loc("/model.10/m/m.0/attn/Softmax_output_0_Softmax/model.10/m/m.0/attn/Softmax_output_0_Softmax_pow_mantissa_table_bf16")
#loc333 = loc("/model.10/m/m.0/attn/Softmax_output_0_Softmax")
#loc334 = loc("/model.10/m/m.0/attn/Transpose_1_output_0_Transpose")
#loc335 = loc("/model.10/m/m.0/attn/MatMul_1_output_0_MatMul")
#loc336 = loc("/model.10/m/m.0/attn/Reshape_1_output_0_Reshape")
#loc337 = loc("/model.10/m/m.0/attn/Add_output_0_Add")
#loc338 = loc("/model.10/m/m.0/attn/proj/conv/Conv_output_0_Conv_filter_reordered")
#loc339 = loc("/model.10/m/m.0/attn/proj/conv/Conv_output_0_Conv_bias_reordered")
#loc340 = loc("/model.10/m/m.0/attn/proj/conv/Conv_output_0_Conv")
#loc341 = loc("/model.10/m/m.0/Add_output_0_Add")
#loc342 = loc("/model.10/m/m.0/ffn/ffn.0/conv/Conv_output_0_Conv_filter_reordered")
#loc343 = loc("/model.10/m/m.0/ffn/ffn.0/conv/Conv_output_0_Conv_bias_reordered")
#loc344 = loc("/model.10/m/m.0/ffn/ffn.0/conv/Conv_output_0_Conv")
#loc345 = loc("/model.10/m/m.0/ffn/ffn.0/act/Mul_output_0_Mul/model.10/m/m.0/ffn/ffn.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc346 = loc("/model.10/m/m.0/ffn/ffn.0/act/Mul_output_0_Mul/model.10/m/m.0/ffn/ffn.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc347 = loc("/model.10/m/m.0/ffn/ffn.0/act/Mul_output_0_Mul")
#loc348 = loc("/model.10/m/m.0/ffn/ffn.1/conv/Conv_output_0_Conv_filter_reordered")
#loc349 = loc("/model.10/m/m.0/ffn/ffn.1/conv/Conv_output_0_Conv_bias_reordered")
#loc350 = loc("/model.10/m/m.0/ffn/ffn.1/conv/Conv_output_0_Conv")
#loc351 = loc("/model.10/m/m.0/Add_1_output_0_Add")
#loc352 = loc("/model.10/Concat_output_0_Concat")
#loc353 = loc("/model.10/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc354 = loc("/model.10/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc355 = loc("/model.10/cv2/conv/Conv_output_0_Conv")
#loc356 = loc("/model.10/cv2/act/Mul_output_0_Mul/model.10/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc357 = loc("/model.10/cv2/act/Mul_output_0_Mul/model.10/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc358 = loc("/model.10/cv2/act/Mul_output_0_Mul")
#loc359 = loc("/model.11/Resize_output_0_Resize_filter_reordered")
#loc360 = loc("/model.11/Resize_output_0_Resize")
#loc361 = loc("/model.12/Concat_output_0_Concat")
#loc362 = loc("/model.13/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc363 = loc("/model.13/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc364 = loc("/model.13/cv1/conv/Conv_output_0_Conv")
#loc365 = loc("/model.13/cv1/act/Mul_output_0_Mul/model.13/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc366 = loc("/model.13/cv1/act/Mul_output_0_Mul/model.13/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc367 = loc("/model.13/cv1/act/Mul_output_0_Mul")
#loc368 = loc("/model.13/Split_output_0_Split")
#loc369 = loc("/model.13/Split_output_1_Split")
#loc370 = loc("/model.13/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc371 = loc("/model.13/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc372 = loc("/model.13/m.0/cv1/conv/Conv_output_0_Conv")
#loc373 = loc("/model.13/m.0/cv1/act/Mul_output_0_Mul/model.13/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc374 = loc("/model.13/m.0/cv1/act/Mul_output_0_Mul/model.13/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc375 = loc("/model.13/m.0/cv1/act/Mul_output_0_Mul")
#loc376 = loc("/model.13/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc377 = loc("/model.13/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc378 = loc("/model.13/m.0/cv2/conv/Conv_output_0_Conv")
#loc379 = loc("/model.13/m.0/cv2/act/Mul_output_0_Mul/model.13/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc380 = loc("/model.13/m.0/cv2/act/Mul_output_0_Mul/model.13/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc381 = loc("/model.13/m.0/cv2/act/Mul_output_0_Mul")
#loc382 = loc("/model.13/Concat_output_0_Concat")
#loc383 = loc("load_/model.13/m.0/cv2/act/Mul_output_0_Mul")
#loc384 = loc("load_/model.13/Split_output_1_Split")
#loc385 = loc("load_/model.13/Split_output_0_Split")
#loc386 = loc("/model.13/m.0/Add_output_0_Add")
#loc387 = loc("/model.13/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc388 = loc("/model.13/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc389 = loc("/model.13/cv2/conv/Conv_output_0_Conv")
#loc390 = loc("/model.13/cv2/act/Mul_output_0_Mul/model.13/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc391 = loc("/model.13/cv2/act/Mul_output_0_Mul/model.13/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc392 = loc("/model.13/cv2/act/Mul_output_0_Mul")
#loc393 = loc("/model.14/Resize_output_0_Resize_filter_reordered")
#loc394 = loc("/model.14/Resize_output_0_Resize")
#loc395 = loc("/model.15/Concat_output_0_Concat")
#loc396 = loc("/model.16/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc397 = loc("/model.16/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc398 = loc("/model.16/cv1/conv/Conv_output_0_Conv")
#loc399 = loc("/model.16/cv1/act/Mul_output_0_Mul/model.16/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc400 = loc("/model.16/cv1/act/Mul_output_0_Mul/model.16/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc401 = loc("/model.16/cv1/act/Mul_output_0_Mul")
#loc402 = loc("/model.16/Split_output_0_Split")
#loc403 = loc("/model.16/Split_output_1_Split")
#loc404 = loc("/model.16/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc405 = loc("/model.16/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc406 = loc("/model.16/m.0/cv1/conv/Conv_output_0_Conv")
#loc407 = loc("/model.16/m.0/cv1/act/Mul_output_0_Mul/model.16/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc408 = loc("/model.16/m.0/cv1/act/Mul_output_0_Mul/model.16/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc409 = loc("/model.16/m.0/cv1/act/Mul_output_0_Mul")
#loc410 = loc("/model.16/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc411 = loc("/model.16/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc412 = loc("/model.16/m.0/cv2/act/Mul_output_0_Mul/model.16/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc413 = loc("/model.16/m.0/cv2/act/Mul_output_0_Mul/model.16/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc414 = loc("/model.16/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc415 = loc("/model.16/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc416 = loc("/model.16/cv2/conv/Conv_output_0_Conv")
#loc417 = loc("load_/model.16/m.0/cv1/act/Mul_output_0_Mul")
#loc418 = loc("load_/model.16/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc419 = loc("load_/model.16/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc420 = loc("load_/model.16/m.0/cv2/act/Mul_output_0_Mul/model.16/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc421 = loc("load_/model.16/m.0/cv2/act/Mul_output_0_Mul/model.16/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc422 = loc("/model.16/m.0/cv2/conv/Conv_output_0_Conv")
#loc423 = loc("load_/model.16/Split_output_1_Split")
#loc424 = loc("/model.16/m.0/cv2/act/Mul_output_0_Mul")
#loc425 = loc("load_/model.16/Split_output_0_Split")
#loc426 = loc("/model.16/m.0/Add_output_0_Add")
#loc427 = loc("load_/model.16/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc428 = loc("load_/model.16/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc429 = loc("/model.16/Concat_output_0_Concat")
#loc430 = loc("/model.16/cv2/act/Mul_output_0_Mul/model.16/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc431 = loc("/model.16/cv2/act/Mul_output_0_Mul/model.16/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc432 = loc("/model.16/cv2/act/Mul_output_0_Mul")
#loc433 = loc("/model.17/conv/Conv_output_0_Conv_filter_reordered")
#loc434 = loc("/model.17/conv/Conv_output_0_Conv_bias_reordered")
#loc435 = loc("/model.17/conv/Conv_output_0_Conv")
#loc436 = loc("/model.23/cv2.0/cv2.0.0/conv/Conv_output_0_Conv_filter_reordered")
#loc437 = loc("/model.23/cv2.0/cv2.0.0/conv/Conv_output_0_Conv_bias_reordered")
#loc438 = loc("/model.23/cv2.0/cv2.0.0/conv/Conv_output_0_Conv")
#loc439 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.0/conv/Conv_output_0_Conv_filter_reordered")
#loc440 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.0/conv/Conv_output_0_Conv_bias_reordered")
#loc441 = loc("/model.17/act/Mul_output_0_Mul/model.17/act/Mul_output_0_Mul_slope_table_bf16")
#loc442 = loc("/model.17/act/Mul_output_0_Mul/model.17/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc443 = loc("/model.23/cv2.0/cv2.0.0/act/Mul_output_0_Mul/model.23/cv2.0/cv2.0.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc444 = loc("/model.23/cv2.0/cv2.0.0/act/Mul_output_0_Mul/model.23/cv2.0/cv2.0.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc445 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.0/conv/Conv_output_0_Conv")
#loc446 = loc("/model.17/act/Mul_output_0_Mul")
#loc447 = loc("/model.23/cv2.0/cv2.0.0/act/Mul_output_0_Mul")
#loc448 = loc("load_/model.16/cv2/act/Mul_output_0_Mul")
#loc449 = loc("load_/model.23/cv3.0/cv3.0.0/cv3.0.0.0/conv/Conv_output_0_Conv_filter_reordered")
#loc450 = loc("load_/model.23/cv3.0/cv3.0.0/cv3.0.0.0/conv/Conv_output_0_Conv_bias_reordered")
#loc451 = loc("load_/model.17/conv/Conv_output_0_Conv")
#loc452 = loc("load_/model.17/act/Mul_output_0_Mul/model.17/act/Mul_output_0_Mul_slope_table_bf16")
#loc453 = loc("load_/model.17/act/Mul_output_0_Mul/model.17/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc454 = loc("load_/model.23/cv2.0/cv2.0.0/conv/Conv_output_0_Conv")
#loc455 = loc("load_/model.23/cv2.0/cv2.0.0/act/Mul_output_0_Mul/model.23/cv2.0/cv2.0.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc456 = loc("load_/model.23/cv2.0/cv2.0.0/act/Mul_output_0_Mul/model.23/cv2.0/cv2.0.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc457 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.0/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.0/cv3.0.0.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc458 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.0/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.0/cv3.0.0.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc459 = loc("/model.23/cv2.0/cv2.0.1/conv/Conv_output_0_Conv_filter_reordered")
#loc460 = loc("/model.23/cv2.0/cv2.0.1/conv/Conv_output_0_Conv_bias_reordered")
#loc461 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.1/conv/Conv_output_0_Conv_filter_reordered")
#loc462 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.1/conv/Conv_output_0_Conv_bias_reordered")
#loc463 = loc("/model.18/Concat_output_0_Concat")
#loc464 = loc("/model.23/cv2.0/cv2.0.1/conv/Conv_output_0_Conv")
#loc465 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.1/conv/Conv_output_0_Conv")
#loc466 = loc("load_/model.23/cv3.0/cv3.0.0/cv3.0.0.0/conv/Conv_output_0_Conv")
#loc467 = loc("load_/model.23/cv3.0/cv3.0.0/cv3.0.0.0/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.0/cv3.0.0.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc468 = loc("load_/model.23/cv3.0/cv3.0.0/cv3.0.0.0/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.0/cv3.0.0.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc469 = loc("load_/model.17/act/Mul_output_0_Mul")
#loc470 = loc("load_/model.13/cv2/act/Mul_output_0_Mul")
#loc471 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.0/act/Mul_output_0_Mul")
#loc472 = loc("load_/model.23/cv2.0/cv2.0.0/act/Mul_output_0_Mul")
#loc473 = loc("load_/model.23/cv2.0/cv2.0.1/conv/Conv_output_0_Conv_filter_reordered")
#loc474 = loc("load_/model.23/cv2.0/cv2.0.1/conv/Conv_output_0_Conv_bias_reordered")
#loc475 = loc("load_/model.23/cv3.0/cv3.0.0/cv3.0.0.1/conv/Conv_output_0_Conv_filter_reordered")
#loc476 = loc("load_/model.23/cv3.0/cv3.0.0/cv3.0.0.1/conv/Conv_output_0_Conv_bias_reordered")
#loc477 = loc("/model.19/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc478 = loc("/model.19/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc479 = loc("/model.19/cv1/conv/Conv_output_0_Conv")
#loc480 = loc("/model.23/cv2.0/cv2.0.1/act/Mul_output_0_Mul/model.23/cv2.0/cv2.0.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc481 = loc("/model.23/cv2.0/cv2.0.1/act/Mul_output_0_Mul/model.23/cv2.0/cv2.0.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc482 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc483 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc484 = loc("/model.19/cv1/act/Mul_output_0_Mul/model.19/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc485 = loc("/model.19/cv1/act/Mul_output_0_Mul/model.19/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc486 = loc("/model.23/cv2.0/cv2.0.1/act/Mul_output_0_Mul")
#loc487 = loc("/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Mul_output_0_Mul")
#loc488 = loc("/model.19/cv1/act/Mul_output_0_Mul")
#loc489 = loc("load_/model.23/cv2.0/cv2.0.1/conv/Conv_output_0_Conv")
#loc490 = loc("load_/model.23/cv2.0/cv2.0.1/act/Mul_output_0_Mul/model.23/cv2.0/cv2.0.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc491 = loc("load_/model.23/cv2.0/cv2.0.1/act/Mul_output_0_Mul/model.23/cv2.0/cv2.0.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc492 = loc("load_/model.23/cv3.0/cv3.0.0/cv3.0.0.1/conv/Conv_output_0_Conv")
#loc493 = loc("load_/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc494 = loc("load_/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc495 = loc("load_/model.19/cv1/conv/Conv_output_0_Conv")
#loc496 = loc("load_/model.19/cv1/act/Mul_output_0_Mul/model.19/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc497 = loc("load_/model.19/cv1/act/Mul_output_0_Mul/model.19/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc498 = loc("/model.23/cv2.0/cv2.0.2/Conv_output_0_Conv_filter_reordered")
#loc499 = loc("/model.23/cv2.0/cv2.0.2/Conv_output_0_Conv_bias_reordered")
#loc500 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.0/conv/Conv_output_0_Conv_filter_reordered")
#loc501 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.0/conv/Conv_output_0_Conv_bias_reordered")
#loc502 = loc("/model.23/cv2.0/cv2.0.2/Conv_output_0_Conv")
#loc503 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.0/conv/Conv_output_0_Conv")
#loc504 = loc("load_/model.23/cv2.0/cv2.0.1/act/Mul_output_0_Mul")
#loc505 = loc("load_/model.23/cv2.0/cv2.0.2/Conv_output_0_Conv_filter_reordered")
#loc506 = loc("load_/model.23/cv2.0/cv2.0.2/Conv_output_0_Conv_bias_reordered")
#loc507 = loc("load_/model.23/cv3.0/cv3.0.0/cv3.0.0.1/act/Mul_output_0_Mul")
#loc508 = loc("load_/model.23/cv3.0/cv3.0.1/cv3.0.1.0/conv/Conv_output_0_Conv_filter_reordered")
#loc509 = loc("load_/model.23/cv3.0/cv3.0.1/cv3.0.1.0/conv/Conv_output_0_Conv_bias_reordered")
#loc510 = loc("/model.19/Split_output_0_Split")
#loc511 = loc("/model.19/Split_output_1_Split")
#loc512 = loc("/model.19/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc513 = loc("/model.19/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc514 = loc("/model.19/m.0/cv1/conv/Conv_output_0_Conv")
#loc515 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.0/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.1/cv3.0.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc516 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.0/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.1/cv3.0.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc517 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.1/conv/Conv_output_0_Conv_filter_reordered")
#loc518 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.1/conv/Conv_output_0_Conv_bias_reordered")
#loc519 = loc("/model.19/m.0/cv1/act/Mul_output_0_Mul/model.19/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc520 = loc("/model.19/m.0/cv1/act/Mul_output_0_Mul/model.19/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc521 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.1/conv/Conv_output_0_Conv")
#loc522 = loc("/model.19/m.0/cv1/act/Mul_output_0_Mul")
#loc523 = loc("load_/model.23/cv3.0/cv3.0.1/cv3.0.1.0/conv/Conv_output_0_Conv")
#loc524 = loc("load_/model.23/cv3.0/cv3.0.1/cv3.0.1.0/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.1/cv3.0.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc525 = loc("load_/model.23/cv3.0/cv3.0.1/cv3.0.1.0/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.1/cv3.0.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc526 = loc("load_/model.23/cv3.0/cv3.0.1/cv3.0.1.1/conv/Conv_output_0_Conv_filter_reordered")
#loc527 = loc("load_/model.23/cv3.0/cv3.0.1/cv3.0.1.1/conv/Conv_output_0_Conv_bias_reordered")
#loc528 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.0/act/Mul_output_0_Mul")
#loc529 = loc("load_/model.19/m.0/cv1/conv/Conv_output_0_Conv")
#loc530 = loc("load_/model.19/m.0/cv1/act/Mul_output_0_Mul/model.19/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc531 = loc("load_/model.19/m.0/cv1/act/Mul_output_0_Mul/model.19/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc532 = loc("/model.19/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc533 = loc("/model.19/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc534 = loc("/model.19/m.0/cv2/conv/Conv_output_0_Conv")
#loc535 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.1/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.1/cv3.0.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc536 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.1/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.1/cv3.0.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc537 = loc("/model.23/cv3.0/cv3.0.2/Conv_output_0_Conv_filter_reordered")
#loc538 = loc("/model.23/cv3.0/cv3.0.2/Conv_output_0_Conv_bias_reordered")
#loc539 = loc("/model.23/cv3.0/cv3.0.2/Conv_output_0_Conv")
#loc540 = loc("load_/model.23/cv3.0/cv3.0.1/cv3.0.1.1/conv/Conv_output_0_Conv")
#loc541 = loc("load_/model.23/cv3.0/cv3.0.1/cv3.0.1.1/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.1/cv3.0.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc542 = loc("load_/model.23/cv3.0/cv3.0.1/cv3.0.1.1/act/Mul_output_0_Mul/model.23/cv3.0/cv3.0.1/cv3.0.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc543 = loc("load_/model.23/cv3.0/cv3.0.2/Conv_output_0_Conv_filter_reordered")
#loc544 = loc("load_/model.23/cv3.0/cv3.0.2/Conv_output_0_Conv_bias_reordered")
#loc545 = loc("/model.23/cv3.0/cv3.0.1/cv3.0.1.1/act/Mul_output_0_Mul")
#loc546 = loc("/model.19/m.0/cv2/act/Mul_output_0_Mul/model.19/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc547 = loc("/model.19/m.0/cv2/act/Mul_output_0_Mul/model.19/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc548 = loc("/model.19/m.0/cv2/act/Mul_output_0_Mul")
#loc549 = loc("/model.23/Concat_output_0_Concat")
#loc550 = loc("/model.19/m.0/Add_output_0_Add")
#loc551 = loc("/model.23/Reshape_output_0_Reshape")
#loc552 = loc("/model.19/Concat_output_0_Concat")
#loc553 = loc("/model.19/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc554 = loc("/model.19/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc555 = loc("/model.19/cv2/conv/Conv_output_0_Conv")
#loc556 = loc("/model.19/cv2/act/Mul_output_0_Mul/model.19/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc557 = loc("/model.19/cv2/act/Mul_output_0_Mul/model.19/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc558 = loc("/model.19/cv2/act/Mul_output_0_Mul")
#loc559 = loc("/model.20/conv/Conv_output_0_Conv_filter_reordered")
#loc560 = loc("/model.20/conv/Conv_output_0_Conv_bias_reordered")
#loc561 = loc("/model.20/conv/Conv_output_0_Conv")
#loc562 = loc("/model.23/cv2.1/cv2.1.0/conv/Conv_output_0_Conv_filter_reordered")
#loc563 = loc("/model.23/cv2.1/cv2.1.0/conv/Conv_output_0_Conv_bias_reordered")
#loc564 = loc("/model.23/cv2.1/cv2.1.0/conv/Conv_output_0_Conv")
#loc565 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.0/conv/Conv_output_0_Conv_filter_reordered")
#loc566 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.0/conv/Conv_output_0_Conv_bias_reordered")
#loc567 = loc("/model.20/act/Mul_output_0_Mul/model.20/act/Mul_output_0_Mul_slope_table_bf16")
#loc568 = loc("/model.20/act/Mul_output_0_Mul/model.20/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc569 = loc("/model.23/cv2.1/cv2.1.0/act/Mul_output_0_Mul/model.23/cv2.1/cv2.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc570 = loc("/model.23/cv2.1/cv2.1.0/act/Mul_output_0_Mul/model.23/cv2.1/cv2.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc571 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.0/conv/Conv_output_0_Conv")
#loc572 = loc("/model.20/act/Mul_output_0_Mul")
#loc573 = loc("/model.23/cv2.1/cv2.1.0/act/Mul_output_0_Mul")
#loc574 = loc("load_/model.19/cv2/act/Mul_output_0_Mul")
#loc575 = loc("load_/model.23/cv3.1/cv3.1.0/cv3.1.0.0/conv/Conv_output_0_Conv_filter_reordered")
#loc576 = loc("load_/model.23/cv3.1/cv3.1.0/cv3.1.0.0/conv/Conv_output_0_Conv_bias_reordered")
#loc577 = loc("load_/model.20/conv/Conv_output_0_Conv")
#loc578 = loc("load_/model.20/act/Mul_output_0_Mul/model.20/act/Mul_output_0_Mul_slope_table_bf16")
#loc579 = loc("load_/model.20/act/Mul_output_0_Mul/model.20/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc580 = loc("load_/model.23/cv2.1/cv2.1.0/conv/Conv_output_0_Conv")
#loc581 = loc("load_/model.23/cv2.1/cv2.1.0/act/Mul_output_0_Mul/model.23/cv2.1/cv2.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc582 = loc("load_/model.23/cv2.1/cv2.1.0/act/Mul_output_0_Mul/model.23/cv2.1/cv2.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc583 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.0/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.0/cv3.1.0.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc584 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.0/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.0/cv3.1.0.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc585 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.0/act/Mul_output_0_Mul")
#loc586 = loc("/model.21/Concat_output_0_Concat")
#loc587 = loc("/model.23/cv2.1/cv2.1.1/conv/Conv_output_0_Conv_filter_reordered")
#loc588 = loc("/model.23/cv2.1/cv2.1.1/conv/Conv_output_0_Conv_bias_reordered")
#loc589 = loc("/model.23/cv2.1/cv2.1.1/conv/Conv_output_0_Conv")
#loc590 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.1/conv/Conv_output_0_Conv_filter_reordered")
#loc591 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.1/conv/Conv_output_0_Conv_bias_reordered")
#loc592 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.1/conv/Conv_output_0_Conv")
#loc593 = loc("/model.22/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc594 = loc("/model.22/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc595 = loc("/model.22/cv1/conv/Conv_output_0_Conv")
#loc596 = loc("/model.23/cv2.1/cv2.1.1/act/Mul_output_0_Mul/model.23/cv2.1/cv2.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc597 = loc("/model.23/cv2.1/cv2.1.1/act/Mul_output_0_Mul/model.23/cv2.1/cv2.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc598 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc599 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc600 = loc("/model.23/cv2.1/cv2.1.1/act/Mul_output_0_Mul")
#loc601 = loc("/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Mul_output_0_Mul")
#loc602 = loc("load_/model.23/cv2.1/cv2.1.1/conv/Conv_output_0_Conv")
#loc603 = loc("load_/model.23/cv2.1/cv2.1.1/act/Mul_output_0_Mul/model.23/cv2.1/cv2.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc604 = loc("load_/model.23/cv2.1/cv2.1.1/act/Mul_output_0_Mul/model.23/cv2.1/cv2.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc605 = loc("load_/model.23/cv3.1/cv3.1.0/cv3.1.0.1/conv/Conv_output_0_Conv")
#loc606 = loc("load_/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc607 = loc("load_/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc608 = loc("/model.22/cv1/act/Mul_output_0_Mul/model.22/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc609 = loc("/model.22/cv1/act/Mul_output_0_Mul/model.22/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc610 = loc("/model.22/cv1/act/Mul_output_0_Mul")
#loc611 = loc("/model.23/cv2.1/cv2.1.2/Conv_output_0_Conv_filter_reordered")
#loc612 = loc("/model.23/cv2.1/cv2.1.2/Conv_output_0_Conv_bias_reordered")
#loc613 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.0/conv/Conv_output_0_Conv_filter_reordered")
#loc614 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.0/conv/Conv_output_0_Conv_bias_reordered")
#loc615 = loc("/model.23/cv2.1/cv2.1.2/Conv_output_0_Conv")
#loc616 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.0/conv/Conv_output_0_Conv")
#loc617 = loc("load_/model.23/cv2.1/cv2.1.1/act/Mul_output_0_Mul")
#loc618 = loc("load_/model.23/cv2.1/cv2.1.2/Conv_output_0_Conv_filter_reordered")
#loc619 = loc("load_/model.23/cv2.1/cv2.1.2/Conv_output_0_Conv_bias_reordered")
#loc620 = loc("load_/model.23/cv3.1/cv3.1.0/cv3.1.0.1/act/Mul_output_0_Mul")
#loc621 = loc("load_/model.23/cv3.1/cv3.1.1/cv3.1.1.0/conv/Conv_output_0_Conv_filter_reordered")
#loc622 = loc("load_/model.23/cv3.1/cv3.1.1/cv3.1.1.0/conv/Conv_output_0_Conv_bias_reordered")
#loc623 = loc("/model.22/Split_output_0_Split")
#loc624 = loc("/model.22/Split_output_1_Split")
#loc625 = loc("/model.22/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc626 = loc("/model.22/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc627 = loc("/model.22/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc628 = loc("/model.22/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc629 = loc("/model.22/m.0/cv1/conv/Conv_output_0_Conv")
#loc630 = loc("/model.22/m.0/cv2/conv/Conv_output_0_Conv")
#loc631 = loc("load_/model.22/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc632 = loc("load_/model.22/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc633 = loc("load_/model.22/Split_output_1_Split")
#loc634 = loc("load_/model.22/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc635 = loc("load_/model.22/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc636 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.0/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.1/cv3.1.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc637 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.0/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.1/cv3.1.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc638 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.1/conv/Conv_output_0_Conv_filter_reordered")
#loc639 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.1/conv/Conv_output_0_Conv_bias_reordered")
#loc640 = loc("/model.22/m.0/cv1/act/Mul_output_0_Mul/model.22/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc641 = loc("/model.22/m.0/cv1/act/Mul_output_0_Mul/model.22/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc642 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.1/conv/Conv_output_0_Conv")
#loc643 = loc("/model.22/m.0/cv1/act/Mul_output_0_Mul")
#loc644 = loc("load_/model.23/cv3.1/cv3.1.1/cv3.1.1.0/conv/Conv_output_0_Conv")
#loc645 = loc("load_/model.23/cv3.1/cv3.1.1/cv3.1.1.0/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.1/cv3.1.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc646 = loc("load_/model.23/cv3.1/cv3.1.1/cv3.1.1.0/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.1/cv3.1.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc647 = loc("load_/model.23/cv3.1/cv3.1.1/cv3.1.1.1/conv/Conv_output_0_Conv_filter_reordered")
#loc648 = loc("load_/model.23/cv3.1/cv3.1.1/cv3.1.1.1/conv/Conv_output_0_Conv_bias_reordered")
#loc649 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.0/act/Mul_output_0_Mul")
#loc650 = loc("load_/model.22/m.0/cv1/conv/Conv_output_0_Conv")
#loc651 = loc("load_/model.22/m.0/cv1/act/Mul_output_0_Mul/model.22/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc652 = loc("load_/model.22/m.0/cv1/act/Mul_output_0_Mul/model.22/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc653 = loc("/model.22/m.0/cv2/act/Mul_output_0_Mul/model.22/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc654 = loc("/model.22/m.0/cv2/act/Mul_output_0_Mul/model.22/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc655 = loc("/model.22/m.0/cv2/act/Mul_output_0_Mul")
#loc656 = loc("/model.22/m.0/m/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc657 = loc("/model.22/m.0/m/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc658 = loc("/model.22/m.0/m/m.0/cv1/conv/Conv_output_0_Conv")
#loc659 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.1/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.1/cv3.1.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc660 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.1/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.1/cv3.1.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc661 = loc("/model.23/cv3.1/cv3.1.2/Conv_output_0_Conv_filter_reordered")
#loc662 = loc("/model.23/cv3.1/cv3.1.2/Conv_output_0_Conv_bias_reordered")
#loc663 = loc("/model.23/cv3.1/cv3.1.2/Conv_output_0_Conv")
#loc664 = loc("load_/model.23/cv3.1/cv3.1.1/cv3.1.1.1/conv/Conv_output_0_Conv")
#loc665 = loc("load_/model.23/cv3.1/cv3.1.1/cv3.1.1.1/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.1/cv3.1.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc666 = loc("load_/model.23/cv3.1/cv3.1.1/cv3.1.1.1/act/Mul_output_0_Mul/model.23/cv3.1/cv3.1.1/cv3.1.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc667 = loc("load_/model.23/cv3.1/cv3.1.2/Conv_output_0_Conv_filter_reordered")
#loc668 = loc("load_/model.23/cv3.1/cv3.1.2/Conv_output_0_Conv_bias_reordered")
#loc669 = loc("/model.23/cv3.1/cv3.1.1/cv3.1.1.1/act/Mul_output_0_Mul")
#loc670 = loc("/model.22/m.0/m/m.0/cv1/act/Mul_output_0_Mul/model.22/m.0/m/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc671 = loc("/model.22/m.0/m/m.0/cv1/act/Mul_output_0_Mul/model.22/m.0/m/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc672 = loc("/model.22/m.0/m/m.0/cv1/act/Mul_output_0_Mul")
#loc673 = loc("/model.23/Concat_1_output_0_Concat")
#loc674 = loc("/model.22/m.0/m/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc675 = loc("/model.22/m.0/m/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc676 = loc("/model.22/m.0/m/m.0/cv2/conv/Conv_output_0_Conv")
#loc677 = loc("/model.23/Reshape_1_output_0_Reshape")
#loc678 = loc("/model.22/m.0/m/m.0/cv2/act/Mul_output_0_Mul/model.22/m.0/m/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc679 = loc("/model.22/m.0/m/m.0/cv2/act/Mul_output_0_Mul/model.22/m.0/m/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc680 = loc("/model.22/m.0/m/m.0/cv2/act/Mul_output_0_Mul")
#loc681 = loc("/model.22/m.0/m/m.0/Add_output_0_Add")
#loc682 = loc("/model.22/m.0/m/m.1/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc683 = loc("/model.22/m.0/m/m.1/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc684 = loc("/model.22/m.0/m/m.1/cv1/conv/Conv_output_0_Conv")
#loc685 = loc("/model.22/m.0/m/m.1/cv1/act/Mul_output_0_Mul/model.22/m.0/m/m.1/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc686 = loc("/model.22/m.0/m/m.1/cv1/act/Mul_output_0_Mul/model.22/m.0/m/m.1/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc687 = loc("/model.22/m.0/m/m.1/cv1/act/Mul_output_0_Mul")
#loc688 = loc("/model.22/m.0/m/m.1/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc689 = loc("/model.22/m.0/m/m.1/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc690 = loc("/model.22/m.0/m/m.1/cv2/conv/Conv_output_0_Conv")
#loc691 = loc("/model.22/m.0/m/m.1/cv2/act/Mul_output_0_Mul/model.22/m.0/m/m.1/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc692 = loc("/model.22/m.0/m/m.1/cv2/act/Mul_output_0_Mul/model.22/m.0/m/m.1/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc693 = loc("/model.22/m.0/m/m.1/cv2/act/Mul_output_0_Mul")
#loc694 = loc("/model.22/m.0/m/m.1/Add_output_0_Add")
#loc695 = loc("/model.22/m.0/Concat_output_0_Concat")
#loc696 = loc("/model.22/m.0/cv3/conv/Conv_output_0_Conv_filter_reordered")
#loc697 = loc("/model.22/m.0/cv3/conv/Conv_output_0_Conv_bias_reordered")
#loc698 = loc("/model.22/m.0/cv3/conv/Conv_output_0_Conv")
#loc699 = loc("/model.22/m.0/cv3/act/Mul_output_0_Mul/model.22/m.0/cv3/act/Mul_output_0_Mul_slope_table_bf16")
#loc700 = loc("/model.22/m.0/cv3/act/Mul_output_0_Mul/model.22/m.0/cv3/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc701 = loc("/model.22/m.0/cv3/act/Mul_output_0_Mul")
#loc702 = loc("/model.22/Concat_output_0_Concat")
#loc703 = loc("/model.22/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc704 = loc("/model.22/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc705 = loc("/model.22/cv2/conv/Conv_output_0_Conv")
#loc706 = loc("/model.22/cv2/act/Mul_output_0_Mul/model.22/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc707 = loc("/model.22/cv2/act/Mul_output_0_Mul/model.22/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc708 = loc("/model.22/cv2/act/Mul_output_0_Mul")
#loc709 = loc("/model.23/cv2.2/cv2.2.0/conv/Conv_output_0_Conv_filter_reordered")
#loc710 = loc("/model.23/cv2.2/cv2.2.0/conv/Conv_output_0_Conv_bias_reordered")
#loc711 = loc("/model.23/cv2.2/cv2.2.0/conv/Conv_output_0_Conv")
#loc712 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.0/conv/Conv_output_0_Conv_filter_reordered")
#loc713 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.0/conv/Conv_output_0_Conv_bias_reordered")
#loc714 = loc("/model.23/cv2.2/cv2.2.0/act/Mul_output_0_Mul/model.23/cv2.2/cv2.2.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc715 = loc("/model.23/cv2.2/cv2.2.0/act/Mul_output_0_Mul/model.23/cv2.2/cv2.2.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc716 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.0/conv/Conv_output_0_Conv")
#loc717 = loc("/model.23/cv2.2/cv2.2.0/act/Mul_output_0_Mul")
#loc718 = loc("load_/model.22/cv2/act/Mul_output_0_Mul")
#loc719 = loc("load_/model.23/cv3.2/cv3.2.0/cv3.2.0.0/conv/Conv_output_0_Conv_filter_reordered")
#loc720 = loc("load_/model.23/cv3.2/cv3.2.0/cv3.2.0.0/conv/Conv_output_0_Conv_bias_reordered")
#loc721 = loc("load_/model.23/cv2.2/cv2.2.0/conv/Conv_output_0_Conv")
#loc722 = loc("load_/model.23/cv2.2/cv2.2.0/act/Mul_output_0_Mul/model.23/cv2.2/cv2.2.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc723 = loc("load_/model.23/cv2.2/cv2.2.0/act/Mul_output_0_Mul/model.23/cv2.2/cv2.2.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc724 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.0/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.0/cv3.2.0.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc725 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.0/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.0/cv3.2.0.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc726 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.0/act/Mul_output_0_Mul")
#loc727 = loc("/model.23/cv2.2/cv2.2.1/conv/Conv_output_0_Conv_filter_reordered")
#loc728 = loc("/model.23/cv2.2/cv2.2.1/conv/Conv_output_0_Conv_bias_reordered")
#loc729 = loc("/model.23/cv2.2/cv2.2.1/conv/Conv_output_0_Conv")
#loc730 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.1/conv/Conv_output_0_Conv_filter_reordered")
#loc731 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.1/conv/Conv_output_0_Conv_bias_reordered")
#loc732 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.1/conv/Conv_output_0_Conv")
#loc733 = loc("/model.23/cv2.2/cv2.2.1/act/Mul_output_0_Mul/model.23/cv2.2/cv2.2.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc734 = loc("/model.23/cv2.2/cv2.2.1/act/Mul_output_0_Mul/model.23/cv2.2/cv2.2.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc735 = loc("/model.23/cv2.2/cv2.2.1/act/Mul_output_0_Mul")
#loc736 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.1/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.0/cv3.2.0.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc737 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.1/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.0/cv3.2.0.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc738 = loc("/model.23/cv3.2/cv3.2.0/cv3.2.0.1/act/Mul_output_0_Mul")
#loc739 = loc("/model.23/cv2.2/cv2.2.2/Conv_output_0_Conv_filter_reordered")
#loc740 = loc("/model.23/cv2.2/cv2.2.2/Conv_output_0_Conv_bias_reordered")
#loc741 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.0/conv/Conv_output_0_Conv_filter_reordered")
#loc742 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.0/conv/Conv_output_0_Conv_bias_reordered")
#loc743 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.0/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.1/cv3.2.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc744 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.0/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.1/cv3.2.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc745 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.1/conv/Conv_output_0_Conv_filter_reordered")
#loc746 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.1/conv/Conv_output_0_Conv_bias_reordered")
#loc747 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.1/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.1/cv3.2.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc748 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.1/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.1/cv3.2.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc749 = loc("/model.23/cv3.2/cv3.2.2/Conv_output_0_Conv_filter_reordered")
#loc750 = loc("/model.23/cv3.2/cv3.2.2/Conv_output_0_Conv_bias_reordered")
#loc751 = loc("/model.23/cv2.2/cv2.2.2/Conv_output_0_Conv")
#loc752 = loc("/model.23/cv3.2/cv3.2.2/Conv_output_0_Conv")
#loc753 = loc("load_/model.23/cv2.2/cv2.2.1/act/Mul_output_0_Mul")
#loc754 = loc("load_/model.23/cv2.2/cv2.2.2/Conv_output_0_Conv_filter_reordered")
#loc755 = loc("load_/model.23/cv2.2/cv2.2.2/Conv_output_0_Conv_bias_reordered")
#loc756 = loc("load_/model.23/cv3.2/cv3.2.0/cv3.2.0.1/act/Mul_output_0_Mul")
#loc757 = loc("load_/model.23/cv3.2/cv3.2.1/cv3.2.1.0/conv/Conv_output_0_Conv_filter_reordered")
#loc758 = loc("load_/model.23/cv3.2/cv3.2.1/cv3.2.1.0/conv/Conv_output_0_Conv_bias_reordered")
#loc759 = loc("load_/model.23/cv3.2/cv3.2.1/cv3.2.1.0/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.1/cv3.2.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc760 = loc("load_/model.23/cv3.2/cv3.2.1/cv3.2.1.0/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.1/cv3.2.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc761 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.0/conv/Conv_output_0_Conv")
#loc762 = loc("load_/model.23/cv3.2/cv3.2.1/cv3.2.1.1/conv/Conv_output_0_Conv_filter_reordered")
#loc763 = loc("load_/model.23/cv3.2/cv3.2.1/cv3.2.1.1/conv/Conv_output_0_Conv_bias_reordered")
#loc764 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.0/act/Mul_output_0_Mul")
#loc765 = loc("load_/model.23/cv3.2/cv3.2.1/cv3.2.1.1/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.1/cv3.2.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc766 = loc("load_/model.23/cv3.2/cv3.2.1/cv3.2.1.1/act/Mul_output_0_Mul/model.23/cv3.2/cv3.2.1/cv3.2.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc767 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.1/conv/Conv_output_0_Conv")
#loc768 = loc("load_/model.23/cv3.2/cv3.2.2/Conv_output_0_Conv_filter_reordered")
#loc769 = loc("load_/model.23/cv3.2/cv3.2.2/Conv_output_0_Conv_bias_reordered")
#loc770 = loc("/model.23/cv3.2/cv3.2.1/cv3.2.1.1/act/Mul_output_0_Mul")
#loc771 = loc("/model.23/Concat_2_output_0_Concat")
#loc772 = loc("/model.23/Reshape_2_output_0_Reshape")
#loc773 = loc("/model.23/Concat_3_output_0_Concat")
#loc774 = loc("/model.23/Split_output_0_Split")
#loc775 = loc("/model.23/Split_output_1_Split")
#loc776 = loc("/model.23/dfl/Reshape_output_0_Reshape")
#loc777 = loc("/model.23/Sigmoid_output_0_Sigmoid/model.23/Sigmoid_output_0_Sigmoid_slope_table_bf16")
#loc778 = loc("/model.23/Sigmoid_output_0_Sigmoid/model.23/Sigmoid_output_0_Sigmoid_slope_slope_table_bf16")
#loc779 = loc("/model.23/Sigmoid_output_0_Sigmoid")
#loc780 = loc("/model.23/dfl/Softmax_output_0_Softmax/model.23/dfl/Softmax_output_0_Softmax_slope_table_bf16")
#loc781 = loc("/model.23/dfl/Softmax_output_0_Softmax/model.23/dfl/Softmax_output_0_Softmax_slope_slope_table_bf16")
#loc782 = loc("/model.23/dfl/Softmax_output_0_Softmax/model.23/dfl/Softmax_output_0_Softmax_pow_table_bf16")
#loc783 = loc("/model.23/dfl/Softmax_output_0_Softmax/model.23/dfl/Softmax_output_0_Softmax_pow_mantissa_table_bf16")
#loc784 = loc("/model.23/dfl/Softmax_output_0_Softmax_/model.23/dfl/Transpose_output_0_Transpose")
#loc785 = loc("/model.23/dfl/Transpose_output_0_Transpose_/model.23/dfl/Softmax_output_0_Softmax")
#loc786 = loc("/model.23/dfl/conv/Conv_output_0_Conv_filter_reordered")
#loc787 = loc("/model.23/dfl/conv/Conv_output_0_Conv")
#loc788 = loc("/model.23/Sigmoid_output_0_Sigmoid_f32")
#loc789 = loc("/model.23/dfl/conv/Conv_output_0_Conv_f32")
#loc790 = loc(fused[#loc135, #loc136])
#loc791 = loc(fused[#loc151, #loc152])
#loc792 = loc(fused[#loc235, #loc236])
#loc793 = loc(fused[#loc294, #loc295, #loc296])
#loc794 = loc(fused[#loc445, #loc446, #loc447])
#loc795 = loc(fused[#loc463, #loc464, #loc465])
#loc796 = loc(fused[#loc486, #loc487, #loc488])
#loc797 = loc(fused[#loc502, #loc503])
#loc798 = loc(fused[#loc521, #loc522])
#loc799 = loc(fused[#loc571, #loc572, #loc573])
#loc800 = loc(fused[#loc600, #loc601])
#loc801 = loc(fused[#loc615, #loc616])
#loc802 = loc(fused[#loc629, #loc630])
#loc803 = loc(fused[#loc642, #loc643])
#loc804 = loc(fused[#loc716, #loc717])
#loc805 = loc(fused[#loc751, #loc752])

