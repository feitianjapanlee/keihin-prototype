#loc = loc(unknown)
#loc1 = loc("images")
module @yolov8n attributes {module.FLOPs = 1440546520 : i64, module.addr_mode = "basic", module.asymmetric = false, module.chip = "cv181x", module.cores = 1 : i64, module.devices = 1 : i64, module.high_precision = false, module.inputs = ["images"], module.mode = "BF16", module.outputs = ["/model.22/dfl/conv/Conv_output_0_Conv_f32", "/model.22/Sigmoid_output_0_Sigmoid_f32"], module.platform = "ONNX", module.q_group_size = 0 : i64, module.state = "TPU_ADDRESSED", module.top_run_mode = "STATIC", module.weight_file = "yolov8n_tpu_addressed_cv181x_bf16_weight.npz"} {
  module @yolov8n attributes {module.coeff_addr = 1099511627776 : i64, module.coeff_size = 6030832 : i64, module.device_id = 0 : i64, module.neuron_size = 1003520 : i64, module.private_size = 0 : i64, module.step = 0 : i64} {
    func.func @main(%arg0: tensor<1x3x224x320xf32> loc(unknown)) -> (tensor<1x1x4x1470xf32, 5497558138880 : i64>, tensor<1x4x1470xf32, 4398046511104 : i64>) {
      %0 = "top.Input"(%arg0) {channel_format = "nchw", do_preprocess = true, keep_aspect_ratio = true, keep_ratio_mode = "letterbox", mean = [0.000000e+00, 0.000000e+00, 0.000000e+00], pad_type = "center", pad_value = 0 : i64, pixel_format = "rgb", resize_dims = [224, 320], scale = [0.0039215688593685627, 0.0039215688593685627, 0.0039215688593685627]} : (tensor<1x3x224x320xf32>) -> tensor<1x3x224x320xf32, 3298534883328 : i64> loc(#loc1)
      %1:2 = call @subfunc_0(%0) : (tensor<1x3x224x320xf32, 3298534883328 : i64>) -> (tensor<1x1x4x1470xf32, 5497558138880 : i64>, tensor<1x4x1470xf32, 4398046511104 : i64>) loc(#loc)
      return %1#0, %1#1 : tensor<1x1x4x1470xf32, 5497558138880 : i64>, tensor<1x4x1470xf32, 4398046511104 : i64> loc(#loc)
    } loc(#loc)
    func.func @subfunc_0(%arg0: tensor<1x3x224x320xf32, 3298534883328 : i64> loc("images")) -> (tensor<1x1x4x1470xf32, 5497558138880 : i64>, tensor<1x4x1470xf32, 4398046511104 : i64>) attributes {id = 0 : i64, mode = #tpu<run_mode TPU_STATIC>, next_index = array<i32: -1>} {
      %0 = "top.None"() : () -> none loc(#loc)
      %1 = "tpu.Cast"(%arg0) {round_mode = #tpu<round_mode HalfAwayFromZero>, with_scale = true} : (tensor<1x3x224x320xf32, 3298534883328 : i64>) -> tensor<1x3x224x320xbf16, 0 : i64> loc(#loc2)
      %2 = "top.Weight"() : () -> tensor<1x16x9x3xbf16, 1099513062512 : i64> loc(#loc3)
      %3 = "top.Weight"() : () -> tensor<2x16x1x1xui16, 1099512804656 : i64> loc(#loc4)
      %4 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc5)
      %5 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc6)
      %6 = "top.Weight"() : () -> tensor<1x32x9x16xbf16, 1099512682800 : i64> loc(#loc7)
      %7 = "top.Weight"() : () -> tensor<2x32x1x1xui16, 1099512803440 : i64> loc(#loc8)
      %8 = "tpu.Group"(%1) ({
        %371 = "tpu.Load"(%1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 12160, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [3], d_idx = [0], d_slice = [1], h_idx = [0, 13, 29, 45, 61, 77, 93, 109, 125, 141, 157, 173, 189, 205], h_slice = [16, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19], w_idx = [0], w_slice = [320], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x3x224x320xbf16, 0 : i64>) -> tensor<1x3x224x320xbf16> loc(#loc10)
        %372 = "tpu.Load"(%2) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12160, out_size = 108, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [3], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x16x9x3xbf16, 1099513062512 : i64>) -> tensor<1x16x9x3xbf16> loc(#loc11)
        %373 = "tpu.Load"(%3) {do_bcast = false, ginfo = #tpu.lg<out_addr = 19200, out_size = 8, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x16x1x1xui16, 1099512804656 : i64>) -> tensor<2x16x1x1xui16> loc(#loc12)
        %374 = "tpu.Load"(%4) {do_bcast = true, ginfo = #tpu.lg<out_addr = 31232, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc13)
        %375 = "tpu.Load"(%5) {do_bcast = true, ginfo = #tpu.lg<out_addr = 19216, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc14)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 5760, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 7, 15, 23, 31, 39, 47, 55, 63, 71, 79, 87, 95, 103], h_slice = [8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], w_idx = [0], w_slice = [160], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x3x224x320xbf16>, tensor<1x16x9x3xbf16>, tensor<2x16x1x1xui16>) -> tensor<1x16x112x160xbf16> loc(#loc15)
        %377 = "tpu.Load"(%6) {do_bcast = false, ginfo = #tpu.lg<out_addr = 18048, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [16], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x9x16xbf16, 1099512682800 : i64>) -> tensor<1x32x9x16xbf16> loc(#loc16)
        %378 = "tpu.Load"(%7) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12272, out_size = 16, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x32x1x1xui16, 1099512803440 : i64>) -> tensor<2x32x1x1xui16> loc(#loc17)
        %379 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 20480, out_size = 5760, buffer_addr = 0, buffer_size = 11520, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 7, 15, 23, 31, 39, 47, 55, 63, 71, 79, 87, 95, 103], h_slice = [8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], w_idx = [0], w_slice = [160], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x16x112x160xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x16x112x160xbf16> loc(#loc18)
        %380 = "tpu.Conv2D"(%379, %377, %378) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52], h_slice = [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [80], id = 9, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x112x160xbf16>, tensor<1x32x9x16xbf16>, tensor<2x32x1x1xui16>) -> tensor<1x32x56x80xbf16> loc(#loc9)
        %381 = "tpu.Store"(%380, %0) {ginfo = #tpu.lg<out_addr = 28672, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52], h_slice = [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [80], id = 10, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x32x56x80xbf16>, none) -> tensor<1x32x56x80xbf16, 430080 : i64> loc(#loc9)
        "tpu.Yield"(%381) : (tensor<1x32x56x80xbf16, 430080 : i64>) -> () loc(#loc9)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 10, -2, 8, 6, 7, -3, 9, 0, 1, 2], group_type = 0 : i64, hsecs = 14 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [-1, 2, -3, 1], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x3x224x320xbf16, 0 : i64>) -> tensor<1x32x56x80xbf16, 430080 : i64> loc(#loc9)
      %9 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc19)
      %10 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc20)
      %11 = "top.Weight"() : () -> tensor<1x32x1x32xbf16, 1099514728784 : i64> loc(#loc21)
      %12 = "top.Weight"() : () -> tensor<2x32x1x1xui16, 1099513043184 : i64> loc(#loc22)
      %13 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc23)
      %14 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc24)
      %15 = "tpu.Group"(%8) ({
        %371 = "tpu.Load"(%8) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 8, 16, 24, 32, 40, 48], h_slice = [8, 8, 8, 8, 8, 8, 8], w_idx = [0], w_slice = [80], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x56x80xbf16, 430080 : i64>) -> tensor<1x32x56x80xbf16> loc(#loc26)
        %372 = "tpu.Load"(%9) {do_bcast = true, ginfo = #tpu.lg<out_addr = 19456, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc27)
        %373 = "tpu.Load"(%10) {do_bcast = true, ginfo = #tpu.lg<out_addr = 19968, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc28)
        %374 = "tpu.Load"(%11) {do_bcast = false, ginfo = #tpu.lg<out_addr = 30720, out_size = 256, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [32], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x1x32xbf16, 1099514728784 : i64>) -> tensor<1x32x1x32xbf16> loc(#loc29)
        %375 = "tpu.Load"(%12) {do_bcast = false, ginfo = #tpu.lg<out_addr = 30976, out_size = 16, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x32x1x1xui16, 1099513043184 : i64>) -> tensor<2x32x1x1xui16> loc(#loc30)
        %376 = "tpu.LutBF16"(%371, %372, %373) {ginfo = #tpu.lg<out_addr = 0, out_size = 5120, buffer_addr = 8192, buffer_size = 10240, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 8, 16, 24, 32, 40, 48], h_slice = [8, 8, 8, 8, 8, 8, 8], w_idx = [0], w_slice = [80], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x56x80xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x32x56x80xbf16> loc(#loc31)
        %377 = "tpu.Load"(%13) {do_bcast = true, ginfo = #tpu.lg<out_addr = 18432, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc32)
        %378 = "tpu.Load"(%14) {do_bcast = true, ginfo = #tpu.lg<out_addr = 18944, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc33)
        %379 = "tpu.Conv2D"(%376, %374, %375) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 8, 16, 24, 32, 40, 48], h_slice = [8, 8, 8, 8, 8, 8, 8], w_idx = [0], w_slice = [80], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x56x80xbf16>, tensor<1x32x1x32xbf16>, tensor<2x32x1x1xui16>) -> tensor<1x32x56x80xbf16> loc(#loc34)
        %380 = "tpu.LutBF16"(%379, %377, %378) {ginfo = #tpu.lg<out_addr = 25600, out_size = 5120, buffer_addr = 0, buffer_size = 10240, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 8, 16, 24, 32, 40, 48], h_slice = [8, 8, 8, 8, 8, 8, 8], w_idx = [0], w_slice = [80], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x56x80xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x32x56x80xbf16> loc(#loc25)
        %381 = "tpu.Store"(%380, %0) {ginfo = #tpu.lg<out_addr = 25600, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 8, 16, 24, 32, 40, 48], h_slice = [8, 8, 8, 8, 8, 8, 8], w_idx = [0], w_slice = [80], id = 10, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x32x56x80xbf16>, none) -> tensor<1x32x56x80xbf16, 0 : i64> loc(#loc25)
        "tpu.Yield"(%381) : (tensor<1x32x56x80xbf16, 0 : i64>) -> () loc(#loc25)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 10, -2, 8, 6, 7, -3, 9, 0, 1, 2], group_type = 0 : i64, hsecs = 7 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [1, 2], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x56x80xbf16, 430080 : i64>) -> tensor<1x32x56x80xbf16, 0 : i64> loc(#loc25)
      %16 = "tpu.Slice"(%15, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 16, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x32x56x80xbf16, 0 : i64>, none, none, none, none) -> tensor<1x16x56x80xbf16, 0 : i64> loc(#loc35)
      %17 = "tpu.Slice"(%15, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 32, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 16, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x32x56x80xbf16, 0 : i64>, none, none, none, none) -> tensor<1x16x56x80xbf16, 143360 : i64> loc(#loc36)
      %18 = "top.Weight"() : () -> tensor<1x16x9x16xbf16, 1099512878448 : i64> loc(#loc37)
      %19 = "top.Weight"() : () -> tensor<2x16x1x1xui16, 1099512803568 : i64> loc(#loc38)
      %20 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc39)
      %21 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc40)
      %22 = "tpu.Group"(%17) ({
        %371 = "tpu.Load"(%17) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 13, 27, 41], h_slice = [15, 16, 16, 15], w_idx = [0], w_slice = [80], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x16x56x80xbf16, 143360 : i64>) -> tensor<1x16x56x80xbf16> loc(#loc42)
        %372 = "tpu.Load"(%18) {do_bcast = false, ginfo = #tpu.lg<out_addr = 5120, out_size = 576, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [16], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x16x9x16xbf16, 1099512878448 : i64>) -> tensor<1x16x9x16xbf16> loc(#loc43)
        %373 = "tpu.Load"(%19) {do_bcast = false, ginfo = #tpu.lg<out_addr = 6720, out_size = 8, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x16x1x1xui16, 1099512803568 : i64>) -> tensor<2x16x1x1xui16> loc(#loc44)
        %374 = "tpu.Load"(%20) {do_bcast = true, ginfo = #tpu.lg<out_addr = 5696, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc45)
        %375 = "tpu.Load"(%21) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6208, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc46)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 14, 28, 42], h_slice = [14, 14, 14, 14], w_idx = [0], w_slice = [80], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x56x80xbf16>, tensor<1x16x9x16xbf16>, tensor<2x16x1x1xui16>) -> tensor<1x16x56x80xbf16> loc(#loc47)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 20864, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 14, 28, 42], h_slice = [14, 14, 14, 14], w_idx = [0], w_slice = [80], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x16x56x80xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x16x56x80xbf16> loc(#loc41)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 14, 28, 42], h_slice = [14, 14, 14, 14], w_idx = [0], w_slice = [80], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x16x56x80xbf16>, none) -> tensor<1x16x56x80xbf16, 286720 : i64> loc(#loc41)
        "tpu.Yield"(%378) : (tensor<1x16x56x80xbf16, 286720 : i64>) -> () loc(#loc41)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 4 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [-2, 0, 1, 2], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x16x56x80xbf16, 143360 : i64>) -> tensor<1x16x56x80xbf16, 286720 : i64> loc(#loc41)
      %23 = "top.Weight"() : () -> tensor<1x16x9x16xbf16, 1099516281952 : i64> loc(#loc48)
      %24 = "top.Weight"() : () -> tensor<2x16x1x1xui16, 1099512692272 : i64> loc(#loc49)
      %25 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc50)
      %26 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc51)
      %27 = "tpu.Group"(%22) ({
        %371 = "tpu.Load"(%22) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 5120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 13, 27, 41], h_slice = [15, 16, 16, 15], w_idx = [0], w_slice = [80], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x16x56x80xbf16, 286720 : i64>) -> tensor<1x16x56x80xbf16> loc(#loc53)
        %372 = "tpu.Load"(%23) {do_bcast = false, ginfo = #tpu.lg<out_addr = 5120, out_size = 576, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [16], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x16x9x16xbf16, 1099516281952 : i64>) -> tensor<1x16x9x16xbf16> loc(#loc54)
        %373 = "tpu.Load"(%24) {do_bcast = false, ginfo = #tpu.lg<out_addr = 6720, out_size = 8, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x16x1x1xui16, 1099512692272 : i64>) -> tensor<2x16x1x1xui16> loc(#loc55)
        %374 = "tpu.Load"(%25) {do_bcast = true, ginfo = #tpu.lg<out_addr = 5696, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc56)
        %375 = "tpu.Load"(%26) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6208, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc57)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 14, 28, 42], h_slice = [14, 14, 14, 14], w_idx = [0], w_slice = [80], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x56x80xbf16>, tensor<1x16x9x16xbf16>, tensor<2x16x1x1xui16>) -> tensor<1x16x56x80xbf16> loc(#loc58)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 20864, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 14, 28, 42], h_slice = [14, 14, 14, 14], w_idx = [0], w_slice = [80], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x16x56x80xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x16x56x80xbf16> loc(#loc52)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 14, 28, 42], h_slice = [14, 14, 14, 14], w_idx = [0], w_slice = [80], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x16x56x80xbf16>, none) -> tensor<1x16x56x80xbf16, 716800 : i64> loc(#loc52)
        "tpu.Yield"(%378) : (tensor<1x16x56x80xbf16, 716800 : i64>) -> () loc(#loc52)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 4 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [0, 1, 2], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x16x56x80xbf16, 286720 : i64>) -> tensor<1x16x56x80xbf16, 716800 : i64> loc(#loc52)
      %28 = "tpu.Group"(%17, %27, %16) ({
        %371 = "tpu.Load"(%27) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 12, 23, 34, 45], h_slice = [12, 11, 11, 11, 11], w_idx = [0], w_slice = [80], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x16x56x80xbf16, 716800 : i64>) -> tensor<1x16x56x80xbf16> loc(#loc60)
        %372 = "tpu.Load"(%17) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 12, 23, 34, 45], h_slice = [12, 11, 11, 11, 11], w_idx = [0], w_slice = [80], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x16x56x80xbf16, 143360 : i64>) -> tensor<1x16x56x80xbf16> loc(#loc42)
        %373 = "tpu.Load"(%16) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 12, 23, 34, 45], h_slice = [12, 11, 11, 11, 11], w_idx = [0], w_slice = [80], id = 2, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x16x56x80xbf16, 0 : i64>) -> tensor<1x16x56x80xbf16> loc(#loc61)
        %374 = "tpu.Add"(%372, %371) {do_relu = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [16], d_idx = [0], d_slice = [1], h_idx = [0, 12, 23, 34, 45], h_slice = [12, 11, 11, 11, 11], w_idx = [0], w_slice = [80], id = 3, stage = 1, slice_idx = 0, group_type = 0>, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x16x56x80xbf16>, tensor<1x16x56x80xbf16>) -> tensor<1x16x56x80xbf16> loc(#loc62)
        %375 = "tpu.Concat"(%373, %372, %374) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 0, out_size = 11520, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [48], d_idx = [0], d_slice = [1], h_idx = [0, 12, 23, 34, 45], h_slice = [12, 11, 11, 11, 11], w_idx = [0], w_slice = [80], id = 4, stage = 1, slice_idx = 0, group_type = 0>, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x16x56x80xbf16>, tensor<1x16x56x80xbf16>, tensor<1x16x56x80xbf16>) -> tensor<1x48x56x80xbf16> loc(#loc59)
        %376 = "tpu.Store"(%375, %0) {ginfo = #tpu.lg<out_addr = 0, out_size = 11520, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [48], d_idx = [0], d_slice = [1], h_idx = [0, 12, 23, 34, 45], h_slice = [12, 11, 11, 11, 11], w_idx = [0], w_slice = [80], id = 5, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x48x56x80xbf16>, none) -> tensor<1x48x56x80xbf16, 286720 : i64> loc(#loc59)
        "tpu.Yield"(%376) : (tensor<1x48x56x80xbf16, 286720 : i64>) -> () loc(#loc59)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 3, 2, 5, -2, 4, 0, -3, 1], group_type = 0 : i64, hsecs = 5 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [-1, 2], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x16x56x80xbf16, 143360 : i64>, tensor<1x16x56x80xbf16, 716800 : i64>, tensor<1x16x56x80xbf16, 0 : i64>) -> tensor<1x48x56x80xbf16, 286720 : i64> loc(#loc59)
      %29 = "top.Weight"() : () -> tensor<1x32x1x48xbf16, 1099512725104 : i64> loc(#loc63)
      %30 = "top.Weight"() : () -> tensor<2x32x1x1xui16, 1099512902256 : i64> loc(#loc64)
      %31 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc65)
      %32 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc66)
      %33 = "top.Weight"() : () -> tensor<1x64x9x32xbf16, 1099515643232 : i64> loc(#loc67)
      %34 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099513043312 : i64> loc(#loc68)
      %35 = "tpu.Group"(%28) ({
        %371 = "tpu.Load"(%28) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 8640, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [48], d_idx = [0], d_slice = [1], h_idx = [0, 7, 15, 23, 31, 39, 47], h_slice = [8, 9, 9, 9, 9, 9, 9], w_idx = [0], w_slice = [80], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x48x56x80xbf16, 286720 : i64>) -> tensor<1x48x56x80xbf16> loc(#loc70)
        %372 = "tpu.Load"(%29) {do_bcast = false, ginfo = #tpu.lg<out_addr = 17408, out_size = 384, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [48], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x1x48xbf16, 1099512725104 : i64>) -> tensor<1x32x1x48xbf16> loc(#loc71)
        %373 = "tpu.Load"(%30) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12064, out_size = 16, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x32x1x1xui16, 1099512902256 : i64>) -> tensor<2x32x1x1xui16> loc(#loc72)
        %374 = "tpu.Load"(%31) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11520, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc73)
        %375 = "tpu.Load"(%32) {do_bcast = true, ginfo = #tpu.lg<out_addr = 16896, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc74)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 5760, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 7, 15, 23, 31, 39, 47], h_slice = [8, 9, 9, 9, 9, 9, 9], w_idx = [0], w_slice = [80], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x48x56x80xbf16>, tensor<1x32x1x48xbf16>, tensor<2x32x1x1xui16>) -> tensor<1x32x56x80xbf16> loc(#loc75)
        %377 = "tpu.Load"(%33) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [32], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x32xbf16, 1099515643232 : i64>) -> tensor<1x64x9x32xbf16> loc(#loc76)
        %378 = "tpu.Load"(%34) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12032, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099513043312 : i64>) -> tensor<2x64x1x1xui16> loc(#loc77)
        %379 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 26240, out_size = 5760, buffer_addr = 0, buffer_size = 11520, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 7, 15, 23, 31, 39, 47], h_slice = [8, 9, 9, 9, 9, 9, 9], w_idx = [0], w_slice = [80], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x56x80xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x32x56x80xbf16> loc(#loc78)
        %380 = "tpu.Conv2D"(%379, %377, %378) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8640, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 9, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x56x80xbf16>, tensor<1x64x9x32xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc69)
        %381 = "tpu.Store"(%380, %0) {ginfo = #tpu.lg<out_addr = 8640, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 10, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 0 : i64> loc(#loc69)
        "tpu.Yield"(%381) : (tensor<1x64x28x40xbf16, 0 : i64>) -> () loc(#loc69)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 10, -2, 8, 6, 7, -3, 9, 0, 1, 2], group_type = 0 : i64, hsecs = 7 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [-1, 1, 2, -3, 0], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [2], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x48x56x80xbf16, 286720 : i64>) -> tensor<1x64x28x40xbf16, 0 : i64> loc(#loc69)
      %36 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc79)
      %37 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc80)
      %38 = "top.Weight"() : () -> tensor<1x64x1x64xbf16, 1099513724880 : i64> loc(#loc81)
      %39 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099515199056 : i64> loc(#loc82)
      %40 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc83)
      %41 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc84)
      %42 = "tpu.Group"(%35) ({
        %371 = "tpu.Load"(%35) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 0 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc86)
        %372 = "tpu.Load"(%36) {do_bcast = true, ginfo = #tpu.lg<out_addr = 18688, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc87)
        %373 = "tpu.Load"(%37) {do_bcast = true, ginfo = #tpu.lg<out_addr = 18176, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc88)
        %374 = "tpu.Load"(%38) {do_bcast = false, ginfo = #tpu.lg<out_addr = 29440, out_size = 1024, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [64], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x64xbf16, 1099513724880 : i64>) -> tensor<1x64x1x64xbf16> loc(#loc89)
        %375 = "tpu.Load"(%39) {do_bcast = false, ginfo = #tpu.lg<out_addr = 19200, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099515199056 : i64>) -> tensor<2x64x1x1xui16> loc(#loc90)
        %376 = "tpu.LutBF16"(%371, %372, %373) {ginfo = #tpu.lg<out_addr = 0, out_size = 4480, buffer_addr = 8192, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc91)
        %377 = "tpu.Load"(%40) {do_bcast = true, ginfo = #tpu.lg<out_addr = 17152, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc92)
        %378 = "tpu.Load"(%41) {do_bcast = true, ginfo = #tpu.lg<out_addr = 17664, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc93)
        %379 = "tpu.Conv2D"(%376, %374, %375) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16>, tensor<1x64x1x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc94)
        %380 = "tpu.LutBF16"(%379, %377, %378) {ginfo = #tpu.lg<out_addr = 24960, out_size = 4480, buffer_addr = 0, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc85)
        %381 = "tpu.Store"(%380, %0) {ginfo = #tpu.lg<out_addr = 24960, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 10, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 143360 : i64> loc(#loc85)
        "tpu.Yield"(%381) : (tensor<1x64x28x40xbf16, 143360 : i64>) -> () loc(#loc85)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 10, -2, 8, 6, 7, -3, 9, 0, 1, 2], group_type = 0 : i64, hsecs = 4 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [2, 1, 0], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x28x40xbf16, 0 : i64>) -> tensor<1x64x28x40xbf16, 143360 : i64> loc(#loc85)
      %43 = "tpu.Slice"(%42, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 32, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x64x28x40xbf16, 143360 : i64>, none, none, none, none) -> tensor<1x32x28x40xbf16, 143360 : i64> loc(#loc95)
      %44 = "tpu.Slice"(%42, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 64, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 32, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x64x28x40xbf16, 143360 : i64>, none, none, none, none) -> tensor<1x32x28x40xbf16, 215040 : i64> loc(#loc96)
      %45 = "top.Weight"() : () -> tensor<1x32x9x32xbf16, 1099512883056 : i64> loc(#loc97)
      %46 = "top.Weight"() : () -> tensor<2x32x1x1xui16, 1099517041760 : i64> loc(#loc98)
      %47 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc99)
      %48 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc100)
      %49 = "tpu.Group"(%44) ({
        %371 = "tpu.Load"(%44) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4800, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 13], h_slice = [15, 15], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 215040 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc102)
        %372 = "tpu.Load"(%45) {do_bcast = false, ginfo = #tpu.lg<out_addr = 4800, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [32], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x9x32xbf16, 1099512883056 : i64>) -> tensor<1x32x9x32xbf16> loc(#loc103)
        %373 = "tpu.Load"(%46) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8128, out_size = 16, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x32x1x1xui16, 1099517041760 : i64>) -> tensor<2x32x1x1xui16> loc(#loc104)
        %374 = "tpu.Load"(%47) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7104, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc105)
        %375 = "tpu.Load"(%48) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7616, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc106)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x28x40xbf16>, tensor<1x32x9x32xbf16>, tensor<2x32x1x1xui16>) -> tensor<1x32x28x40xbf16> loc(#loc107)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 20864, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x32x28x40xbf16> loc(#loc101)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x32x28x40xbf16>, none) -> tensor<1x32x28x40xbf16, 0 : i64> loc(#loc101)
        "tpu.Yield"(%378) : (tensor<1x32x28x40xbf16, 0 : i64>) -> () loc(#loc101)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x28x40xbf16, 215040 : i64>) -> tensor<1x32x28x40xbf16, 0 : i64> loc(#loc101)
      %50 = "top.Weight"() : () -> tensor<1x32x9x32xbf16, 1099513063376 : i64> loc(#loc108)
      %51 = "top.Weight"() : () -> tensor<2x32x1x1xui16, 1099513527120 : i64> loc(#loc109)
      %52 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc110)
      %53 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc111)
      %54 = "tpu.Group"(%49) ({
        %371 = "tpu.Load"(%49) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4800, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 13], h_slice = [15, 15], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 0 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc113)
        %372 = "tpu.Load"(%50) {do_bcast = false, ginfo = #tpu.lg<out_addr = 4800, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [32], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x9x32xbf16, 1099513063376 : i64>) -> tensor<1x32x9x32xbf16> loc(#loc114)
        %373 = "tpu.Load"(%51) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8128, out_size = 16, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x32x1x1xui16, 1099513527120 : i64>) -> tensor<2x32x1x1xui16> loc(#loc115)
        %374 = "tpu.Load"(%52) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7616, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc116)
        %375 = "tpu.Load"(%53) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7104, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc117)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x28x40xbf16>, tensor<1x32x9x32xbf16>, tensor<2x32x1x1xui16>) -> tensor<1x32x28x40xbf16> loc(#loc118)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 20864, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x32x28x40xbf16> loc(#loc112)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x32x28x40xbf16>, none) -> tensor<1x32x28x40xbf16, 71680 : i64> loc(#loc112)
        "tpu.Yield"(%378) : (tensor<1x32x28x40xbf16, 71680 : i64>) -> () loc(#loc112)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x28x40xbf16, 0 : i64>) -> tensor<1x32x28x40xbf16, 71680 : i64> loc(#loc112)
      %55 = "tpu.Add"(%44, %54) {do_relu = false, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x32x28x40xbf16, 215040 : i64>, tensor<1x32x28x40xbf16, 71680 : i64>) -> tensor<1x32x28x40xbf16, 0 : i64> loc(#loc119)
      %56 = "top.Weight"() : () -> tensor<1x32x9x32xbf16, 1099513044080 : i64> loc(#loc120)
      %57 = "top.Weight"() : () -> tensor<2x32x1x1xui16, 1099514022096 : i64> loc(#loc121)
      %58 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc122)
      %59 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc123)
      %60 = "tpu.Group"(%55) ({
        %371 = "tpu.Load"(%55) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4800, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 13], h_slice = [15, 15], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 0 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc125)
        %372 = "tpu.Load"(%56) {do_bcast = false, ginfo = #tpu.lg<out_addr = 4800, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [32], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x9x32xbf16, 1099513044080 : i64>) -> tensor<1x32x9x32xbf16> loc(#loc126)
        %373 = "tpu.Load"(%57) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8128, out_size = 16, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x32x1x1xui16, 1099514022096 : i64>) -> tensor<2x32x1x1xui16> loc(#loc127)
        %374 = "tpu.Load"(%58) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7104, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc128)
        %375 = "tpu.Load"(%59) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7616, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc129)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x28x40xbf16>, tensor<1x32x9x32xbf16>, tensor<2x32x1x1xui16>) -> tensor<1x32x28x40xbf16> loc(#loc130)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 20864, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x32x28x40xbf16> loc(#loc124)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x32x28x40xbf16>, none) -> tensor<1x32x28x40xbf16, 71680 : i64> loc(#loc124)
        "tpu.Yield"(%378) : (tensor<1x32x28x40xbf16, 71680 : i64>) -> () loc(#loc124)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x28x40xbf16, 0 : i64>) -> tensor<1x32x28x40xbf16, 71680 : i64> loc(#loc124)
      %61 = "top.Weight"() : () -> tensor<1x32x9x32xbf16, 1099515032656 : i64> loc(#loc131)
      %62 = "top.Weight"() : () -> tensor<2x32x1x1xui16, 1099513526992 : i64> loc(#loc132)
      %63 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc133)
      %64 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc134)
      %65 = "top.Weight"() : () -> tensor<1x64x1x128xbf16, 1099513806800 : i64> loc(#loc135)
      %66 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099512728432 : i64> loc(#loc136)
      %67 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc137)
      %68 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc138)
      %69 = "tpu.Group"(%60, %55, %43, %44) ({
        %371 = "tpu.Load"(%60) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 2880, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 6, 13, 20], h_slice = [8, 9, 9, 8], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 71680 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc140)
        %372 = "tpu.Load"(%61) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [32], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x9x32xbf16, 1099515032656 : i64>) -> tensor<1x32x9x32xbf16> loc(#loc141)
        %373 = "tpu.Load"(%62) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12128, out_size = 16, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x32x1x1xui16, 1099513526992 : i64>) -> tensor<2x32x1x1xui16> loc(#loc142)
        %374 = "tpu.Load"(%63) {do_bcast = true, ginfo = #tpu.lg<out_addr = 30912, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc143)
        %375 = "tpu.Load"(%64) {do_bcast = true, ginfo = #tpu.lg<out_addr = 31424, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc144)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16640, out_size = 2240, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x28x40xbf16>, tensor<1x32x9x32xbf16>, tensor<2x32x1x1xui16>) -> tensor<1x32x28x40xbf16> loc(#loc145)
        %377 = "tpu.Load"(%55) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2240, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 0 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc125)
        %378 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 0, out_size = 2240, buffer_addr = 4096, buffer_size = 4480, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x32x28x40xbf16> loc(#loc146)
        %379 = "tpu.Load"(%43) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 2240, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 143360 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc147)
        %380 = "tpu.Load"(%44) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2240, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 215040 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc102)
        %381 = "tpu.Add"(%377, %378) {do_relu = false, ginfo = #tpu.lg<out_addr = 16640, out_size = 2240, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 10, stage = 1, slice_idx = 0, group_type = 0>, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x32x28x40xbf16>, tensor<1x32x28x40xbf16>) -> tensor<1x32x28x40xbf16> loc(#loc148)
        %382 = "tpu.Load"(%65) {do_bcast = false, ginfo = #tpu.lg<out_addr = 14592, out_size = 2048, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [128], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x128xbf16, 1099513806800 : i64>) -> tensor<1x64x1x128xbf16> loc(#loc149)
        %383 = "tpu.Load"(%66) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12096, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 12, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099512728432 : i64>) -> tensor<2x64x1x1xui16> loc(#loc150)
        %384 = "tpu.Concat"(%379, %380, %377, %381) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 0, out_size = 8960, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 13, stage = 1, slice_idx = 0, group_type = 0>, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x32x28x40xbf16>, tensor<1x32x28x40xbf16>, tensor<1x32x28x40xbf16>, tensor<1x32x28x40xbf16>) -> tensor<1x128x28x40xbf16> loc(#loc151)
        %385 = "tpu.Load"(%67) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11072, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 14, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc152)
        %386 = "tpu.Load"(%68) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11584, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 15, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc153)
        %387 = "tpu.Conv2D"(%384, %382, %383) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 25600, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 16, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x28x40xbf16>, tensor<1x64x1x128xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc154)
        %388 = "tpu.LutBF16"(%387, %385, %386) {ginfo = #tpu.lg<out_addr = 0, out_size = 4480, buffer_addr = 16640, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 17, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc139)
        %389 = "tpu.Store"(%388, %0) {ginfo = #tpu.lg<out_addr = 0, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 18, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 860160 : i64> loc(#loc139)
        "tpu.Yield"(%389) : (tensor<1x64x28x40xbf16, 860160 : i64>) -> () loc(#loc139)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 18, -2, 7, 6, -3, 10, 8, 9, -4, 13, 11, 12, -5, 16, 14, 15, -6, 17, 0, 1, 2], group_type = 0 : i64, hsecs = 4 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x28x40xbf16, 71680 : i64>, tensor<1x32x28x40xbf16, 0 : i64>, tensor<1x32x28x40xbf16, 143360 : i64>, tensor<1x32x28x40xbf16, 215040 : i64>) -> tensor<1x64x28x40xbf16, 860160 : i64> loc(#loc139)
      %70 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x64xbf16, 1099513082832 : i64> loc(#loc155)
      %71 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099513724368 : i64> loc(#loc156)
      %72 = "tpu.Conv2D"(%69, %70, %71) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16, 860160 : i64>, tensor<1x128x9x64xbf16, 1099513082832 : i64>, tensor<2x128x1x1xui16, 1099513724368 : i64>) -> tensor<1x128x14x20xbf16, 0 : i64> loc(#loc157)
      %73 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc158)
      %74 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc159)
      %75 = "tpu.LutBF16"(%72, %73, %74) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16, 0 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x128x14x20xbf16, 71680 : i64> loc(#loc160)
      %76 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x1x128xbf16, 1099512692336 : i64> loc(#loc161)
      %77 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099513043568 : i64> loc(#loc162)
      %78 = "tpu.Conv2D"(%75, %76, %77) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16, 71680 : i64>, tensor<1x128x1x128xbf16, 1099512692336 : i64>, tensor<2x128x1x1xui16, 1099513043568 : i64>) -> tensor<1x128x14x20xbf16, 143360 : i64> loc(#loc163)
      %79 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc164)
      %80 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc165)
      %81 = "tpu.LutBF16"(%78, %79, %80) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16, 143360 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x128x14x20xbf16, 0 : i64> loc(#loc166)
      %82 = "tpu.Slice"(%81, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 64, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x128x14x20xbf16, 0 : i64>, none, none, none, none) -> tensor<1x64x14x20xbf16, 0 : i64> loc(#loc167)
      %83 = "tpu.Slice"(%81, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 128, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 64, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x128x14x20xbf16, 0 : i64>, none, none, none, none) -> tensor<1x64x14x20xbf16, 35840 : i64> loc(#loc168)
      %84 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099513304272 : i64> loc(#loc169)
      %85 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099512692016 : i64> loc(#loc170)
      %86 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc171)
      %87 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc172)
      %88 = "tpu.Group"(%83) ({
        %371 = "tpu.Load"(%83) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 35840 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc174)
        %372 = "tpu.Load"(%84) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099513304272 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc175)
        %373 = "tpu.Load"(%85) {do_bcast = false, ginfo = #tpu.lg<out_addr = 9728, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099512692016 : i64>) -> tensor<2x64x1x1xui16> loc(#loc176)
        %374 = "tpu.Load"(%86) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc177)
        %375 = "tpu.Load"(%87) {do_bcast = true, ginfo = #tpu.lg<out_addr = 9216, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc178)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc179)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 25088, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc173)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 71680 : i64> loc(#loc173)
        "tpu.Yield"(%378) : (tensor<1x64x14x20xbf16, 71680 : i64>) -> () loc(#loc173)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 35840 : i64>) -> tensor<1x64x14x20xbf16, 71680 : i64> loc(#loc173)
      %89 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099512729200 : i64> loc(#loc180)
      %90 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099512387120 : i64> loc(#loc181)
      %91 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc182)
      %92 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc183)
      %93 = "tpu.Group"(%88, %83) ({
        %371 = "tpu.Load"(%88) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 71680 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc185)
        %372 = "tpu.Load"(%89) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099512729200 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc186)
        %373 = "tpu.Load"(%90) {do_bcast = false, ginfo = #tpu.lg<out_addr = 14848, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099512387120 : i64>) -> tensor<2x64x1x1xui16> loc(#loc187)
        %374 = "tpu.Load"(%91) {do_bcast = true, ginfo = #tpu.lg<out_addr = 30976, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc188)
        %375 = "tpu.Load"(%92) {do_bcast = true, ginfo = #tpu.lg<out_addr = 14880, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc189)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc190)
        %377 = "tpu.Load"(%83) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 35840 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc174)
        %378 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 24576, out_size = 2304, buffer_addr = 9216, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc191)
        %379 = "tpu.Add"(%377, %378) {do_relu = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 8, stage = 1, slice_idx = 0, group_type = 0>, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc184)
        %380 = "tpu.Store"(%379, %0) {ginfo = #tpu.lg<out_addr = 28672, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 107520 : i64> loc(#loc184)
        "tpu.Yield"(%380) : (tensor<1x64x14x20xbf16, 107520 : i64>) -> () loc(#loc184)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 9, -2, 7, 6, -3, 8, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 71680 : i64>, tensor<1x64x14x20xbf16, 35840 : i64>) -> tensor<1x64x14x20xbf16, 107520 : i64> loc(#loc184)
      %94 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099513733072 : i64> loc(#loc192)
      %95 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099512902000 : i64> loc(#loc193)
      %96 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc194)
      %97 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc195)
      %98 = "tpu.Group"(%93) ({
        %371 = "tpu.Load"(%93) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 107520 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc197)
        %372 = "tpu.Load"(%94) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099513733072 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc198)
        %373 = "tpu.Load"(%95) {do_bcast = false, ginfo = #tpu.lg<out_addr = 9728, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099512902000 : i64>) -> tensor<2x64x1x1xui16> loc(#loc199)
        %374 = "tpu.Load"(%96) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc200)
        %375 = "tpu.Load"(%97) {do_bcast = true, ginfo = #tpu.lg<out_addr = 9216, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc201)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc202)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 25088, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc196)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 143360 : i64> loc(#loc196)
        "tpu.Yield"(%378) : (tensor<1x64x14x20xbf16, 143360 : i64>) -> () loc(#loc196)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 107520 : i64>) -> tensor<1x64x14x20xbf16, 143360 : i64> loc(#loc196)
      %99 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x64xbf16, 1099515125328 : i64> loc(#loc203)
      %100 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099515494496 : i64> loc(#loc204)
      %101 = "tpu.Conv2D"(%98, %99, %100) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16, 143360 : i64>, tensor<1x64x9x64xbf16, 1099515125328 : i64>, tensor<2x64x1x1xui16, 1099515494496 : i64>) -> tensor<1x64x14x20xbf16, 179200 : i64> loc(#loc205)
      %102 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc206)
      %103 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc207)
      %104 = "top.Weight"() : () -> tensor<1x128x1x256xbf16, 1099517042928 : i64> loc(#loc208)
      %105 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099513378000 : i64> loc(#loc209)
      %106 = "tpu.Group"(%101, %93, %82, %83) ({
        %371 = "tpu.Load"(%101) {do_bcast = false, ginfo = #tpu.lg<out_addr = 17408, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 179200 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc211)
        %372 = "tpu.Load"(%102) {do_bcast = true, ginfo = #tpu.lg<out_addr = 19712, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc212)
        %373 = "tpu.Load"(%103) {do_bcast = true, ginfo = #tpu.lg<out_addr = 26880, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc213)
        %374 = "tpu.Load"(%93) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 107520 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc197)
        %375 = "tpu.LutBF16"(%371, %372, %373) {ginfo = #tpu.lg<out_addr = 8192, out_size = 2304, buffer_addr = 12288, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc214)
        %376 = "tpu.Load"(%82) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 0 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc215)
        %377 = "tpu.Load"(%83) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 35840 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc174)
        %378 = "tpu.Add"(%374, %375) {do_relu = false, ginfo = #tpu.lg<out_addr = 17408, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc216)
        %379 = "tpu.Load"(%104) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 8192, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [256], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x256xbf16, 1099517042928 : i64>) -> tensor<1x128x1x256xbf16> loc(#loc217)
        %380 = "tpu.Load"(%105) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20224, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099513378000 : i64>) -> tensor<2x128x1x1xui16> loc(#loc218)
        %381 = "tpu.Concat"(%376, %377, %374, %378) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 10, stage = 1, slice_idx = 0, group_type = 0>, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>) -> tensor<1x256x14x20xbf16> loc(#loc219)
        %382 = "tpu.Conv2D"(%381, %379, %380) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 11, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x14x20xbf16>, tensor<1x128x1x256xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x14x20xbf16> loc(#loc210)
        %383 = "tpu.Store"(%382, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 12, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x14x20xbf16>, none) -> tensor<1x128x14x20xbf16, 215040 : i64> loc(#loc210)
        "tpu.Yield"(%383) : (tensor<1x128x14x20xbf16, 215040 : i64>) -> () loc(#loc210)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 4, 3, 12, -2, 7, 5, 6, -3, 10, 8, 9, -4, 11, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 179200 : i64>, tensor<1x64x14x20xbf16, 107520 : i64>, tensor<1x64x14x20xbf16, 0 : i64>, tensor<1x64x14x20xbf16, 35840 : i64>) -> tensor<1x128x14x20xbf16, 215040 : i64> loc(#loc210)
      %107 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc220)
      %108 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc221)
      %109 = "tpu.LutBF16"(%106, %107, %108) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16, 215040 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x128x14x20xbf16, 143360 : i64> loc(#loc222)
      %110 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x9x128xbf16, 1099514046800 : i64> loc(#loc223)
      %111 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099513378512 : i64> loc(#loc224)
      %112 = "tpu.Conv2D"(%109, %110, %111) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16, 143360 : i64>, tensor<1x256x9x128xbf16, 1099514046800 : i64>, tensor<2x256x1x1xui16, 1099513378512 : i64>) -> tensor<1x256x7x10xbf16, 215040 : i64> loc(#loc225)
      %113 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc226)
      %114 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc227)
      %115 = "tpu.LutBF16"(%112, %113, %114) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x7x10xbf16, 215040 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x256x7x10xbf16, 250880 : i64> loc(#loc228)
      %116 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x256xbf16, 1099512902896 : i64> loc(#loc229)
      %117 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099513081808 : i64> loc(#loc230)
      %118 = "tpu.Conv2D"(%115, %116, %117) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16, 250880 : i64>, tensor<1x256x1x256xbf16, 1099512902896 : i64>, tensor<2x256x1x1xui16, 1099513081808 : i64>) -> tensor<1x256x7x10xbf16, 215040 : i64> loc(#loc231)
      %119 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc232)
      %120 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc233)
      %121 = "tpu.LutBF16"(%118, %119, %120) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x7x10xbf16, 215040 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x256x7x10xbf16, 286720 : i64> loc(#loc234)
      %122 = "tpu.Slice"(%121, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 128, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x256x7x10xbf16, 286720 : i64>, none, none, none, none) -> tensor<1x128x7x10xbf16, 286720 : i64> loc(#loc235)
      %123 = "tpu.Slice"(%121, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 256, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 128, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x256x7x10xbf16, 286720 : i64>, none, none, none, none) -> tensor<1x128x7x10xbf16, 304640 : i64> loc(#loc236)
      %124 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099511730224 : i64> loc(#loc237)
      %125 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099512802928 : i64> loc(#loc238)
      %126 = "tpu.Conv2D"(%123, %124, %125) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 304640 : i64>, tensor<1x128x9x128xbf16, 1099511730224 : i64>, tensor<2x128x1x1xui16, 1099512802928 : i64>) -> tensor<1x128x7x10xbf16, 215040 : i64> loc(#loc239)
      %127 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc240)
      %128 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc241)
      %129 = "tpu.LutBF16"(%126, %127, %128) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 215040 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x128x7x10xbf16, 232960 : i64> loc(#loc242)
      %130 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099512026160 : i64> loc(#loc243)
      %131 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099512682288 : i64> loc(#loc244)
      %132 = "tpu.Conv2D"(%129, %130, %131) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 232960 : i64>, tensor<1x128x9x128xbf16, 1099512026160 : i64>, tensor<2x128x1x1xui16, 1099512682288 : i64>) -> tensor<1x128x7x10xbf16, 215040 : i64> loc(#loc245)
      %133 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc246)
      %134 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc247)
      %135 = "tpu.LutBF16"(%132, %133, %134) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 215040 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x128x7x10xbf16, 232960 : i64> loc(#loc248)
      %136 = "tpu.Add"(%123, %135) {do_relu = false, is_scalar = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x7x10xbf16, 304640 : i64>, tensor<1x128x7x10xbf16, 232960 : i64>) -> tensor<1x128x7x10xbf16, 215040 : i64> loc(#loc249)
      %137 = "tpu.Concat"(%122, %123, %136) {axis = 1 : si32, do_relu = false, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x7x10xbf16, 286720 : i64>, tensor<1x128x7x10xbf16, 304640 : i64>, tensor<1x128x7x10xbf16, 215040 : i64>) -> tensor<1x384x7x10xbf16, 232960 : i64> loc(#loc250)
      %138 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x384xbf16, 1099514761552 : i64> loc(#loc251)
      %139 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099512025136 : i64> loc(#loc252)
      %140 = "tpu.Conv2D"(%137, %138, %139) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x384x7x10xbf16, 232960 : i64>, tensor<1x256x1x384xbf16, 1099514761552 : i64>, tensor<2x256x1x1xui16, 1099512025136 : i64>) -> tensor<1x256x7x10xbf16, 286720 : i64> loc(#loc253)
      %141 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc254)
      %142 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc255)
      %143 = "tpu.LutBF16"(%140, %141, %142) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x7x10xbf16, 286720 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x256x7x10xbf16, 215040 : i64> loc(#loc256)
      %144 = "top.Weight"() : () -> tensor<1x128x1x256xbf16, 1099512321328 : i64> loc(#loc257)
      %145 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099513723856 : i64> loc(#loc258)
      %146 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc259)
      %147 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc260)
      %148:4 = "tpu.Group"(%143) ({
        %371 = "tpu.Load"(%143) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [256], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x256x7x10xbf16, 215040 : i64>) -> tensor<1x256x7x10xbf16> loc(#loc265)
        %372 = "tpu.Load"(%144) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 8192, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [256], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x256xbf16, 1099512321328 : i64>) -> tensor<1x128x1x256xbf16> loc(#loc266)
        %373 = "tpu.Load"(%145) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099513723856 : i64>) -> tensor<2x128x1x1xui16> loc(#loc267)
        %374 = "tpu.Load"(%146) {do_bcast = true, ginfo = #tpu.lg<out_addr = 22784, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc268)
        %375 = "tpu.Load"(%147) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc269)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16>, tensor<1x128x1x256xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x7x10xbf16> loc(#loc270)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 0, out_size = 2304, buffer_addr = 4096, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x7x10xbf16> loc(#loc261)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 0, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x7x10xbf16>, none) -> tensor<1x128x7x10xbf16, 250880 : i64> loc(#loc261)
        %379 = "tpu.Pool2D"(%377) {count_include_pad = false, do_relu = false, first_round_mode = #tpu<round_mode HalfAwayFromZero>, ginfo = #tpu.lg<out_addr = 4096, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 8, stage = 1, slice_idx = 0, group_type = 0>, is_adaptive = false, keepdims = true, kernel_shape = [5, 5], pad_value = 0 : i64, pads = [2, 2, 2, 2], pool_mode = #tpu<pool_mode Max>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfAwayFromZero>, strides = [1, 1]} : (tensor<1x128x7x10xbf16>) -> tensor<1x128x7x10xbf16> loc(#loc262)
        %380 = "tpu.Store"(%379, %0) {ginfo = #tpu.lg<out_addr = 4096, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 9, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x7x10xbf16>, none) -> tensor<1x128x7x10xbf16, 268800 : i64> loc(#loc262)
        %381 = "tpu.Pool2D"(%379) {count_include_pad = false, do_relu = false, first_round_mode = #tpu<round_mode HalfAwayFromZero>, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 10, stage = 1, slice_idx = 0, group_type = 0>, is_adaptive = false, keepdims = true, kernel_shape = [5, 5], pad_value = 0 : i64, pads = [2, 2, 2, 2], pool_mode = #tpu<pool_mode Max>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfAwayFromZero>, strides = [1, 1]} : (tensor<1x128x7x10xbf16>) -> tensor<1x128x7x10xbf16> loc(#loc263)
        %382 = "tpu.Store"(%381, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 11, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x7x10xbf16>, none) -> tensor<1x128x7x10xbf16, 286720 : i64> loc(#loc263)
        %383 = "tpu.Pool2D"(%381) {count_include_pad = false, do_relu = false, first_round_mode = #tpu<round_mode HalfAwayFromZero>, ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 12, stage = 1, slice_idx = 0, group_type = 0>, is_adaptive = false, keepdims = true, kernel_shape = [5, 5], pad_value = 0 : i64, pads = [2, 2, 2, 2], pool_mode = #tpu<pool_mode Max>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfAwayFromZero>, strides = [1, 1]} : (tensor<1x128x7x10xbf16>) -> tensor<1x128x7x10xbf16> loc(#loc264)
        %384 = "tpu.Store"(%383, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 13, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x7x10xbf16>, none) -> tensor<1x128x7x10xbf16, 304640 : i64> loc(#loc264)
        "tpu.Yield"(%378, %380, %382, %384) : (tensor<1x128x7x10xbf16, 250880 : i64>, tensor<1x128x7x10xbf16, 268800 : i64>, tensor<1x128x7x10xbf16, 286720 : i64>, tensor<1x128x7x10xbf16, 304640 : i64>) -> () loc(#loc635)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 13, -2, 6, -3, 8, 7, -4, 10, 9, -5, 12, 11, 0, 1, 2], group_type = 0 : i64, hsecs = 1 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x256x7x10xbf16, 215040 : i64>) -> (tensor<1x128x7x10xbf16, 250880 : i64>, tensor<1x128x7x10xbf16, 268800 : i64>, tensor<1x128x7x10xbf16, 286720 : i64>, tensor<1x128x7x10xbf16, 304640 : i64>) loc(#loc635)
      %149 = "tpu.Concat"(%148#0, %148#1, %148#2, %148#3) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x7x10xbf16, 250880 : i64>, tensor<1x128x7x10xbf16, 268800 : i64>, tensor<1x128x7x10xbf16, 286720 : i64>, tensor<1x128x7x10xbf16, 304640 : i64>) -> tensor<1x512x7x10xbf16, 250880 : i64> loc(#loc271)
      %150 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x512xbf16, 1099516631136 : i64> loc(#loc272)
      %151 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099513042160 : i64> loc(#loc273)
      %152 = "tpu.Conv2D"(%149, %150, %151) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x512x7x10xbf16, 250880 : i64>, tensor<1x256x1x512xbf16, 1099516631136 : i64>, tensor<2x256x1x1xui16, 1099513042160 : i64>) -> tensor<1x256x7x10xbf16, 215040 : i64> loc(#loc274)
      %153 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc275)
      %154 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc276)
      %155 = "tpu.LutBF16"(%152, %153, %154) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x7x10xbf16, 215040 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x256x7x10xbf16, 519680 : i64> loc(#loc277)
      %156 = "top.Weight"() : () -> tensor<1x256x2x2xbf16, 1099511727920 : i64> loc(#loc278)
      %157 = "tpu.Deconv"(%155, %156, %0) {dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 256 : i64, inserts = [0, 0], kernel_shape = [2, 2], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, strides = [2, 2], with_bias = false} : (tensor<1x256x7x10xbf16, 519680 : i64>, tensor<1x256x2x2xbf16, 1099511727920 : i64>, none) -> tensor<1x256x14x20xbf16, 0 : i64> loc(#loc279)
      %158 = "tpu.Concat"(%157, %109) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x256x14x20xbf16, 0 : i64>, tensor<1x128x14x20xbf16, 143360 : i64>) -> tensor<1x384x14x20xbf16, 0 : i64> loc(#loc280)
      %159 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x1x384xbf16, 1099511629616 : i64> loc(#loc281)
      %160 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099512902384 : i64> loc(#loc282)
      %161 = "tpu.Conv2D"(%158, %159, %160) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x384x14x20xbf16, 0 : i64>, tensor<1x128x1x384xbf16, 1099511629616 : i64>, tensor<2x128x1x1xui16, 1099512902384 : i64>) -> tensor<1x128x14x20xbf16, 215040 : i64> loc(#loc283)
      %162 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc284)
      %163 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc285)
      %164 = "tpu.LutBF16"(%161, %162, %163) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16, 215040 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x128x14x20xbf16, 0 : i64> loc(#loc286)
      %165 = "tpu.Slice"(%164, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 64, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x128x14x20xbf16, 0 : i64>, none, none, none, none) -> tensor<1x64x14x20xbf16, 0 : i64> loc(#loc287)
      %166 = "tpu.Slice"(%164, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 128, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 64, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x128x14x20xbf16, 0 : i64>, none, none, none, none) -> tensor<1x64x14x20xbf16, 35840 : i64> loc(#loc288)
      %167 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099513823440 : i64> loc(#loc289)
      %168 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099513971408 : i64> loc(#loc290)
      %169 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc291)
      %170 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc292)
      %171 = "tpu.Group"(%166) ({
        %371 = "tpu.Load"(%166) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 35840 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc294)
        %372 = "tpu.Load"(%167) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099513823440 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc295)
        %373 = "tpu.Load"(%168) {do_bcast = false, ginfo = #tpu.lg<out_addr = 9728, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099513971408 : i64>) -> tensor<2x64x1x1xui16> loc(#loc296)
        %374 = "tpu.Load"(%169) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc297)
        %375 = "tpu.Load"(%170) {do_bcast = true, ginfo = #tpu.lg<out_addr = 9216, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc298)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc299)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 25088, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc293)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 71680 : i64> loc(#loc293)
        "tpu.Yield"(%378) : (tensor<1x64x14x20xbf16, 71680 : i64>) -> () loc(#loc293)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 35840 : i64>) -> tensor<1x64x14x20xbf16, 71680 : i64> loc(#loc293)
      %172 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x64xbf16, 1099515763296 : i64> loc(#loc300)
      %173 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099512386864 : i64> loc(#loc301)
      %174 = "tpu.Conv2D"(%171, %172, %173) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16, 71680 : i64>, tensor<1x64x9x64xbf16, 1099515763296 : i64>, tensor<2x64x1x1xui16, 1099512386864 : i64>) -> tensor<1x64x14x20xbf16, 107520 : i64> loc(#loc302)
      %175 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc303)
      %176 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc304)
      %177 = "top.Weight"() : () -> tensor<1x128x1x192xbf16, 1099513971920 : i64> loc(#loc305)
      %178 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099512728688 : i64> loc(#loc306)
      %179 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc307)
      %180 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc308)
      %181 = "tpu.Group"(%174, %165, %166) ({
        %371 = "tpu.Load"(%174) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 107520 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc310)
        %372 = "tpu.Load"(%175) {do_bcast = true, ginfo = #tpu.lg<out_addr = 31488, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc311)
        %373 = "tpu.Load"(%176) {do_bcast = true, ginfo = #tpu.lg<out_addr = 32000, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc312)
        %374 = "tpu.Load"(%165) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 0 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc313)
        %375 = "tpu.Load"(%166) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 35840 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc294)
        %376 = "tpu.LutBF16"(%371, %372, %373) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 26880, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc314)
        %377 = "tpu.Load"(%177) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 6144, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [192], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x192xbf16, 1099513971920 : i64>) -> tensor<1x128x1x192xbf16> loc(#loc315)
        %378 = "tpu.Load"(%178) {do_bcast = false, ginfo = #tpu.lg<out_addr = 32512, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099512728688 : i64>) -> tensor<2x128x1x1xui16> loc(#loc316)
        %379 = "tpu.Concat"(%374, %375, %376) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 6912, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [192], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 8, stage = 1, slice_idx = 0, group_type = 0>, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>) -> tensor<1x192x14x20xbf16> loc(#loc317)
        %380 = "tpu.Load"(%179) {do_bcast = true, ginfo = #tpu.lg<out_addr = 15104, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc318)
        %381 = "tpu.Load"(%180) {do_bcast = true, ginfo = #tpu.lg<out_addr = 15616, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 10, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc319)
        %382 = "tpu.Conv2D"(%379, %377, %378) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 11, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x192x14x20xbf16>, tensor<1x128x1x192xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x14x20xbf16> loc(#loc320)
        %383 = "tpu.LutBF16"(%382, %380, %381) {ginfo = #tpu.lg<out_addr = 6144, out_size = 4608, buffer_addr = 20992, buffer_size = 9216, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 12, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x14x20xbf16> loc(#loc309)
        %384 = "tpu.Store"(%383, %0) {ginfo = #tpu.lg<out_addr = 6144, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 13, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x14x20xbf16>, none) -> tensor<1x128x14x20xbf16, 250880 : i64> loc(#loc309)
        "tpu.Yield"(%384) : (tensor<1x128x14x20xbf16, 250880 : i64>) -> () loc(#loc309)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 13, -2, 8, 6, 7, -3, 11, 9, 10, -4, 12, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 107520 : i64>, tensor<1x64x14x20xbf16, 0 : i64>, tensor<1x64x14x20xbf16, 35840 : i64>) -> tensor<1x128x14x20xbf16, 250880 : i64> loc(#loc309)
      %182 = "top.Weight"() : () -> tensor<1x128x2x2xbf16, 1099514021072 : i64> loc(#loc321)
      %183 = "tpu.Deconv"(%181, %182, %0) {dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 128 : i64, inserts = [0, 0], kernel_shape = [2, 2], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, strides = [2, 2], with_bias = false} : (tensor<1x128x14x20xbf16, 250880 : i64>, tensor<1x128x2x2xbf16, 1099514021072 : i64>, none) -> tensor<1x128x28x40xbf16, 573440 : i64> loc(#loc322)
      %184 = "tpu.Concat"(%183, %69) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x28x40xbf16, 573440 : i64>, tensor<1x64x28x40xbf16, 860160 : i64>) -> tensor<1x192x28x40xbf16, 573440 : i64> loc(#loc323)
      %185 = "top.Weight"() : () -> tensor<1x64x1x192xbf16, 1099514022224 : i64> loc(#loc324)
      %186 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099513823184 : i64> loc(#loc325)
      %187 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc326)
      %188 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc327)
      %189 = "tpu.Group"(%184) ({
        %371 = "tpu.Load"(%184) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 11520, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [192], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x192x28x40xbf16, 573440 : i64>) -> tensor<1x192x28x40xbf16> loc(#loc329)
        %372 = "tpu.Load"(%185) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 3072, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [192], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x192xbf16, 1099514022224 : i64>) -> tensor<1x64x1x192xbf16> loc(#loc330)
        %373 = "tpu.Load"(%186) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12032, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099513823184 : i64>) -> tensor<2x64x1x1xui16> loc(#loc331)
        %374 = "tpu.Load"(%187) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc332)
        %375 = "tpu.Load"(%188) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11520, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc333)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x192x28x40xbf16>, tensor<1x64x1x192xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc334)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 16384, out_size = 3840, buffer_addr = 25088, buffer_size = 7680, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc328)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6, 12, 18, 23], h_slice = [6, 6, 6, 5, 5], w_idx = [0], w_slice = [40], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 0 : i64> loc(#loc328)
        "tpu.Yield"(%378) : (tensor<1x64x28x40xbf16, 0 : i64>) -> () loc(#loc328)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 5 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x192x28x40xbf16, 573440 : i64>) -> tensor<1x64x28x40xbf16, 0 : i64> loc(#loc328)
      %190 = "tpu.Slice"(%189, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 32, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x64x28x40xbf16, 0 : i64>, none, none, none, none) -> tensor<1x32x28x40xbf16, 0 : i64> loc(#loc335)
      %191 = "tpu.Slice"(%189, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 64, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 32, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x64x28x40xbf16, 0 : i64>, none, none, none, none) -> tensor<1x32x28x40xbf16, 71680 : i64> loc(#loc336)
      %192 = "top.Weight"() : () -> tensor<1x32x9x32xbf16, 1099514710352 : i64> loc(#loc337)
      %193 = "top.Weight"() : () -> tensor<2x32x1x1xui16, 1099514958160 : i64> loc(#loc338)
      %194 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc339)
      %195 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc340)
      %196 = "tpu.Group"(%191) ({
        %371 = "tpu.Load"(%191) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4800, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 13], h_slice = [15, 15], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 71680 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc342)
        %372 = "tpu.Load"(%192) {do_bcast = false, ginfo = #tpu.lg<out_addr = 4800, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [32], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x9x32xbf16, 1099514710352 : i64>) -> tensor<1x32x9x32xbf16> loc(#loc343)
        %373 = "tpu.Load"(%193) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8128, out_size = 16, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x32x1x1xui16, 1099514958160 : i64>) -> tensor<2x32x1x1xui16> loc(#loc344)
        %374 = "tpu.Load"(%194) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7104, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc345)
        %375 = "tpu.Load"(%195) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7616, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc346)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x28x40xbf16>, tensor<1x32x9x32xbf16>, tensor<2x32x1x1xui16>) -> tensor<1x32x28x40xbf16> loc(#loc347)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 20864, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x32x28x40xbf16> loc(#loc341)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x32x28x40xbf16>, none) -> tensor<1x32x28x40xbf16, 322560 : i64> loc(#loc341)
        "tpu.Yield"(%378) : (tensor<1x32x28x40xbf16, 322560 : i64>) -> () loc(#loc341)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x28x40xbf16, 71680 : i64>) -> tensor<1x32x28x40xbf16, 322560 : i64> loc(#loc341)
      %197 = "top.Weight"() : () -> tensor<1x32x9x32xbf16, 1099514730832 : i64> loc(#loc348)
      %198 = "top.Weight"() : () -> tensor<2x32x1x1xui16, 1099514958288 : i64> loc(#loc349)
      %199 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc350)
      %200 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc351)
      %201 = "tpu.Group"(%196) ({
        %371 = "tpu.Load"(%196) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4800, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 13], h_slice = [15, 15], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 322560 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc353)
        %372 = "tpu.Load"(%197) {do_bcast = false, ginfo = #tpu.lg<out_addr = 4800, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [32], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x9x32xbf16, 1099514730832 : i64>) -> tensor<1x32x9x32xbf16> loc(#loc354)
        %373 = "tpu.Load"(%198) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8128, out_size = 16, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x32x1x1xui16, 1099514958288 : i64>) -> tensor<2x32x1x1xui16> loc(#loc355)
        %374 = "tpu.Load"(%199) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7104, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc356)
        %375 = "tpu.Load"(%200) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7616, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc357)
        %376 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x28x40xbf16>, tensor<1x32x9x32xbf16>, tensor<2x32x1x1xui16>) -> tensor<1x32x28x40xbf16> loc(#loc358)
        %377 = "tpu.LutBF16"(%376, %374, %375) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 20864, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x32x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x32x28x40xbf16> loc(#loc352)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x32x28x40xbf16>, none) -> tensor<1x32x28x40xbf16, 555520 : i64> loc(#loc352)
        "tpu.Yield"(%378) : (tensor<1x32x28x40xbf16, 555520 : i64>) -> () loc(#loc352)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x28x40xbf16, 322560 : i64>) -> tensor<1x32x28x40xbf16, 555520 : i64> loc(#loc352)
      %202 = "top.Weight"() : () -> tensor<1x64x1x96xbf16, 1099514749264 : i64> loc(#loc359)
      %203 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099514958416 : i64> loc(#loc360)
      %204 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc361)
      %205 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc362)
      %206 = "tpu.Group"(%190, %191, %201) ({
        %371 = "tpu.Load"(%190) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2240, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 0 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc364)
        %372 = "tpu.Load"(%191) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16768, out_size = 2240, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 71680 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc342)
        %373 = "tpu.Load"(%201) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24992, out_size = 2240, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [32], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x32x28x40xbf16, 555520 : i64>) -> tensor<1x32x28x40xbf16> loc(#loc365)
        %374 = "tpu.Load"(%202) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8960, out_size = 1536, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [96], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x96xbf16, 1099514749264 : i64>) -> tensor<1x64x1x96xbf16> loc(#loc366)
        %375 = "tpu.Load"(%203) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24960, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099514958416 : i64>) -> tensor<2x64x1x1xui16> loc(#loc367)
        %376 = "tpu.Concat"(%371, %372, %373) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 0, out_size = 6720, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [96], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 5, stage = 1, slice_idx = 0, group_type = 0>, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x32x28x40xbf16>, tensor<1x32x28x40xbf16>, tensor<1x32x28x40xbf16>) -> tensor<1x96x28x40xbf16> loc(#loc368)
        %377 = "tpu.Load"(%204) {do_bcast = true, ginfo = #tpu.lg<out_addr = 10496, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc369)
        %378 = "tpu.Load"(%205) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11008, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc370)
        %379 = "tpu.Conv2D"(%376, %374, %375) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x96x28x40xbf16>, tensor<1x64x1x96xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc371)
        %380 = "tpu.LutBF16"(%379, %377, %378) {ginfo = #tpu.lg<out_addr = 20480, out_size = 4480, buffer_addr = 0, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc363)
        %381 = "tpu.Store"(%380, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 10, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 322560 : i64> loc(#loc363)
        "tpu.Yield"(%381) : (tensor<1x64x28x40xbf16, 322560 : i64>) -> () loc(#loc363)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 10, -2, 8, 6, 7, -3, 9, 0, 1, 2], group_type = 0 : i64, hsecs = 4 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x32x28x40xbf16, 0 : i64>, tensor<1x32x28x40xbf16, 71680 : i64>, tensor<1x32x28x40xbf16, 555520 : i64>) -> tensor<1x64x28x40xbf16, 322560 : i64> loc(#loc363)
      %207 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x64xbf16, 1099514958672 : i64> loc(#loc372)
      %208 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099515032400 : i64> loc(#loc373)
      %209 = "tpu.Conv2D"(%206, %207, %208) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16, 322560 : i64>, tensor<1x64x9x64xbf16, 1099514958672 : i64>, tensor<2x64x1x1xui16, 1099515032400 : i64>) -> tensor<1x64x14x20xbf16, 0 : i64> loc(#loc374)
      %210 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x64xbf16, 1099515051344 : i64> loc(#loc375)
      %211 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099515125072 : i64> loc(#loc376)
      %212 = "tpu.Conv2D"(%206, %210, %211) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16, 322560 : i64>, tensor<1x64x9x64xbf16, 1099515051344 : i64>, tensor<2x64x1x1xui16, 1099515125072 : i64>) -> tensor<1x64x28x40xbf16, 35840 : i64> loc(#loc377)
      %213 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099513897680 : i64> loc(#loc378)
      %214 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099515199328 : i64> loc(#loc379)
      %215 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc380)
      %216 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc381)
      %217 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc382)
      %218 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc383)
      %219 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc384)
      %220 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc385)
      %221:3 = "tpu.Group"(%206, %209, %212) ({
        %371 = "tpu.Load"(%206) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 3, 7, 11, 15, 19, 23], h_slice = [5, 6, 6, 6, 6, 6, 5], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 322560 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc389)
        %372 = "tpu.Load"(%213) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099513897680 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc390)
        %373 = "tpu.Load"(%214) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20224, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099515199328 : i64>) -> tensor<2x64x1x1xui16> loc(#loc391)
        %374 = "tpu.Load"(%209) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 640, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12], h_slice = [2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 0 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc392)
        %375 = "tpu.Load"(%215) {do_bcast = true, ginfo = #tpu.lg<out_addr = 32256, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc393)
        %376 = "tpu.Load"(%216) {do_bcast = true, ginfo = #tpu.lg<out_addr = 23040, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc394)
        %377 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc395)
        %378 = "tpu.Load"(%212) {do_bcast = false, ginfo = #tpu.lg<out_addr = 9216, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 35840 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc396)
        %379 = "tpu.Load"(%217) {do_bcast = true, ginfo = #tpu.lg<out_addr = 14848, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc397)
        %380 = "tpu.Load"(%218) {do_bcast = true, ginfo = #tpu.lg<out_addr = 11776, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc398)
        %381 = "tpu.LutBF16"(%374, %375, %376) {ginfo = #tpu.lg<out_addr = 16384, out_size = 640, buffer_addr = 24576, buffer_size = 1280, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12], h_slice = [2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [20], id = 10, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc386)
        %382 = "tpu.Load"(%219) {do_bcast = true, ginfo = #tpu.lg<out_addr = 15360, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc399)
        %383 = "tpu.Load"(%220) {do_bcast = true, ginfo = #tpu.lg<out_addr = 15872, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 12, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc400)
        %384 = "tpu.Store"(%381, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 640, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 2, 4, 6, 8, 10, 12], h_slice = [2, 2, 2, 2, 2, 2, 2], w_idx = [0], w_slice = [20], id = 13, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 215040 : i64> loc(#loc386)
        %385 = "tpu.LutBF16"(%378, %379, %380) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2560, buffer_addr = 24576, buffer_size = 5120, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 14, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc387)
        %386 = "tpu.Store"(%385, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 15, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 698880 : i64> loc(#loc387)
        %387 = "tpu.LutBF16"(%377, %382, %383) {ginfo = #tpu.lg<out_addr = 24576, out_size = 2560, buffer_addr = 27136, buffer_size = 5120, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 16, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc388)
        %388 = "tpu.Store"(%387, %0) {ginfo = #tpu.lg<out_addr = 24576, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 17, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 555520 : i64> loc(#loc388)
        "tpu.Yield"(%384, %386, %388) : (tensor<1x64x14x20xbf16, 215040 : i64>, tensor<1x64x28x40xbf16, 698880 : i64>, tensor<1x64x28x40xbf16, 555520 : i64>) -> () loc(#loc636)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 17, -2, 10, 7, 8, 9, -3, 14, 11, 12, 13, -4, 16, 15, 0, 1, 2], group_type = 0 : i64, hsecs = 7 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x28x40xbf16, 322560 : i64>, tensor<1x64x14x20xbf16, 0 : i64>, tensor<1x64x28x40xbf16, 35840 : i64>) -> (tensor<1x64x14x20xbf16, 215040 : i64>, tensor<1x64x28x40xbf16, 698880 : i64>, tensor<1x64x28x40xbf16, 555520 : i64>) loc(#loc636)
      %222 = "tpu.Concat"(%221#0, %181) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x14x20xbf16, 215040 : i64>, tensor<1x128x14x20xbf16, 250880 : i64>) -> tensor<1x192x14x20xbf16, 215040 : i64> loc(#loc401)
      %223 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099515494752 : i64> loc(#loc402)
      %224 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099515568480 : i64> loc(#loc403)
      %225 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099515568736 : i64> loc(#loc404)
      %226 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099515688288 : i64> loc(#loc405)
      %227:2 = "tpu.Group"(%221#1, %221#2) ({
        %371 = "tpu.Load"(%221#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 3, 7, 11, 15, 19, 23], h_slice = [5, 6, 6, 6, 6, 6, 5], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 698880 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc408)
        %372 = "tpu.Load"(%223) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099515494752 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc409)
        %373 = "tpu.Load"(%224) {do_bcast = false, ginfo = #tpu.lg<out_addr = 11808, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099515568480 : i64>) -> tensor<2x64x1x1xui16> loc(#loc410)
        %374 = "tpu.Load"(%221#2) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 3840, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 3, 7, 11, 15, 19, 23], h_slice = [5, 6, 6, 6, 6, 6, 5], w_idx = [0], w_slice = [40], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 555520 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc411)
        %375 = "tpu.Load"(%225) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099515568736 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc412)
        %376 = "tpu.Load"(%226) {do_bcast = false, ginfo = #tpu.lg<out_addr = 11776, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099515688288 : i64>) -> tensor<2x64x1x1xui16> loc(#loc413)
        %377 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 9216, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc406)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 9216, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 358400 : i64> loc(#loc406)
        %379 = "tpu.Conv2D"(%374, %375, %376) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 21504, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc407)
        %380 = "tpu.Store"(%379, %0) {ginfo = #tpu.lg<out_addr = 21504, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 12, 16, 20, 24], h_slice = [4, 4, 4, 4, 4, 4, 4], w_idx = [0], w_slice = [40], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 0 : i64> loc(#loc407)
        "tpu.Yield"(%378, %380) : (tensor<1x64x28x40xbf16, 358400 : i64>, tensor<1x64x28x40xbf16, 0 : i64>) -> () loc(#loc637)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 7 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x28x40xbf16, 698880 : i64>, tensor<1x64x28x40xbf16, 555520 : i64>) -> (tensor<1x64x28x40xbf16, 358400 : i64>, tensor<1x64x28x40xbf16, 0 : i64>) loc(#loc637)
      %228 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x1x192xbf16, 1099517108464 : i64> loc(#loc414)
      %229 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099515910752 : i64> loc(#loc415)
      %230 = "tpu.Conv2D"(%222, %228, %229) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x192x14x20xbf16, 215040 : i64>, tensor<1x128x1x192xbf16, 1099517108464 : i64>, tensor<2x128x1x1xui16, 1099515910752 : i64>) -> tensor<1x128x14x20xbf16, 143360 : i64> loc(#loc416)
      %231 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc417)
      %232 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc418)
      %233 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc419)
      %234 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc420)
      %235 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc421)
      %236 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc422)
      %237:3 = "tpu.Group"(%227#0, %227#1, %230) ({
        %371 = "tpu.Load"(%227#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 25344, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 358400 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc426)
        %372 = "tpu.Load"(%231) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7168, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc427)
        %373 = "tpu.Load"(%232) {do_bcast = true, ginfo = #tpu.lg<out_addr = 7680, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc428)
        %374 = "tpu.Load"(%227#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 0 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc429)
        %375 = "tpu.Load"(%233) {do_bcast = true, ginfo = #tpu.lg<out_addr = 5120, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc430)
        %376 = "tpu.Load"(%234) {do_bcast = true, ginfo = #tpu.lg<out_addr = 5632, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc431)
        %377 = "tpu.LutBF16"(%371, %372, %373) {ginfo = #tpu.lg<out_addr = 8192, out_size = 4480, buffer_addr = 16384, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc423)
        %378 = "tpu.Load"(%230) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12672, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 11], h_slice = [4, 4, 3, 3], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x14x20xbf16, 143360 : i64>) -> tensor<1x128x14x20xbf16> loc(#loc432)
        %379 = "tpu.Load"(%235) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6144, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc433)
        %380 = "tpu.Load"(%236) {do_bcast = true, ginfo = #tpu.lg<out_addr = 6656, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc434)
        %381 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 8192, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 10, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 627200 : i64> loc(#loc423)
        %382 = "tpu.LutBF16"(%374, %375, %376) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 20864, buffer_size = 8960, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 11, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x28x40xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x28x40xbf16> loc(#loc424)
        %383 = "tpu.Store"(%382, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7, 14, 21], h_slice = [7, 7, 7, 7], w_idx = [0], w_slice = [40], id = 12, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 215040 : i64> loc(#loc424)
        %384 = "tpu.LutBF16"(%378, %379, %380) {ginfo = #tpu.lg<out_addr = 29824, out_size = 2560, buffer_addr = 0, buffer_size = 5120, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 11], h_slice = [4, 4, 3, 3], w_idx = [0], w_slice = [20], id = 13, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x14x20xbf16> loc(#loc425)
        %385 = "tpu.Store"(%384, %0) {ginfo = #tpu.lg<out_addr = 29824, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 4, 8, 11], h_slice = [4, 4, 3, 3], w_idx = [0], w_slice = [20], id = 14, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x14x20xbf16>, none) -> tensor<1x128x14x20xbf16, 555520 : i64> loc(#loc425)
        "tpu.Yield"(%381, %383, %385) : (tensor<1x64x28x40xbf16, 627200 : i64>, tensor<1x64x28x40xbf16, 215040 : i64>, tensor<1x128x14x20xbf16, 555520 : i64>) -> () loc(#loc638)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 14, -2, 11, 7, 8, 9, 10, -3, 13, 12, 0, 1, 2], group_type = 0 : i64, hsecs = 4 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [-3, 1, 2], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x28x40xbf16, 358400 : i64>, tensor<1x64x28x40xbf16, 0 : i64>, tensor<1x128x14x20xbf16, 143360 : i64>) -> (tensor<1x64x28x40xbf16, 627200 : i64>, tensor<1x64x28x40xbf16, 215040 : i64>, tensor<1x128x14x20xbf16, 555520 : i64>) loc(#loc638)
      %238 = "top.Weight"() : () -> tensor<1x64x1x64xbf16, 1099513033968 : i64> loc(#loc435)
      %239 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099515911264 : i64> loc(#loc436)
      %240 = "top.Weight"() : () -> tensor<1x4x1x64xbf16, 1099512804144 : i64> loc(#loc437)
      %241 = "top.Weight"() : () -> tensor<2x4x1x1xui16, 1099515199312 : i64> loc(#loc438)
      %242:2 = "tpu.Group"(%237#0, %237#1) ({
        %371 = "tpu.Load"(%237#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 21248, out_size = 8960, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 627200 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc441)
        %372 = "tpu.Load"(%238) {do_bcast = false, ginfo = #tpu.lg<out_addr = 10080, out_size = 1024, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x64xbf16, 1099513033968 : i64>) -> tensor<1x64x1x64xbf16> loc(#loc442)
        %373 = "tpu.Load"(%239) {do_bcast = false, ginfo = #tpu.lg<out_addr = 11232, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099515911264 : i64>) -> tensor<2x64x1x1xui16> loc(#loc443)
        %374 = "tpu.Load"(%237#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 8960, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x28x40xbf16, 215040 : i64>) -> tensor<1x64x28x40xbf16> loc(#loc444)
        %375 = "tpu.Load"(%240) {do_bcast = false, ginfo = #tpu.lg<out_addr = 11104, out_size = 128, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [64], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x4x1x64xbf16, 1099512804144 : i64>) -> tensor<1x4x1x64xbf16> loc(#loc445)
        %376 = "tpu.Load"(%241) {do_bcast = false, ginfo = #tpu.lg<out_addr = 11264, out_size = 4, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x4x1x1xui16, 1099515199312 : i64>) -> tensor<2x4x1x1xui16> loc(#loc446)
        %377 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 8960, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16>, tensor<1x64x1x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x28x40xbf16> loc(#loc439)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 12288, out_size = 8960, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x28x40xbf16>, none) -> tensor<1x64x28x40xbf16, 0 : i64> loc(#loc439)
        %379 = "tpu.Conv2D"(%374, %375, %376) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8960, out_size = 1120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x28x40xbf16>, tensor<1x4x1x64xbf16>, tensor<2x4x1x1xui16>) -> tensor<1x4x28x40xbf16> loc(#loc440)
        %380 = "tpu.Store"(%379, %0) {ginfo = #tpu.lg<out_addr = 8960, out_size = 1120, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0, 14], h_slice = [14, 14], w_idx = [0], w_slice = [40], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x4x28x40xbf16>, none) -> tensor<1x4x28x40xbf16, 143360 : i64> loc(#loc440)
        "tpu.Yield"(%378, %380) : (tensor<1x64x28x40xbf16, 0 : i64>, tensor<1x4x28x40xbf16, 143360 : i64>) -> () loc(#loc639)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [1, 2], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x28x40xbf16, 627200 : i64>, tensor<1x64x28x40xbf16, 215040 : i64>) -> (tensor<1x64x28x40xbf16, 0 : i64>, tensor<1x4x28x40xbf16, 143360 : i64>) loc(#loc639)
      %243 = "tpu.Slice"(%237#2, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 64, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x128x14x20xbf16, 555520 : i64>, none, none, none, none) -> tensor<1x64x14x20xbf16, 555520 : i64> loc(#loc447)
      %244 = "tpu.Slice"(%237#2, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 128, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 64, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x128x14x20xbf16, 555520 : i64>, none, none, none, none) -> tensor<1x64x14x20xbf16, 591360 : i64> loc(#loc448)
      %245 = "tpu.Concat"(%242#0, %242#1) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x28x40xbf16, 0 : i64>, tensor<1x4x28x40xbf16, 143360 : i64>) -> tensor<1x68x28x40xbf16, 0 : i64> loc(#loc449)
      %246 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x64xbf16, 1099512804720 : i64> loc(#loc450)
      %247 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099515912288 : i64> loc(#loc451)
      %248 = "tpu.Conv2D"(%244, %246, %247) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16, 591360 : i64>, tensor<1x64x9x64xbf16, 1099512804720 : i64>, tensor<2x64x1x1xui16, 1099515912288 : i64>) -> tensor<1x64x14x20xbf16, 152320 : i64> loc(#loc452)
      %249 = "tpu.Reshape"(%245) {flatten_start_dim = -1 : i64, shape = [1, 68, -1]} : (tensor<1x68x28x40xbf16, 0 : i64>) -> tensor<1x68x1120xbf16, 0 : i64> loc(#loc453)
      %250 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc454)
      %251 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc455)
      %252 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099515912544 : i64> loc(#loc456)
      %253 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099516281184 : i64> loc(#loc457)
      %254 = "tpu.Group"(%248) ({
        %371 = "tpu.Load"(%248) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 152320 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc459)
        %372 = "tpu.Load"(%250) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc460)
        %373 = "tpu.Load"(%251) {do_bcast = true, ginfo = #tpu.lg<out_addr = 9216, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc461)
        %374 = "tpu.Load"(%252) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099515912544 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc462)
        %375 = "tpu.Load"(%253) {do_bcast = false, ginfo = #tpu.lg<out_addr = 9728, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099516281184 : i64>) -> tensor<2x64x1x1xui16> loc(#loc463)
        %376 = "tpu.LutBF16"(%371, %372, %373) {ginfo = #tpu.lg<out_addr = 12288, out_size = 2560, buffer_addr = 25088, buffer_size = 5120, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc464)
        %377 = "tpu.Conv2D"(%376, %374, %375) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc458)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 188160 : i64> loc(#loc458)
        "tpu.Yield"(%378) : (tensor<1x64x14x20xbf16, 188160 : i64>) -> () loc(#loc458)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 7, -2, 6, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 152320 : i64>) -> tensor<1x64x14x20xbf16, 188160 : i64> loc(#loc458)
      %255 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc465)
      %256 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc466)
      %257 = "top.Weight"() : () -> tensor<1x128x1x192xbf16, 1099516286560 : i64> loc(#loc467)
      %258 = "top.Weight"() : () -> tensor<2x128x1x1xui16, 1099516335712 : i64> loc(#loc468)
      %259 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc469)
      %260 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc470)
      %261 = "tpu.Group"(%254, %243, %244) ({
        %371 = "tpu.Load"(%254) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 188160 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc472)
        %372 = "tpu.Load"(%255) {do_bcast = true, ginfo = #tpu.lg<out_addr = 31488, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc473)
        %373 = "tpu.Load"(%256) {do_bcast = true, ginfo = #tpu.lg<out_addr = 32000, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc474)
        %374 = "tpu.Load"(%243) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 555520 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc475)
        %375 = "tpu.Load"(%244) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 591360 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc476)
        %376 = "tpu.LutBF16"(%371, %372, %373) {ginfo = #tpu.lg<out_addr = 24576, out_size = 2304, buffer_addr = 26880, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc477)
        %377 = "tpu.Load"(%257) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 6144, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [192], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x128x1x192xbf16, 1099516286560 : i64>) -> tensor<1x128x1x192xbf16> loc(#loc478)
        %378 = "tpu.Load"(%258) {do_bcast = false, ginfo = #tpu.lg<out_addr = 32512, out_size = 64, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 7, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x128x1x1xui16, 1099516335712 : i64>) -> tensor<2x128x1x1xui16> loc(#loc479)
        %379 = "tpu.Concat"(%374, %375, %376) {axis = 1 : si32, do_relu = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 6912, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [192], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 8, stage = 1, slice_idx = 0, group_type = 0>, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>, tensor<1x64x14x20xbf16>) -> tensor<1x192x14x20xbf16> loc(#loc480)
        %380 = "tpu.Load"(%259) {do_bcast = true, ginfo = #tpu.lg<out_addr = 15104, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 9, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc481)
        %381 = "tpu.Load"(%260) {do_bcast = true, ginfo = #tpu.lg<out_addr = 15616, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 10, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc482)
        %382 = "tpu.Conv2D"(%379, %377, %378) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 11, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x192x14x20xbf16>, tensor<1x128x1x192xbf16>, tensor<2x128x1x1xui16>) -> tensor<1x128x14x20xbf16> loc(#loc483)
        %383 = "tpu.LutBF16"(%382, %380, %381) {ginfo = #tpu.lg<out_addr = 6144, out_size = 4608, buffer_addr = 20992, buffer_size = 9216, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 12, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x128x14x20xbf16> loc(#loc471)
        %384 = "tpu.Store"(%383, %0) {ginfo = #tpu.lg<out_addr = 6144, out_size = 4608, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [128], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 13, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x128x14x20xbf16>, none) -> tensor<1x128x14x20xbf16, 224000 : i64> loc(#loc471)
        "tpu.Yield"(%384) : (tensor<1x128x14x20xbf16, 224000 : i64>) -> () loc(#loc471)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 5, 3, 4, 13, -2, 8, 6, 7, -3, 11, 9, 10, -4, 12, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 188160 : i64>, tensor<1x64x14x20xbf16, 555520 : i64>, tensor<1x64x14x20xbf16, 591360 : i64>) -> tensor<1x128x14x20xbf16, 224000 : i64> loc(#loc471)
      %262 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099516336224 : i64> loc(#loc484)
      %263 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099516893280 : i64> loc(#loc485)
      %264 = "tpu.Conv2D"(%261, %262, %263) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [2, 2], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16, 224000 : i64>, tensor<1x128x9x128xbf16, 1099516336224 : i64>, tensor<2x128x1x1xui16, 1099516893280 : i64>) -> tensor<1x128x7x10xbf16, 295680 : i64> loc(#loc486)
      %265 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x128xbf16, 1099513379536 : i64> loc(#loc487)
      %266 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099513230288 : i64> loc(#loc488)
      %267 = "tpu.Conv2D"(%261, %265, %266) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16, 224000 : i64>, tensor<1x64x9x128xbf16, 1099513379536 : i64>, tensor<2x64x1x1xui16, 1099513230288 : i64>) -> tensor<1x64x14x20xbf16, 313600 : i64> loc(#loc489)
      %268 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x128xbf16, 1099516894304 : i64> loc(#loc490)
      %269 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099517650160 : i64> loc(#loc491)
      %270 = "tpu.Conv2D"(%261, %268, %269) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x14x20xbf16, 224000 : i64>, tensor<1x64x9x128xbf16, 1099516894304 : i64>, tensor<2x64x1x1xui16, 1099517650160 : i64>) -> tensor<1x64x14x20xbf16, 349440 : i64> loc(#loc492)
      %271 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc493)
      %272 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc494)
      %273 = "tpu.LutBF16"(%264, %271, %272) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 295680 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x128x7x10xbf16, 501760 : i64> loc(#loc495)
      %274 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc496)
      %275 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc497)
      %276 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc498)
      %277 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc499)
      %278:2 = "tpu.Group"(%267, %270) ({
        %371 = "tpu.Load"(%267) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 313600 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc502)
        %372 = "tpu.Load"(%274) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc503)
        %373 = "tpu.Load"(%275) {do_bcast = true, ginfo = #tpu.lg<out_addr = 2304, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc504)
        %374 = "tpu.Load"(%270) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 349440 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc505)
        %375 = "tpu.Load"(%276) {do_bcast = true, ginfo = #tpu.lg<out_addr = 16384, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc506)
        %376 = "tpu.Load"(%277) {do_bcast = true, ginfo = #tpu.lg<out_addr = 20480, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc507)
        %377 = "tpu.LutBF16"(%371, %372, %373) {ginfo = #tpu.lg<out_addr = 4096, out_size = 2304, buffer_addr = 25088, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc500)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 4096, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 188160 : i64> loc(#loc500)
        %379 = "tpu.LutBF16"(%374, %375, %376) {ginfo = #tpu.lg<out_addr = 12288, out_size = 2304, buffer_addr = 25088, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc501)
        %380 = "tpu.Store"(%379, %0) {ginfo = #tpu.lg<out_addr = 12288, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 152320 : i64> loc(#loc501)
        "tpu.Yield"(%378, %380) : (tensor<1x64x14x20xbf16, 188160 : i64>, tensor<1x64x14x20xbf16, 152320 : i64>) -> () loc(#loc640)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 313600 : i64>, tensor<1x64x14x20xbf16, 349440 : i64>) -> (tensor<1x64x14x20xbf16, 188160 : i64>, tensor<1x64x14x20xbf16, 152320 : i64>) loc(#loc640)
      %279 = "tpu.Concat"(%273, %155) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x7x10xbf16, 501760 : i64>, tensor<1x256x7x10xbf16, 519680 : i64>) -> tensor<1x384x7x10xbf16, 501760 : i64> loc(#loc508)
      %280 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099515689568 : i64> loc(#loc509)
      %281 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099512728176 : i64> loc(#loc510)
      %282 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099514636624 : i64> loc(#loc511)
      %283 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099515642976 : i64> loc(#loc512)
      %284:2 = "tpu.Group"(%278#0, %278#1) ({
        %371 = "tpu.Load"(%278#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 188160 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc515)
        %372 = "tpu.Load"(%280) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099515689568 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc516)
        %373 = "tpu.Load"(%281) {do_bcast = false, ginfo = #tpu.lg<out_addr = 11552, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099512728176 : i64>) -> tensor<2x64x1x1xui16> loc(#loc517)
        %374 = "tpu.Load"(%278#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 2560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 6], h_slice = [8, 8], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 152320 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc518)
        %375 = "tpu.Load"(%282) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099514636624 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc519)
        %376 = "tpu.Load"(%283) {do_bcast = false, ginfo = #tpu.lg<out_addr = 11520, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099515642976 : i64>) -> tensor<2x64x1x1xui16> loc(#loc520)
        %377 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 9216, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc513)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 9216, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 259840 : i64> loc(#loc513)
        %379 = "tpu.Conv2D"(%374, %375, %376) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 21504, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc514)
        %380 = "tpu.Store"(%379, %0) {ginfo = #tpu.lg<out_addr = 21504, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 224000 : i64> loc(#loc514)
        "tpu.Yield"(%378, %380) : (tensor<1x64x14x20xbf16, 259840 : i64>, tensor<1x64x14x20xbf16, 224000 : i64>) -> () loc(#loc641)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 188160 : i64>, tensor<1x64x14x20xbf16, 152320 : i64>) -> (tensor<1x64x14x20xbf16, 259840 : i64>, tensor<1x64x14x20xbf16, 224000 : i64>) loc(#loc641)
      %285 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x384xbf16, 1099513527248 : i64> loc(#loc521)
      %286 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099517041888 : i64> loc(#loc522)
      %287 = "tpu.Conv2D"(%279, %285, %286) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x384x7x10xbf16, 501760 : i64>, tensor<1x256x1x384xbf16, 1099513527248 : i64>, tensor<2x256x1x1xui16, 1099517041888 : i64>) -> tensor<1x256x7x10xbf16, 295680 : i64> loc(#loc523)
      %288 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc524)
      %289 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc525)
      %290 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc526)
      %291 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc527)
      %292:2 = "tpu.Group"(%284#0, %284#1) ({
        %371 = "tpu.Load"(%284#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 259840 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc530)
        %372 = "tpu.Load"(%288) {do_bcast = true, ginfo = #tpu.lg<out_addr = 2304, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc531)
        %373 = "tpu.Load"(%289) {do_bcast = true, ginfo = #tpu.lg<out_addr = 24576, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc532)
        %374 = "tpu.Load"(%284#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 4096, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 224000 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc533)
        %375 = "tpu.Load"(%290) {do_bcast = true, ginfo = #tpu.lg<out_addr = 16384, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099512803632 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc534)
        %376 = "tpu.Load"(%291) {do_bcast = true, ginfo = #tpu.lg<out_addr = 20480, out_size = 512, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [1], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [32], w_idx = [0], w_slice = [8], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x1x32x8xbf16> loc(#loc535)
        %377 = "tpu.LutBF16"(%371, %372, %373) {ginfo = #tpu.lg<out_addr = 0, out_size = 2304, buffer_addr = 25088, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc528)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 0, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 188160 : i64> loc(#loc528)
        %379 = "tpu.LutBF16"(%374, %375, %376) {ginfo = #tpu.lg<out_addr = 8192, out_size = 2304, buffer_addr = 25088, buffer_size = 4608, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 8, stage = 1, slice_idx = 0, group_type = 0>, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x14x20xbf16>, tensor<1x1x32x8xbf16>, tensor<1x1x32x8xbf16>) -> tensor<1x64x14x20xbf16> loc(#loc529)
        %380 = "tpu.Store"(%379, %0) {ginfo = #tpu.lg<out_addr = 8192, out_size = 2304, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0, 7], h_slice = [7, 7], w_idx = [0], w_slice = [20], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 152320 : i64> loc(#loc529)
        "tpu.Yield"(%378, %380) : (tensor<1x64x14x20xbf16, 188160 : i64>, tensor<1x64x14x20xbf16, 152320 : i64>) -> () loc(#loc642)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 2 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 259840 : i64>, tensor<1x64x14x20xbf16, 224000 : i64>) -> (tensor<1x64x14x20xbf16, 188160 : i64>, tensor<1x64x14x20xbf16, 152320 : i64>) loc(#loc642)
      %293 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc536)
      %294 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc537)
      %295 = "tpu.LutBF16"(%287, %293, %294) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x7x10xbf16, 295680 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x256x7x10xbf16, 224000 : i64> loc(#loc538)
      %296 = "top.Weight"() : () -> tensor<1x64x1x64xbf16, 1099515680096 : i64> loc(#loc539)
      %297 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099515051088 : i64> loc(#loc540)
      %298 = "top.Weight"() : () -> tensor<1x4x1x64xbf16, 1099515688544 : i64> loc(#loc541)
      %299 = "top.Weight"() : () -> tensor<2x4x1x1xui16, 1099517042912 : i64> loc(#loc542)
      %300:2 = "tpu.Group"(%292#0, %292#1) ({
        %371 = "tpu.Load"(%292#0) {do_bcast = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [14], w_idx = [0], w_slice = [20], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 188160 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc545)
        %372 = "tpu.Load"(%296) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 1024, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x64xbf16, 1099515680096 : i64>) -> tensor<1x64x1x64xbf16> loc(#loc546)
        %373 = "tpu.Load"(%297) {do_bcast = false, ginfo = #tpu.lg<out_addr = 4608, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099515051088 : i64>) -> tensor<2x64x1x1xui16> loc(#loc547)
        %374 = "tpu.Load"(%292#1) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [14], w_idx = [0], w_slice = [20], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x14x20xbf16, 152320 : i64>) -> tensor<1x64x14x20xbf16> loc(#loc548)
        %375 = "tpu.Load"(%298) {do_bcast = false, ginfo = #tpu.lg<out_addr = 4480, out_size = 128, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [64], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x4x1x64xbf16, 1099515688544 : i64>) -> tensor<1x4x1x64xbf16> loc(#loc549)
        %376 = "tpu.Load"(%299) {do_bcast = false, ginfo = #tpu.lg<out_addr = 4640, out_size = 4, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x4x1x1xui16, 1099517042912 : i64>) -> tensor<2x4x1x1xui16> loc(#loc550)
        %377 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [14], w_idx = [0], w_slice = [20], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x64x1x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x14x20xbf16> loc(#loc543)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 8192, out_size = 4480, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [14], w_idx = [0], w_slice = [20], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x14x20xbf16>, none) -> tensor<1x64x14x20xbf16, 399840 : i64> loc(#loc543)
        %379 = "tpu.Conv2D"(%374, %375, %376) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [14], w_idx = [0], w_slice = [20], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x14x20xbf16>, tensor<1x4x1x64xbf16>, tensor<2x4x1x1xui16>) -> tensor<1x4x14x20xbf16> loc(#loc544)
        %380 = "tpu.Store"(%379, %0) {ginfo = #tpu.lg<out_addr = 28672, out_size = 560, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [14], w_idx = [0], w_slice = [20], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x4x14x20xbf16>, none) -> tensor<1x4x14x20xbf16, 435680 : i64> loc(#loc544)
        "tpu.Yield"(%378, %380) : (tensor<1x64x14x20xbf16, 399840 : i64>, tensor<1x4x14x20xbf16, 435680 : i64>) -> () loc(#loc643)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 1 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x14x20xbf16, 188160 : i64>, tensor<1x64x14x20xbf16, 152320 : i64>) -> (tensor<1x64x14x20xbf16, 399840 : i64>, tensor<1x4x14x20xbf16, 435680 : i64>) loc(#loc643)
      %301 = "tpu.Slice"(%295, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 128, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x256x7x10xbf16, 224000 : i64>, none, none, none, none) -> tensor<1x128x7x10xbf16, 224000 : i64> loc(#loc551)
      %302 = "tpu.Slice"(%295, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 256, 9223372036854775807, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 128, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x256x7x10xbf16, 224000 : i64>, none, none, none, none) -> tensor<1x128x7x10xbf16, 241920 : i64> loc(#loc552)
      %303 = "tpu.Concat"(%300#0, %300#1) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x14x20xbf16, 399840 : i64>, tensor<1x4x14x20xbf16, 435680 : i64>) -> tensor<1x68x14x20xbf16, 399840 : i64> loc(#loc553)
      %304 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099512387376 : i64> loc(#loc554)
      %305 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099515911520 : i64> loc(#loc555)
      %306 = "tpu.Conv2D"(%302, %304, %305) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 241920 : i64>, tensor<1x128x9x128xbf16, 1099512387376 : i64>, tensor<2x128x1x1xui16, 1099515911520 : i64>) -> tensor<1x128x7x10xbf16, 152320 : i64> loc(#loc556)
      %307 = "tpu.Reshape"(%303) {flatten_start_dim = -1 : i64, shape = [1, 68, -1]} : (tensor<1x68x14x20xbf16, 399840 : i64>) -> tensor<1x68x280xbf16, 399840 : i64> loc(#loc557)
      %308 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc558)
      %309 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc559)
      %310 = "tpu.LutBF16"(%306, %308, %309) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 152320 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x128x7x10xbf16, 170240 : i64> loc(#loc560)
      %311 = "top.Weight"() {do_compress = true} : () -> tensor<1x128x9x128xbf16, 1099515986272 : i64> loc(#loc561)
      %312 = "top.Weight"() {do_compress = true} : () -> tensor<2x128x1x1xui16, 1099515689056 : i64> loc(#loc562)
      %313 = "tpu.Conv2D"(%310, %311, %312) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x128x7x10xbf16, 170240 : i64>, tensor<1x128x9x128xbf16, 1099515986272 : i64>, tensor<2x128x1x1xui16, 1099515689056 : i64>) -> tensor<1x128x7x10xbf16, 188160 : i64> loc(#loc563)
      %314 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc564)
      %315 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc565)
      %316 = "tpu.LutBF16"(%313, %314, %315) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x128x7x10xbf16, 188160 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x128x7x10xbf16, 152320 : i64> loc(#loc566)
      %317 = "tpu.Concat"(%301, %302, %316) {axis = 1 : si32, do_relu = false, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x128x7x10xbf16, 224000 : i64>, tensor<1x128x7x10xbf16, 241920 : i64>, tensor<1x128x7x10xbf16, 152320 : i64>) -> tensor<1x384x7x10xbf16, 170240 : i64> loc(#loc567)
      %318 = "top.Weight"() {do_compress = true} : () -> tensor<1x256x1x384xbf16, 1099517157616 : i64> loc(#loc568)
      %319 = "top.Weight"() {do_compress = true} : () -> tensor<2x256x1x1xui16, 1099517354224 : i64> loc(#loc569)
      %320 = "tpu.Conv2D"(%317, %318, %319) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x384x7x10xbf16, 170240 : i64>, tensor<1x256x1x384xbf16, 1099517157616 : i64>, tensor<2x256x1x1xui16, 1099517354224 : i64>) -> tensor<1x256x7x10xbf16, 224000 : i64> loc(#loc570)
      %321 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc571)
      %322 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc572)
      %323 = "tpu.LutBF16"(%320, %321, %322) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x256x7x10xbf16, 224000 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x256x7x10xbf16, 152320 : i64> loc(#loc573)
      %324 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x256xbf16, 1099515199584 : i64> loc(#loc574)
      %325 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099511729968 : i64> loc(#loc575)
      %326 = "tpu.Conv2D"(%323, %324, %325) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16, 152320 : i64>, tensor<1x64x9x256xbf16, 1099515199584 : i64>, tensor<2x64x1x1xui16, 1099511729968 : i64>) -> tensor<1x64x7x10xbf16, 188160 : i64> loc(#loc576)
      %327 = "top.Weight"() {do_compress = true} : () -> tensor<1x64x9x256xbf16, 1099517355248 : i64> loc(#loc577)
      %328 = "top.Weight"() {do_compress = true} : () -> tensor<2x64x1x1xui16, 1099512321072 : i64> loc(#loc578)
      %329 = "tpu.Conv2D"(%323, %327, %328) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x256x7x10xbf16, 152320 : i64>, tensor<1x64x9x256xbf16, 1099517355248 : i64>, tensor<2x64x1x1xui16, 1099512321072 : i64>) -> tensor<1x64x7x10xbf16, 197120 : i64> loc(#loc579)
      %330 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc580)
      %331 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc581)
      %332 = "tpu.LutBF16"(%326, %330, %331) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x7x10xbf16, 188160 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x64x7x10xbf16, 206080 : i64> loc(#loc582)
      %333 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc583)
      %334 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc584)
      %335 = "tpu.LutBF16"(%329, %333, %334) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x7x10xbf16, 197120 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x64x7x10xbf16, 152320 : i64> loc(#loc585)
      %336 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099513230544 : i64> loc(#loc586)
      %337 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099513971664 : i64> loc(#loc587)
      %338 = "top.Weight"() : () -> tensor<1x64x9x64xbf16, 1099515837024 : i64> loc(#loc588)
      %339 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099515912032 : i64> loc(#loc589)
      %340:2 = "tpu.Group"(%332, %335) ({
        %371 = "tpu.Load"(%332) {do_bcast = false, ginfo = #tpu.lg<out_addr = 10368, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x7x10xbf16, 206080 : i64>) -> tensor<1x64x7x10xbf16> loc(#loc592)
        %372 = "tpu.Load"(%336) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099513230544 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc593)
        %373 = "tpu.Load"(%337) {do_bcast = false, ginfo = #tpu.lg<out_addr = 11552, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099513971664 : i64>) -> tensor<2x64x1x1xui16> loc(#loc594)
        %374 = "tpu.Load"(%335) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x7x10xbf16, 152320 : i64>) -> tensor<1x64x7x10xbf16> loc(#loc595)
        %375 = "tpu.Load"(%338) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 9216, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [9], w_idx = [0], w_slice = [64], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x9x64xbf16, 1099515837024 : i64>) -> tensor<1x64x9x64xbf16> loc(#loc596)
        %376 = "tpu.Load"(%339) {do_bcast = false, ginfo = #tpu.lg<out_addr = 11520, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099515912032 : i64>) -> tensor<2x64x1x1xui16> loc(#loc597)
        %377 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x7x10xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x7x10xbf16> loc(#loc590)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 28672, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x7x10xbf16>, none) -> tensor<1x64x7x10xbf16, 215040 : i64> loc(#loc590)
        %379 = "tpu.Conv2D"(%374, %375, %376) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 9216, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x7x10xbf16>, tensor<1x64x9x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x7x10xbf16> loc(#loc591)
        %380 = "tpu.Store"(%379, %0) {ginfo = #tpu.lg<out_addr = 9216, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x7x10xbf16>, none) -> tensor<1x64x7x10xbf16, 161280 : i64> loc(#loc591)
        "tpu.Yield"(%378, %380) : (tensor<1x64x7x10xbf16, 215040 : i64>, tensor<1x64x7x10xbf16, 161280 : i64>) -> () loc(#loc644)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 1 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x7x10xbf16, 206080 : i64>, tensor<1x64x7x10xbf16, 152320 : i64>) -> (tensor<1x64x7x10xbf16, 215040 : i64>, tensor<1x64x7x10xbf16, 161280 : i64>) loc(#loc644)
      %341 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc598)
      %342 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc599)
      %343 = "tpu.LutBF16"(%340#0, %341, %342) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x7x10xbf16, 215040 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x64x7x10xbf16, 170240 : i64> loc(#loc600)
      %344 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512803632 : i64> loc(#loc601)
      %345 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516281440 : i64> loc(#loc602)
      %346 = "tpu.LutBF16"(%340#1, %344, %345) {lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64} : (tensor<1x64x7x10xbf16, 161280 : i64>, tensor<1x1x32x8xbf16, 1099512803632 : i64>, tensor<1x1x32x8xbf16, 1099516281440 : i64>) -> tensor<1x64x7x10xbf16, 179200 : i64> loc(#loc603)
      %347 = "top.Weight"() : () -> tensor<1x64x1x64xbf16, 1099517650416 : i64> loc(#loc604)
      %348 = "top.Weight"() : () -> tensor<2x64x1x1xui16, 1099511629360 : i64> loc(#loc605)
      %349 = "top.Weight"() : () -> tensor<1x4x1x64xbf16, 1099511628848 : i64> loc(#loc606)
      %350 = "top.Weight"() : () -> tensor<2x4x1x1xui16, 1099511628832 : i64> loc(#loc607)
      %351:2 = "tpu.Group"(%343, %346) ({
        %371 = "tpu.Load"(%343) {do_bcast = false, ginfo = #tpu.lg<out_addr = 8192, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 0, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x7x10xbf16, 170240 : i64>) -> tensor<1x64x7x10xbf16> loc(#loc610)
        %372 = "tpu.Load"(%347) {do_bcast = false, ginfo = #tpu.lg<out_addr = 12288, out_size = 1024, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [64], id = 1, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x1x64xbf16, 1099517650416 : i64>) -> tensor<1x64x1x64xbf16> loc(#loc611)
        %373 = "tpu.Load"(%348) {do_bcast = false, ginfo = #tpu.lg<out_addr = 24576, out_size = 32, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 2, stage = 0, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x64x1x1xui16, 1099511629360 : i64>) -> tensor<2x64x1x1xui16> loc(#loc612)
        %374 = "tpu.Load"(%346) {do_bcast = false, ginfo = #tpu.lg<out_addr = 0, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 3, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 1 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x64x7x10xbf16, 179200 : i64>) -> tensor<1x64x7x10xbf16> loc(#loc613)
        %375 = "tpu.Load"(%349) {do_bcast = false, ginfo = #tpu.lg<out_addr = 20480, out_size = 128, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [64], id = 4, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<1x4x1x64xbf16, 1099511628848 : i64>) -> tensor<1x4x1x64xbf16> loc(#loc614)
        %376 = "tpu.Load"(%350) {do_bcast = false, ginfo = #tpu.lg<out_addr = 28672, out_size = 4, buffer_addr = 0, buffer_size = 0, eu_align = false, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [2], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [1], w_idx = [0], w_slice = [1], id = 5, stage = 1, slice_idx = 0, group_type = 0>, lmem_type = 0 : i64, support_compress = true, use_3ic_optimize = 0 : i64} : (tensor<2x4x1x1xui16, 1099511628832 : i64>) -> tensor<2x4x1x1xui16> loc(#loc615)
        %377 = "tpu.Conv2D"(%371, %372, %373) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 4096, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 6, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x7x10xbf16>, tensor<1x64x1x64xbf16>, tensor<2x64x1x1xui16>) -> tensor<1x64x7x10xbf16> loc(#loc608)
        %378 = "tpu.Store"(%377, %0) {ginfo = #tpu.lg<out_addr = 4096, out_size = 1152, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [64], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 7, stage = 1, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x64x7x10xbf16>, none) -> tensor<1x64x7x10xbf16, 188160 : i64> loc(#loc608)
        %379 = "tpu.Conv2D"(%374, %375, %376) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, ginfo = #tpu.lg<out_addr = 16384, out_size = 144, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 8, stage = 1, slice_idx = 0, group_type = 0>, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x64x7x10xbf16>, tensor<1x4x1x64xbf16>, tensor<2x4x1x1xui16>) -> tensor<1x4x7x10xbf16> loc(#loc609)
        %380 = "tpu.Store"(%379, %0) {ginfo = #tpu.lg<out_addr = 16384, out_size = 144, buffer_addr = 0, buffer_size = 0, eu_align = true, can_merge = false, in_hslice_offset = [], n_idx = [0], n_slice = [1], c_idx = [0], c_slice = [4], d_idx = [0], d_slice = [1], h_idx = [0], h_slice = [7], w_idx = [0], w_slice = [10], id = 9, stage = 2, slice_idx = 0, group_type = 0>, support_compress = true} : (tensor<1x4x7x10xbf16>, none) -> tensor<1x4x7x10xbf16, 197120 : i64> loc(#loc609)
        "tpu.Yield"(%378, %380) : (tensor<1x64x7x10xbf16, 188160 : i64>, tensor<1x4x7x10xbf16, 197120 : i64>) -> () loc(#loc645)
      }) {core_slice_ncdhw = [], csecs = 1 : i64, dsecs = 1 : i64, flow = [-1, 6, 3, 4, 5, 9, -2, 8, 7, 0, 1, 2], group_type = 0 : i64, hsecs = 1 : i64, nsecs = 1 : i64, other_down_overlap_op = [], other_up_overlap_op = [], run_core_id = [], self_down_overlap_op = [], self_up_overlap_op = [], support_compress = true, swpipl_stage_num = 3 : i64, wsecs = 1 : i64} : (tensor<1x64x7x10xbf16, 170240 : i64>, tensor<1x64x7x10xbf16, 179200 : i64>) -> (tensor<1x64x7x10xbf16, 188160 : i64>, tensor<1x4x7x10xbf16, 197120 : i64>) loc(#loc645)
      %352 = "tpu.Concat"(%351#0, %351#1) {axis = 1 : si32, do_relu = false, only_merge = true, relu_limit = -1.000000e+00 : f64} : (tensor<1x64x7x10xbf16, 188160 : i64>, tensor<1x4x7x10xbf16, 197120 : i64>) -> tensor<1x68x7x10xbf16, 188160 : i64> loc(#loc616)
      %353 = "tpu.Reshape"(%352) {flatten_start_dim = -1 : i64, shape = [1, 68, -1]} : (tensor<1x68x7x10xbf16, 188160 : i64>) -> tensor<1x68x70xbf16, 188160 : i64> loc(#loc617)
      %354 = "tpu.Concat"(%249, %307, %353) {axis = 2 : si32, do_relu = false, only_merge = false, relu_limit = -1.000000e+00 : f64} : (tensor<1x68x1120xbf16, 0 : i64>, tensor<1x68x280xbf16, 399840 : i64>, tensor<1x68x70xbf16, 188160 : i64>) -> tensor<1x68x1470xbf16, 199920 : i64> loc(#loc618)
      %355 = "tpu.Slice"(%354, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 64, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 0, 0], steps = [1, 1, 1]} : (tensor<1x68x1470xbf16, 199920 : i64>, none, none, none, none) -> tensor<1x64x1470xbf16, 199920 : i64> loc(#loc619)
      %356 = "tpu.Slice"(%354, %0, %0, %0, %0) {axes = [], ends = [9223372036854775807, 68, 9223372036854775807], hasparamConvert_axes = [1], offset = [0, 64, 0], steps = [1, 1, 1]} : (tensor<1x68x1470xbf16, 199920 : i64>, none, none, none, none) -> tensor<1x4x1470xbf16, 388080 : i64> loc(#loc620)
      %357 = "tpu.Reshape"(%355) {flatten_start_dim = -1 : i64, shape = [1, 4, 16, 1470]} : (tensor<1x64x1470xbf16, 199920 : i64>) -> tensor<1x4x16x1470xbf16, 199920 : i64> loc(#loc621)
      %358 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099516893792 : i64> loc(#loc622)
      %359 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099515642464 : i64> loc(#loc623)
      %360 = "tpu.LutBF16"(%356, %358, %359) {bias = 0.000000e+00 : f64, log = false, lut_mode = #tpu<lut_mode Slope>, max_range = 1.200000e+01 : f64, min_range = -1.200000e+01 : f64, scale = 1.000000e+00 : f64} : (tensor<1x4x1470xbf16, 388080 : i64>, tensor<1x1x32x8xbf16, 1099516893792 : i64>, tensor<1x1x32x8xbf16, 1099515642464 : i64>) -> tensor<1x4x1470xbf16, 0 : i64> loc(#loc624)
      %361 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099511628320 : i64> loc(#loc625)
      %362 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099513897168 : i64> loc(#loc626)
      %363 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099511627808 : i64> loc(#loc627)
      %364 = "top.Weight"() : () -> tensor<1x1x32x8xbf16, 1099512901488 : i64> loc(#loc628)
      %365 = "tpu.Softmax"(%357, %361, %362, %363, %364, %0) {axis = 2 : si32, beta = 1.000000e+00 : f64, log = false, round_mode = #tpu<round_mode HalfAwayFromZero>} : (tensor<1x4x16x1470xbf16, 199920 : i64>, tensor<1x1x32x8xbf16, 1099511628320 : i64>, tensor<1x1x32x8xbf16, 1099513897168 : i64>, tensor<1x1x32x8xbf16, 1099511627808 : i64>, tensor<1x1x32x8xbf16, 1099512901488 : i64>, none) -> tensor<1x4x16x1470xbf16, 11760 : i64> loc(#loc629)
      %366 = "tpu.Permute"(%365, %0) {order = [0, 2, 1, 3]} : (tensor<1x4x16x1470xbf16, 11760 : i64>, none) -> tensor<1x16x4x1470xbf16, 199920 : i64> loc(#loc630)
      %367 = "top.Weight"() {do_compress = true} : () -> tensor<1x1x1x16xbf16, 1099511627776 : i64> loc(#loc631)
      %368 = "tpu.Conv2D"(%366, %367, %0) {coeff_merged = false, dilations = [1, 1], do_relu = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode MultiplierShift>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = false} : (tensor<1x16x4x1470xbf16, 199920 : i64>, tensor<1x1x1x16xbf16, 1099511627776 : i64>, none) -> tensor<1x1x4x1470xbf16, 11760 : i64> loc(#loc632)
      %369 = "tpu.Cast"(%360) {round_mode = #tpu<round_mode HalfAwayFromZero>, with_scale = true} : (tensor<1x4x1470xbf16, 0 : i64>) -> tensor<1x4x1470xf32, 4398046511104 : i64> loc(#loc633)
      %370 = "tpu.Cast"(%368) {round_mode = #tpu<round_mode HalfAwayFromZero>, with_scale = true} : (tensor<1x1x4x1470xbf16, 11760 : i64>) -> tensor<1x1x4x1470xf32, 5497558138880 : i64> loc(#loc634)
      return %370, %369 : tensor<1x1x4x1470xf32, 5497558138880 : i64>, tensor<1x4x1470xf32, 4398046511104 : i64> loc(#loc)
    } loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("images/model.0/conv/Conv_output_0_Conv_bf16")
#loc3 = loc("/model.0/conv/Conv_output_0_Conv_filter_reordered")
#loc4 = loc("/model.0/conv/Conv_output_0_Conv_bias_reordered")
#loc5 = loc("/model.0/act/Mul_output_0_Mul/model.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc6 = loc("/model.0/act/Mul_output_0_Mul/model.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc7 = loc("/model.1/conv/Conv_output_0_Conv_filter_reordered")
#loc8 = loc("/model.1/conv/Conv_output_0_Conv_bias_reordered")
#loc9 = loc("/model.1/conv/Conv_output_0_Conv")
#loc10 = loc("load_images/model.0/conv/Conv_output_0_Conv_bf16")
#loc11 = loc("load_/model.0/conv/Conv_output_0_Conv_filter_reordered")
#loc12 = loc("load_/model.0/conv/Conv_output_0_Conv_bias_reordered")
#loc13 = loc("load_/model.0/act/Mul_output_0_Mul/model.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc14 = loc("load_/model.0/act/Mul_output_0_Mul/model.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc15 = loc("/model.0/conv/Conv_output_0_Conv")
#loc16 = loc("load_/model.1/conv/Conv_output_0_Conv_filter_reordered")
#loc17 = loc("load_/model.1/conv/Conv_output_0_Conv_bias_reordered")
#loc18 = loc("/model.0/act/Mul_output_0_Mul")
#loc19 = loc("/model.1/act/Mul_output_0_Mul/model.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc20 = loc("/model.1/act/Mul_output_0_Mul/model.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc21 = loc("/model.2/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc22 = loc("/model.2/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc23 = loc("/model.2/cv1/act/Mul_output_0_Mul/model.2/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc24 = loc("/model.2/cv1/act/Mul_output_0_Mul/model.2/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc25 = loc("/model.2/cv1/act/Mul_output_0_Mul")
#loc26 = loc("load_/model.1/conv/Conv_output_0_Conv")
#loc27 = loc("load_/model.1/act/Mul_output_0_Mul/model.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc28 = loc("load_/model.1/act/Mul_output_0_Mul/model.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc29 = loc("load_/model.2/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc30 = loc("load_/model.2/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc31 = loc("/model.1/act/Mul_output_0_Mul")
#loc32 = loc("load_/model.2/cv1/act/Mul_output_0_Mul/model.2/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc33 = loc("load_/model.2/cv1/act/Mul_output_0_Mul/model.2/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc34 = loc("/model.2/cv1/conv/Conv_output_0_Conv")
#loc35 = loc("/model.2/Split_output_0_Split")
#loc36 = loc("/model.2/Split_output_1_Split")
#loc37 = loc("/model.2/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc38 = loc("/model.2/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc39 = loc("/model.2/m.0/cv1/act/Mul_output_0_Mul/model.2/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc40 = loc("/model.2/m.0/cv1/act/Mul_output_0_Mul/model.2/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc41 = loc("/model.2/m.0/cv1/act/Mul_output_0_Mul")
#loc42 = loc("load_/model.2/Split_output_1_Split")
#loc43 = loc("load_/model.2/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc44 = loc("load_/model.2/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc45 = loc("load_/model.2/m.0/cv1/act/Mul_output_0_Mul/model.2/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc46 = loc("load_/model.2/m.0/cv1/act/Mul_output_0_Mul/model.2/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc47 = loc("/model.2/m.0/cv1/conv/Conv_output_0_Conv")
#loc48 = loc("/model.2/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc49 = loc("/model.2/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc50 = loc("/model.2/m.0/cv2/act/Mul_output_0_Mul/model.2/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc51 = loc("/model.2/m.0/cv2/act/Mul_output_0_Mul/model.2/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc52 = loc("/model.2/m.0/cv2/act/Mul_output_0_Mul")
#loc53 = loc("load_/model.2/m.0/cv1/act/Mul_output_0_Mul")
#loc54 = loc("load_/model.2/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc55 = loc("load_/model.2/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc56 = loc("load_/model.2/m.0/cv2/act/Mul_output_0_Mul/model.2/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc57 = loc("load_/model.2/m.0/cv2/act/Mul_output_0_Mul/model.2/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc58 = loc("/model.2/m.0/cv2/conv/Conv_output_0_Conv")
#loc59 = loc("/model.2/Concat_output_0_Concat")
#loc60 = loc("load_/model.2/m.0/cv2/act/Mul_output_0_Mul")
#loc61 = loc("load_/model.2/Split_output_0_Split")
#loc62 = loc("/model.2/m.0/Add_output_0_Add")
#loc63 = loc("/model.2/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc64 = loc("/model.2/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc65 = loc("/model.2/cv2/act/Mul_output_0_Mul/model.2/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc66 = loc("/model.2/cv2/act/Mul_output_0_Mul/model.2/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc67 = loc("/model.3/conv/Conv_output_0_Conv_filter_reordered")
#loc68 = loc("/model.3/conv/Conv_output_0_Conv_bias_reordered")
#loc69 = loc("/model.3/conv/Conv_output_0_Conv")
#loc70 = loc("load_/model.2/Concat_output_0_Concat")
#loc71 = loc("load_/model.2/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc72 = loc("load_/model.2/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc73 = loc("load_/model.2/cv2/act/Mul_output_0_Mul/model.2/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc74 = loc("load_/model.2/cv2/act/Mul_output_0_Mul/model.2/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc75 = loc("/model.2/cv2/conv/Conv_output_0_Conv")
#loc76 = loc("load_/model.3/conv/Conv_output_0_Conv_filter_reordered")
#loc77 = loc("load_/model.3/conv/Conv_output_0_Conv_bias_reordered")
#loc78 = loc("/model.2/cv2/act/Mul_output_0_Mul")
#loc79 = loc("/model.3/act/Mul_output_0_Mul/model.3/act/Mul_output_0_Mul_slope_table_bf16")
#loc80 = loc("/model.3/act/Mul_output_0_Mul/model.3/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc81 = loc("/model.4/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc82 = loc("/model.4/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc83 = loc("/model.4/cv1/act/Mul_output_0_Mul/model.4/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc84 = loc("/model.4/cv1/act/Mul_output_0_Mul/model.4/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc85 = loc("/model.4/cv1/act/Mul_output_0_Mul")
#loc86 = loc("load_/model.3/conv/Conv_output_0_Conv")
#loc87 = loc("load_/model.3/act/Mul_output_0_Mul/model.3/act/Mul_output_0_Mul_slope_table_bf16")
#loc88 = loc("load_/model.3/act/Mul_output_0_Mul/model.3/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc89 = loc("load_/model.4/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc90 = loc("load_/model.4/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc91 = loc("/model.3/act/Mul_output_0_Mul")
#loc92 = loc("load_/model.4/cv1/act/Mul_output_0_Mul/model.4/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc93 = loc("load_/model.4/cv1/act/Mul_output_0_Mul/model.4/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc94 = loc("/model.4/cv1/conv/Conv_output_0_Conv")
#loc95 = loc("/model.4/Split_output_0_Split")
#loc96 = loc("/model.4/Split_output_1_Split")
#loc97 = loc("/model.4/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc98 = loc("/model.4/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc99 = loc("/model.4/m.0/cv1/act/Mul_output_0_Mul/model.4/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc100 = loc("/model.4/m.0/cv1/act/Mul_output_0_Mul/model.4/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc101 = loc("/model.4/m.0/cv1/act/Mul_output_0_Mul")
#loc102 = loc("load_/model.4/Split_output_1_Split")
#loc103 = loc("load_/model.4/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc104 = loc("load_/model.4/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc105 = loc("load_/model.4/m.0/cv1/act/Mul_output_0_Mul/model.4/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc106 = loc("load_/model.4/m.0/cv1/act/Mul_output_0_Mul/model.4/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc107 = loc("/model.4/m.0/cv1/conv/Conv_output_0_Conv")
#loc108 = loc("/model.4/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc109 = loc("/model.4/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc110 = loc("/model.4/m.0/cv2/act/Mul_output_0_Mul/model.4/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc111 = loc("/model.4/m.0/cv2/act/Mul_output_0_Mul/model.4/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc112 = loc("/model.4/m.0/cv2/act/Mul_output_0_Mul")
#loc113 = loc("load_/model.4/m.0/cv1/act/Mul_output_0_Mul")
#loc114 = loc("load_/model.4/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc115 = loc("load_/model.4/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc116 = loc("load_/model.4/m.0/cv2/act/Mul_output_0_Mul/model.4/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc117 = loc("load_/model.4/m.0/cv2/act/Mul_output_0_Mul/model.4/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc118 = loc("/model.4/m.0/cv2/conv/Conv_output_0_Conv")
#loc119 = loc("/model.4/m.0/Add_output_0_Add")
#loc120 = loc("/model.4/m.1/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc121 = loc("/model.4/m.1/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc122 = loc("/model.4/m.1/cv1/act/Mul_output_0_Mul/model.4/m.1/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc123 = loc("/model.4/m.1/cv1/act/Mul_output_0_Mul/model.4/m.1/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc124 = loc("/model.4/m.1/cv1/act/Mul_output_0_Mul")
#loc125 = loc("load_/model.4/m.0/Add_output_0_Add")
#loc126 = loc("load_/model.4/m.1/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc127 = loc("load_/model.4/m.1/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc128 = loc("load_/model.4/m.1/cv1/act/Mul_output_0_Mul/model.4/m.1/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc129 = loc("load_/model.4/m.1/cv1/act/Mul_output_0_Mul/model.4/m.1/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc130 = loc("/model.4/m.1/cv1/conv/Conv_output_0_Conv")
#loc131 = loc("/model.4/m.1/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc132 = loc("/model.4/m.1/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc133 = loc("/model.4/m.1/cv2/act/Mul_output_0_Mul/model.4/m.1/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc134 = loc("/model.4/m.1/cv2/act/Mul_output_0_Mul/model.4/m.1/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc135 = loc("/model.4/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc136 = loc("/model.4/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc137 = loc("/model.4/cv2/act/Mul_output_0_Mul/model.4/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc138 = loc("/model.4/cv2/act/Mul_output_0_Mul/model.4/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc139 = loc("/model.4/cv2/act/Mul_output_0_Mul")
#loc140 = loc("load_/model.4/m.1/cv1/act/Mul_output_0_Mul")
#loc141 = loc("load_/model.4/m.1/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc142 = loc("load_/model.4/m.1/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc143 = loc("load_/model.4/m.1/cv2/act/Mul_output_0_Mul/model.4/m.1/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc144 = loc("load_/model.4/m.1/cv2/act/Mul_output_0_Mul/model.4/m.1/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc145 = loc("/model.4/m.1/cv2/conv/Conv_output_0_Conv")
#loc146 = loc("/model.4/m.1/cv2/act/Mul_output_0_Mul")
#loc147 = loc("load_/model.4/Split_output_0_Split")
#loc148 = loc("/model.4/m.1/Add_output_0_Add")
#loc149 = loc("load_/model.4/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc150 = loc("load_/model.4/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc151 = loc("/model.4/Concat_output_0_Concat")
#loc152 = loc("load_/model.4/cv2/act/Mul_output_0_Mul/model.4/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc153 = loc("load_/model.4/cv2/act/Mul_output_0_Mul/model.4/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc154 = loc("/model.4/cv2/conv/Conv_output_0_Conv")
#loc155 = loc("/model.5/conv/Conv_output_0_Conv_filter_reordered")
#loc156 = loc("/model.5/conv/Conv_output_0_Conv_bias_reordered")
#loc157 = loc("/model.5/conv/Conv_output_0_Conv")
#loc158 = loc("/model.5/act/Mul_output_0_Mul/model.5/act/Mul_output_0_Mul_slope_table_bf16")
#loc159 = loc("/model.5/act/Mul_output_0_Mul/model.5/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc160 = loc("/model.5/act/Mul_output_0_Mul")
#loc161 = loc("/model.6/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc162 = loc("/model.6/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc163 = loc("/model.6/cv1/conv/Conv_output_0_Conv")
#loc164 = loc("/model.6/cv1/act/Mul_output_0_Mul/model.6/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc165 = loc("/model.6/cv1/act/Mul_output_0_Mul/model.6/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc166 = loc("/model.6/cv1/act/Mul_output_0_Mul")
#loc167 = loc("/model.6/Split_output_0_Split")
#loc168 = loc("/model.6/Split_output_1_Split")
#loc169 = loc("/model.6/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc170 = loc("/model.6/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc171 = loc("/model.6/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc172 = loc("/model.6/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc173 = loc("/model.6/m.0/cv1/act/Mul_output_0_Mul")
#loc174 = loc("load_/model.6/Split_output_1_Split")
#loc175 = loc("load_/model.6/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc176 = loc("load_/model.6/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc177 = loc("load_/model.6/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc178 = loc("load_/model.6/m.0/cv1/act/Mul_output_0_Mul/model.6/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc179 = loc("/model.6/m.0/cv1/conv/Conv_output_0_Conv")
#loc180 = loc("/model.6/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc181 = loc("/model.6/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc182 = loc("/model.6/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc183 = loc("/model.6/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc184 = loc("/model.6/m.0/Add_output_0_Add")
#loc185 = loc("load_/model.6/m.0/cv1/act/Mul_output_0_Mul")
#loc186 = loc("load_/model.6/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc187 = loc("load_/model.6/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc188 = loc("load_/model.6/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc189 = loc("load_/model.6/m.0/cv2/act/Mul_output_0_Mul/model.6/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc190 = loc("/model.6/m.0/cv2/conv/Conv_output_0_Conv")
#loc191 = loc("/model.6/m.0/cv2/act/Mul_output_0_Mul")
#loc192 = loc("/model.6/m.1/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc193 = loc("/model.6/m.1/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc194 = loc("/model.6/m.1/cv1/act/Mul_output_0_Mul/model.6/m.1/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc195 = loc("/model.6/m.1/cv1/act/Mul_output_0_Mul/model.6/m.1/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc196 = loc("/model.6/m.1/cv1/act/Mul_output_0_Mul")
#loc197 = loc("load_/model.6/m.0/Add_output_0_Add")
#loc198 = loc("load_/model.6/m.1/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc199 = loc("load_/model.6/m.1/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc200 = loc("load_/model.6/m.1/cv1/act/Mul_output_0_Mul/model.6/m.1/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc201 = loc("load_/model.6/m.1/cv1/act/Mul_output_0_Mul/model.6/m.1/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc202 = loc("/model.6/m.1/cv1/conv/Conv_output_0_Conv")
#loc203 = loc("/model.6/m.1/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc204 = loc("/model.6/m.1/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc205 = loc("/model.6/m.1/cv2/conv/Conv_output_0_Conv")
#loc206 = loc("/model.6/m.1/cv2/act/Mul_output_0_Mul/model.6/m.1/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc207 = loc("/model.6/m.1/cv2/act/Mul_output_0_Mul/model.6/m.1/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc208 = loc("/model.6/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc209 = loc("/model.6/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc210 = loc("/model.6/cv2/conv/Conv_output_0_Conv")
#loc211 = loc("load_/model.6/m.1/cv2/conv/Conv_output_0_Conv")
#loc212 = loc("load_/model.6/m.1/cv2/act/Mul_output_0_Mul/model.6/m.1/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc213 = loc("load_/model.6/m.1/cv2/act/Mul_output_0_Mul/model.6/m.1/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc214 = loc("/model.6/m.1/cv2/act/Mul_output_0_Mul")
#loc215 = loc("load_/model.6/Split_output_0_Split")
#loc216 = loc("/model.6/m.1/Add_output_0_Add")
#loc217 = loc("load_/model.6/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc218 = loc("load_/model.6/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc219 = loc("/model.6/Concat_output_0_Concat")
#loc220 = loc("/model.6/cv2/act/Mul_output_0_Mul/model.6/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc221 = loc("/model.6/cv2/act/Mul_output_0_Mul/model.6/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc222 = loc("/model.6/cv2/act/Mul_output_0_Mul")
#loc223 = loc("/model.7/conv/Conv_output_0_Conv_filter_reordered")
#loc224 = loc("/model.7/conv/Conv_output_0_Conv_bias_reordered")
#loc225 = loc("/model.7/conv/Conv_output_0_Conv")
#loc226 = loc("/model.7/act/Mul_output_0_Mul/model.7/act/Mul_output_0_Mul_slope_table_bf16")
#loc227 = loc("/model.7/act/Mul_output_0_Mul/model.7/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc228 = loc("/model.7/act/Mul_output_0_Mul")
#loc229 = loc("/model.8/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc230 = loc("/model.8/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc231 = loc("/model.8/cv1/conv/Conv_output_0_Conv")
#loc232 = loc("/model.8/cv1/act/Mul_output_0_Mul/model.8/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc233 = loc("/model.8/cv1/act/Mul_output_0_Mul/model.8/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc234 = loc("/model.8/cv1/act/Mul_output_0_Mul")
#loc235 = loc("/model.8/Split_output_0_Split")
#loc236 = loc("/model.8/Split_output_1_Split")
#loc237 = loc("/model.8/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc238 = loc("/model.8/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc239 = loc("/model.8/m.0/cv1/conv/Conv_output_0_Conv")
#loc240 = loc("/model.8/m.0/cv1/act/Mul_output_0_Mul/model.8/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc241 = loc("/model.8/m.0/cv1/act/Mul_output_0_Mul/model.8/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc242 = loc("/model.8/m.0/cv1/act/Mul_output_0_Mul")
#loc243 = loc("/model.8/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc244 = loc("/model.8/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc245 = loc("/model.8/m.0/cv2/conv/Conv_output_0_Conv")
#loc246 = loc("/model.8/m.0/cv2/act/Mul_output_0_Mul/model.8/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc247 = loc("/model.8/m.0/cv2/act/Mul_output_0_Mul/model.8/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc248 = loc("/model.8/m.0/cv2/act/Mul_output_0_Mul")
#loc249 = loc("/model.8/m.0/Add_output_0_Add")
#loc250 = loc("/model.8/Concat_output_0_Concat")
#loc251 = loc("/model.8/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc252 = loc("/model.8/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc253 = loc("/model.8/cv2/conv/Conv_output_0_Conv")
#loc254 = loc("/model.8/cv2/act/Mul_output_0_Mul/model.8/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc255 = loc("/model.8/cv2/act/Mul_output_0_Mul/model.8/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc256 = loc("/model.8/cv2/act/Mul_output_0_Mul")
#loc257 = loc("/model.9/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc258 = loc("/model.9/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc259 = loc("/model.9/cv1/act/Mul_output_0_Mul/model.9/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc260 = loc("/model.9/cv1/act/Mul_output_0_Mul/model.9/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc261 = loc("/model.9/cv1/act/Mul_output_0_Mul")
#loc262 = loc("/model.9/m/MaxPool_output_0_MaxPool")
#loc263 = loc("/model.9/m_1/MaxPool_output_0_MaxPool")
#loc264 = loc("/model.9/m_2/MaxPool_output_0_MaxPool")
#loc265 = loc("load_/model.8/cv2/act/Mul_output_0_Mul")
#loc266 = loc("load_/model.9/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc267 = loc("load_/model.9/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc268 = loc("load_/model.9/cv1/act/Mul_output_0_Mul/model.9/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc269 = loc("load_/model.9/cv1/act/Mul_output_0_Mul/model.9/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc270 = loc("/model.9/cv1/conv/Conv_output_0_Conv")
#loc271 = loc("/model.9/Concat_output_0_Concat")
#loc272 = loc("/model.9/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc273 = loc("/model.9/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc274 = loc("/model.9/cv2/conv/Conv_output_0_Conv")
#loc275 = loc("/model.9/cv2/act/Mul_output_0_Mul/model.9/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc276 = loc("/model.9/cv2/act/Mul_output_0_Mul/model.9/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc277 = loc("/model.9/cv2/act/Mul_output_0_Mul")
#loc278 = loc("/model.10/Resize_output_0_Resize_filter_reordered")
#loc279 = loc("/model.10/Resize_output_0_Resize")
#loc280 = loc("/model.11/Concat_output_0_Concat")
#loc281 = loc("/model.12/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc282 = loc("/model.12/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc283 = loc("/model.12/cv1/conv/Conv_output_0_Conv")
#loc284 = loc("/model.12/cv1/act/Mul_output_0_Mul/model.12/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc285 = loc("/model.12/cv1/act/Mul_output_0_Mul/model.12/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc286 = loc("/model.12/cv1/act/Mul_output_0_Mul")
#loc287 = loc("/model.12/Split_output_0_Split")
#loc288 = loc("/model.12/Split_output_1_Split")
#loc289 = loc("/model.12/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc290 = loc("/model.12/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc291 = loc("/model.12/m.0/cv1/act/Mul_output_0_Mul/model.12/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc292 = loc("/model.12/m.0/cv1/act/Mul_output_0_Mul/model.12/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc293 = loc("/model.12/m.0/cv1/act/Mul_output_0_Mul")
#loc294 = loc("load_/model.12/Split_output_1_Split")
#loc295 = loc("load_/model.12/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc296 = loc("load_/model.12/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc297 = loc("load_/model.12/m.0/cv1/act/Mul_output_0_Mul/model.12/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc298 = loc("load_/model.12/m.0/cv1/act/Mul_output_0_Mul/model.12/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc299 = loc("/model.12/m.0/cv1/conv/Conv_output_0_Conv")
#loc300 = loc("/model.12/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc301 = loc("/model.12/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc302 = loc("/model.12/m.0/cv2/conv/Conv_output_0_Conv")
#loc303 = loc("/model.12/m.0/cv2/act/Mul_output_0_Mul/model.12/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc304 = loc("/model.12/m.0/cv2/act/Mul_output_0_Mul/model.12/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc305 = loc("/model.12/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc306 = loc("/model.12/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc307 = loc("/model.12/cv2/act/Mul_output_0_Mul/model.12/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc308 = loc("/model.12/cv2/act/Mul_output_0_Mul/model.12/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc309 = loc("/model.12/cv2/act/Mul_output_0_Mul")
#loc310 = loc("load_/model.12/m.0/cv2/conv/Conv_output_0_Conv")
#loc311 = loc("load_/model.12/m.0/cv2/act/Mul_output_0_Mul/model.12/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc312 = loc("load_/model.12/m.0/cv2/act/Mul_output_0_Mul/model.12/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc313 = loc("load_/model.12/Split_output_0_Split")
#loc314 = loc("/model.12/m.0/cv2/act/Mul_output_0_Mul")
#loc315 = loc("load_/model.12/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc316 = loc("load_/model.12/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc317 = loc("/model.12/Concat_output_0_Concat")
#loc318 = loc("load_/model.12/cv2/act/Mul_output_0_Mul/model.12/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc319 = loc("load_/model.12/cv2/act/Mul_output_0_Mul/model.12/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc320 = loc("/model.12/cv2/conv/Conv_output_0_Conv")
#loc321 = loc("/model.13/Resize_output_0_Resize_filter_reordered")
#loc322 = loc("/model.13/Resize_output_0_Resize")
#loc323 = loc("/model.14/Concat_output_0_Concat")
#loc324 = loc("/model.15/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc325 = loc("/model.15/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc326 = loc("/model.15/cv1/act/Mul_output_0_Mul/model.15/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc327 = loc("/model.15/cv1/act/Mul_output_0_Mul/model.15/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc328 = loc("/model.15/cv1/act/Mul_output_0_Mul")
#loc329 = loc("load_/model.14/Concat_output_0_Concat")
#loc330 = loc("load_/model.15/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc331 = loc("load_/model.15/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc332 = loc("load_/model.15/cv1/act/Mul_output_0_Mul/model.15/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc333 = loc("load_/model.15/cv1/act/Mul_output_0_Mul/model.15/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc334 = loc("/model.15/cv1/conv/Conv_output_0_Conv")
#loc335 = loc("/model.15/Split_output_0_Split")
#loc336 = loc("/model.15/Split_output_1_Split")
#loc337 = loc("/model.15/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc338 = loc("/model.15/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc339 = loc("/model.15/m.0/cv1/act/Mul_output_0_Mul/model.15/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc340 = loc("/model.15/m.0/cv1/act/Mul_output_0_Mul/model.15/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc341 = loc("/model.15/m.0/cv1/act/Mul_output_0_Mul")
#loc342 = loc("load_/model.15/Split_output_1_Split")
#loc343 = loc("load_/model.15/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc344 = loc("load_/model.15/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc345 = loc("load_/model.15/m.0/cv1/act/Mul_output_0_Mul/model.15/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc346 = loc("load_/model.15/m.0/cv1/act/Mul_output_0_Mul/model.15/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc347 = loc("/model.15/m.0/cv1/conv/Conv_output_0_Conv")
#loc348 = loc("/model.15/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc349 = loc("/model.15/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc350 = loc("/model.15/m.0/cv2/act/Mul_output_0_Mul/model.15/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc351 = loc("/model.15/m.0/cv2/act/Mul_output_0_Mul/model.15/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc352 = loc("/model.15/m.0/cv2/act/Mul_output_0_Mul")
#loc353 = loc("load_/model.15/m.0/cv1/act/Mul_output_0_Mul")
#loc354 = loc("load_/model.15/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc355 = loc("load_/model.15/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc356 = loc("load_/model.15/m.0/cv2/act/Mul_output_0_Mul/model.15/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc357 = loc("load_/model.15/m.0/cv2/act/Mul_output_0_Mul/model.15/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc358 = loc("/model.15/m.0/cv2/conv/Conv_output_0_Conv")
#loc359 = loc("/model.15/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc360 = loc("/model.15/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc361 = loc("/model.15/cv2/act/Mul_output_0_Mul/model.15/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc362 = loc("/model.15/cv2/act/Mul_output_0_Mul/model.15/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc363 = loc("/model.15/cv2/act/Mul_output_0_Mul")
#loc364 = loc("load_/model.15/Split_output_0_Split")
#loc365 = loc("load_/model.15/m.0/cv2/act/Mul_output_0_Mul")
#loc366 = loc("load_/model.15/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc367 = loc("load_/model.15/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc368 = loc("/model.15/Concat_output_0_Concat")
#loc369 = loc("load_/model.15/cv2/act/Mul_output_0_Mul/model.15/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc370 = loc("load_/model.15/cv2/act/Mul_output_0_Mul/model.15/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc371 = loc("/model.15/cv2/conv/Conv_output_0_Conv")
#loc372 = loc("/model.16/conv/Conv_output_0_Conv_filter_reordered")
#loc373 = loc("/model.16/conv/Conv_output_0_Conv_bias_reordered")
#loc374 = loc("/model.16/conv/Conv_output_0_Conv")
#loc375 = loc("/model.22/cv2.0/cv2.0.0/conv/Conv_output_0_Conv_filter_reordered")
#loc376 = loc("/model.22/cv2.0/cv2.0.0/conv/Conv_output_0_Conv_bias_reordered")
#loc377 = loc("/model.22/cv2.0/cv2.0.0/conv/Conv_output_0_Conv")
#loc378 = loc("/model.22/cv3.0/cv3.0.0/conv/Conv_output_0_Conv_filter_reordered")
#loc379 = loc("/model.22/cv3.0/cv3.0.0/conv/Conv_output_0_Conv_bias_reordered")
#loc380 = loc("/model.16/act/Mul_output_0_Mul/model.16/act/Mul_output_0_Mul_slope_table_bf16")
#loc381 = loc("/model.16/act/Mul_output_0_Mul/model.16/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc382 = loc("/model.22/cv2.0/cv2.0.0/act/Mul_output_0_Mul/model.22/cv2.0/cv2.0.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc383 = loc("/model.22/cv2.0/cv2.0.0/act/Mul_output_0_Mul/model.22/cv2.0/cv2.0.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc384 = loc("/model.22/cv3.0/cv3.0.0/act/Mul_output_0_Mul/model.22/cv3.0/cv3.0.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc385 = loc("/model.22/cv3.0/cv3.0.0/act/Mul_output_0_Mul/model.22/cv3.0/cv3.0.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc386 = loc("/model.16/act/Mul_output_0_Mul")
#loc387 = loc("/model.22/cv2.0/cv2.0.0/act/Mul_output_0_Mul")
#loc388 = loc("/model.22/cv3.0/cv3.0.0/act/Mul_output_0_Mul")
#loc389 = loc("load_/model.15/cv2/act/Mul_output_0_Mul")
#loc390 = loc("load_/model.22/cv3.0/cv3.0.0/conv/Conv_output_0_Conv_filter_reordered")
#loc391 = loc("load_/model.22/cv3.0/cv3.0.0/conv/Conv_output_0_Conv_bias_reordered")
#loc392 = loc("load_/model.16/conv/Conv_output_0_Conv")
#loc393 = loc("load_/model.16/act/Mul_output_0_Mul/model.16/act/Mul_output_0_Mul_slope_table_bf16")
#loc394 = loc("load_/model.16/act/Mul_output_0_Mul/model.16/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc395 = loc("/model.22/cv3.0/cv3.0.0/conv/Conv_output_0_Conv")
#loc396 = loc("load_/model.22/cv2.0/cv2.0.0/conv/Conv_output_0_Conv")
#loc397 = loc("load_/model.22/cv2.0/cv2.0.0/act/Mul_output_0_Mul/model.22/cv2.0/cv2.0.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc398 = loc("load_/model.22/cv2.0/cv2.0.0/act/Mul_output_0_Mul/model.22/cv2.0/cv2.0.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc399 = loc("load_/model.22/cv3.0/cv3.0.0/act/Mul_output_0_Mul/model.22/cv3.0/cv3.0.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc400 = loc("load_/model.22/cv3.0/cv3.0.0/act/Mul_output_0_Mul/model.22/cv3.0/cv3.0.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc401 = loc("/model.17/Concat_output_0_Concat")
#loc402 = loc("/model.22/cv2.0/cv2.0.1/conv/Conv_output_0_Conv_filter_reordered")
#loc403 = loc("/model.22/cv2.0/cv2.0.1/conv/Conv_output_0_Conv_bias_reordered")
#loc404 = loc("/model.22/cv3.0/cv3.0.1/conv/Conv_output_0_Conv_filter_reordered")
#loc405 = loc("/model.22/cv3.0/cv3.0.1/conv/Conv_output_0_Conv_bias_reordered")
#loc406 = loc("/model.22/cv2.0/cv2.0.1/conv/Conv_output_0_Conv")
#loc407 = loc("/model.22/cv3.0/cv3.0.1/conv/Conv_output_0_Conv")
#loc408 = loc("load_/model.22/cv2.0/cv2.0.0/act/Mul_output_0_Mul")
#loc409 = loc("load_/model.22/cv2.0/cv2.0.1/conv/Conv_output_0_Conv_filter_reordered")
#loc410 = loc("load_/model.22/cv2.0/cv2.0.1/conv/Conv_output_0_Conv_bias_reordered")
#loc411 = loc("load_/model.22/cv3.0/cv3.0.0/act/Mul_output_0_Mul")
#loc412 = loc("load_/model.22/cv3.0/cv3.0.1/conv/Conv_output_0_Conv_filter_reordered")
#loc413 = loc("load_/model.22/cv3.0/cv3.0.1/conv/Conv_output_0_Conv_bias_reordered")
#loc414 = loc("/model.18/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc415 = loc("/model.18/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc416 = loc("/model.18/cv1/conv/Conv_output_0_Conv")
#loc417 = loc("/model.22/cv2.0/cv2.0.1/act/Mul_output_0_Mul/model.22/cv2.0/cv2.0.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc418 = loc("/model.22/cv2.0/cv2.0.1/act/Mul_output_0_Mul/model.22/cv2.0/cv2.0.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc419 = loc("/model.22/cv3.0/cv3.0.1/act/Mul_output_0_Mul/model.22/cv3.0/cv3.0.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc420 = loc("/model.22/cv3.0/cv3.0.1/act/Mul_output_0_Mul/model.22/cv3.0/cv3.0.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc421 = loc("/model.18/cv1/act/Mul_output_0_Mul/model.18/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc422 = loc("/model.18/cv1/act/Mul_output_0_Mul/model.18/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc423 = loc("/model.22/cv2.0/cv2.0.1/act/Mul_output_0_Mul")
#loc424 = loc("/model.22/cv3.0/cv3.0.1/act/Mul_output_0_Mul")
#loc425 = loc("/model.18/cv1/act/Mul_output_0_Mul")
#loc426 = loc("load_/model.22/cv2.0/cv2.0.1/conv/Conv_output_0_Conv")
#loc427 = loc("load_/model.22/cv2.0/cv2.0.1/act/Mul_output_0_Mul/model.22/cv2.0/cv2.0.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc428 = loc("load_/model.22/cv2.0/cv2.0.1/act/Mul_output_0_Mul/model.22/cv2.0/cv2.0.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc429 = loc("load_/model.22/cv3.0/cv3.0.1/conv/Conv_output_0_Conv")
#loc430 = loc("load_/model.22/cv3.0/cv3.0.1/act/Mul_output_0_Mul/model.22/cv3.0/cv3.0.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc431 = loc("load_/model.22/cv3.0/cv3.0.1/act/Mul_output_0_Mul/model.22/cv3.0/cv3.0.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc432 = loc("load_/model.18/cv1/conv/Conv_output_0_Conv")
#loc433 = loc("load_/model.18/cv1/act/Mul_output_0_Mul/model.18/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc434 = loc("load_/model.18/cv1/act/Mul_output_0_Mul/model.18/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc435 = loc("/model.22/cv2.0/cv2.0.2/Conv_output_0_Conv_filter_reordered")
#loc436 = loc("/model.22/cv2.0/cv2.0.2/Conv_output_0_Conv_bias_reordered")
#loc437 = loc("/model.22/cv3.0/cv3.0.2/Conv_output_0_Conv_filter_reordered")
#loc438 = loc("/model.22/cv3.0/cv3.0.2/Conv_output_0_Conv_bias_reordered")
#loc439 = loc("/model.22/cv2.0/cv2.0.2/Conv_output_0_Conv")
#loc440 = loc("/model.22/cv3.0/cv3.0.2/Conv_output_0_Conv")
#loc441 = loc("load_/model.22/cv2.0/cv2.0.1/act/Mul_output_0_Mul")
#loc442 = loc("load_/model.22/cv2.0/cv2.0.2/Conv_output_0_Conv_filter_reordered")
#loc443 = loc("load_/model.22/cv2.0/cv2.0.2/Conv_output_0_Conv_bias_reordered")
#loc444 = loc("load_/model.22/cv3.0/cv3.0.1/act/Mul_output_0_Mul")
#loc445 = loc("load_/model.22/cv3.0/cv3.0.2/Conv_output_0_Conv_filter_reordered")
#loc446 = loc("load_/model.22/cv3.0/cv3.0.2/Conv_output_0_Conv_bias_reordered")
#loc447 = loc("/model.18/Split_output_0_Split")
#loc448 = loc("/model.18/Split_output_1_Split")
#loc449 = loc("/model.22/Concat_output_0_Concat")
#loc450 = loc("/model.18/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc451 = loc("/model.18/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc452 = loc("/model.18/m.0/cv1/conv/Conv_output_0_Conv")
#loc453 = loc("/model.22/Reshape_output_0_Reshape")
#loc454 = loc("/model.18/m.0/cv1/act/Mul_output_0_Mul/model.18/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc455 = loc("/model.18/m.0/cv1/act/Mul_output_0_Mul/model.18/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc456 = loc("/model.18/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc457 = loc("/model.18/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc458 = loc("/model.18/m.0/cv2/conv/Conv_output_0_Conv")
#loc459 = loc("load_/model.18/m.0/cv1/conv/Conv_output_0_Conv")
#loc460 = loc("load_/model.18/m.0/cv1/act/Mul_output_0_Mul/model.18/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc461 = loc("load_/model.18/m.0/cv1/act/Mul_output_0_Mul/model.18/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc462 = loc("load_/model.18/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc463 = loc("load_/model.18/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc464 = loc("/model.18/m.0/cv1/act/Mul_output_0_Mul")
#loc465 = loc("/model.18/m.0/cv2/act/Mul_output_0_Mul/model.18/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc466 = loc("/model.18/m.0/cv2/act/Mul_output_0_Mul/model.18/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc467 = loc("/model.18/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc468 = loc("/model.18/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc469 = loc("/model.18/cv2/act/Mul_output_0_Mul/model.18/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc470 = loc("/model.18/cv2/act/Mul_output_0_Mul/model.18/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc471 = loc("/model.18/cv2/act/Mul_output_0_Mul")
#loc472 = loc("load_/model.18/m.0/cv2/conv/Conv_output_0_Conv")
#loc473 = loc("load_/model.18/m.0/cv2/act/Mul_output_0_Mul/model.18/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc474 = loc("load_/model.18/m.0/cv2/act/Mul_output_0_Mul/model.18/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc475 = loc("load_/model.18/Split_output_0_Split")
#loc476 = loc("load_/model.18/Split_output_1_Split")
#loc477 = loc("/model.18/m.0/cv2/act/Mul_output_0_Mul")
#loc478 = loc("load_/model.18/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc479 = loc("load_/model.18/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc480 = loc("/model.18/Concat_output_0_Concat")
#loc481 = loc("load_/model.18/cv2/act/Mul_output_0_Mul/model.18/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc482 = loc("load_/model.18/cv2/act/Mul_output_0_Mul/model.18/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc483 = loc("/model.18/cv2/conv/Conv_output_0_Conv")
#loc484 = loc("/model.19/conv/Conv_output_0_Conv_filter_reordered")
#loc485 = loc("/model.19/conv/Conv_output_0_Conv_bias_reordered")
#loc486 = loc("/model.19/conv/Conv_output_0_Conv")
#loc487 = loc("/model.22/cv2.1/cv2.1.0/conv/Conv_output_0_Conv_filter_reordered")
#loc488 = loc("/model.22/cv2.1/cv2.1.0/conv/Conv_output_0_Conv_bias_reordered")
#loc489 = loc("/model.22/cv2.1/cv2.1.0/conv/Conv_output_0_Conv")
#loc490 = loc("/model.22/cv3.1/cv3.1.0/conv/Conv_output_0_Conv_filter_reordered")
#loc491 = loc("/model.22/cv3.1/cv3.1.0/conv/Conv_output_0_Conv_bias_reordered")
#loc492 = loc("/model.22/cv3.1/cv3.1.0/conv/Conv_output_0_Conv")
#loc493 = loc("/model.19/act/Mul_output_0_Mul/model.19/act/Mul_output_0_Mul_slope_table_bf16")
#loc494 = loc("/model.19/act/Mul_output_0_Mul/model.19/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc495 = loc("/model.19/act/Mul_output_0_Mul")
#loc496 = loc("/model.22/cv2.1/cv2.1.0/act/Mul_output_0_Mul/model.22/cv2.1/cv2.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc497 = loc("/model.22/cv2.1/cv2.1.0/act/Mul_output_0_Mul/model.22/cv2.1/cv2.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc498 = loc("/model.22/cv3.1/cv3.1.0/act/Mul_output_0_Mul/model.22/cv3.1/cv3.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc499 = loc("/model.22/cv3.1/cv3.1.0/act/Mul_output_0_Mul/model.22/cv3.1/cv3.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc500 = loc("/model.22/cv2.1/cv2.1.0/act/Mul_output_0_Mul")
#loc501 = loc("/model.22/cv3.1/cv3.1.0/act/Mul_output_0_Mul")
#loc502 = loc("load_/model.22/cv2.1/cv2.1.0/conv/Conv_output_0_Conv")
#loc503 = loc("load_/model.22/cv2.1/cv2.1.0/act/Mul_output_0_Mul/model.22/cv2.1/cv2.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc504 = loc("load_/model.22/cv2.1/cv2.1.0/act/Mul_output_0_Mul/model.22/cv2.1/cv2.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc505 = loc("load_/model.22/cv3.1/cv3.1.0/conv/Conv_output_0_Conv")
#loc506 = loc("load_/model.22/cv3.1/cv3.1.0/act/Mul_output_0_Mul/model.22/cv3.1/cv3.1.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc507 = loc("load_/model.22/cv3.1/cv3.1.0/act/Mul_output_0_Mul/model.22/cv3.1/cv3.1.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc508 = loc("/model.20/Concat_output_0_Concat")
#loc509 = loc("/model.22/cv2.1/cv2.1.1/conv/Conv_output_0_Conv_filter_reordered")
#loc510 = loc("/model.22/cv2.1/cv2.1.1/conv/Conv_output_0_Conv_bias_reordered")
#loc511 = loc("/model.22/cv3.1/cv3.1.1/conv/Conv_output_0_Conv_filter_reordered")
#loc512 = loc("/model.22/cv3.1/cv3.1.1/conv/Conv_output_0_Conv_bias_reordered")
#loc513 = loc("/model.22/cv2.1/cv2.1.1/conv/Conv_output_0_Conv")
#loc514 = loc("/model.22/cv3.1/cv3.1.1/conv/Conv_output_0_Conv")
#loc515 = loc("load_/model.22/cv2.1/cv2.1.0/act/Mul_output_0_Mul")
#loc516 = loc("load_/model.22/cv2.1/cv2.1.1/conv/Conv_output_0_Conv_filter_reordered")
#loc517 = loc("load_/model.22/cv2.1/cv2.1.1/conv/Conv_output_0_Conv_bias_reordered")
#loc518 = loc("load_/model.22/cv3.1/cv3.1.0/act/Mul_output_0_Mul")
#loc519 = loc("load_/model.22/cv3.1/cv3.1.1/conv/Conv_output_0_Conv_filter_reordered")
#loc520 = loc("load_/model.22/cv3.1/cv3.1.1/conv/Conv_output_0_Conv_bias_reordered")
#loc521 = loc("/model.21/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc522 = loc("/model.21/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc523 = loc("/model.21/cv1/conv/Conv_output_0_Conv")
#loc524 = loc("/model.22/cv2.1/cv2.1.1/act/Mul_output_0_Mul/model.22/cv2.1/cv2.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc525 = loc("/model.22/cv2.1/cv2.1.1/act/Mul_output_0_Mul/model.22/cv2.1/cv2.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc526 = loc("/model.22/cv3.1/cv3.1.1/act/Mul_output_0_Mul/model.22/cv3.1/cv3.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc527 = loc("/model.22/cv3.1/cv3.1.1/act/Mul_output_0_Mul/model.22/cv3.1/cv3.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc528 = loc("/model.22/cv2.1/cv2.1.1/act/Mul_output_0_Mul")
#loc529 = loc("/model.22/cv3.1/cv3.1.1/act/Mul_output_0_Mul")
#loc530 = loc("load_/model.22/cv2.1/cv2.1.1/conv/Conv_output_0_Conv")
#loc531 = loc("load_/model.22/cv2.1/cv2.1.1/act/Mul_output_0_Mul/model.22/cv2.1/cv2.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc532 = loc("load_/model.22/cv2.1/cv2.1.1/act/Mul_output_0_Mul/model.22/cv2.1/cv2.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc533 = loc("load_/model.22/cv3.1/cv3.1.1/conv/Conv_output_0_Conv")
#loc534 = loc("load_/model.22/cv3.1/cv3.1.1/act/Mul_output_0_Mul/model.22/cv3.1/cv3.1.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc535 = loc("load_/model.22/cv3.1/cv3.1.1/act/Mul_output_0_Mul/model.22/cv3.1/cv3.1.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc536 = loc("/model.21/cv1/act/Mul_output_0_Mul/model.21/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc537 = loc("/model.21/cv1/act/Mul_output_0_Mul/model.21/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc538 = loc("/model.21/cv1/act/Mul_output_0_Mul")
#loc539 = loc("/model.22/cv2.1/cv2.1.2/Conv_output_0_Conv_filter_reordered")
#loc540 = loc("/model.22/cv2.1/cv2.1.2/Conv_output_0_Conv_bias_reordered")
#loc541 = loc("/model.22/cv3.1/cv3.1.2/Conv_output_0_Conv_filter_reordered")
#loc542 = loc("/model.22/cv3.1/cv3.1.2/Conv_output_0_Conv_bias_reordered")
#loc543 = loc("/model.22/cv2.1/cv2.1.2/Conv_output_0_Conv")
#loc544 = loc("/model.22/cv3.1/cv3.1.2/Conv_output_0_Conv")
#loc545 = loc("load_/model.22/cv2.1/cv2.1.1/act/Mul_output_0_Mul")
#loc546 = loc("load_/model.22/cv2.1/cv2.1.2/Conv_output_0_Conv_filter_reordered")
#loc547 = loc("load_/model.22/cv2.1/cv2.1.2/Conv_output_0_Conv_bias_reordered")
#loc548 = loc("load_/model.22/cv3.1/cv3.1.1/act/Mul_output_0_Mul")
#loc549 = loc("load_/model.22/cv3.1/cv3.1.2/Conv_output_0_Conv_filter_reordered")
#loc550 = loc("load_/model.22/cv3.1/cv3.1.2/Conv_output_0_Conv_bias_reordered")
#loc551 = loc("/model.21/Split_output_0_Split")
#loc552 = loc("/model.21/Split_output_1_Split")
#loc553 = loc("/model.22/Concat_1_output_0_Concat")
#loc554 = loc("/model.21/m.0/cv1/conv/Conv_output_0_Conv_filter_reordered")
#loc555 = loc("/model.21/m.0/cv1/conv/Conv_output_0_Conv_bias_reordered")
#loc556 = loc("/model.21/m.0/cv1/conv/Conv_output_0_Conv")
#loc557 = loc("/model.22/Reshape_1_output_0_Reshape")
#loc558 = loc("/model.21/m.0/cv1/act/Mul_output_0_Mul/model.21/m.0/cv1/act/Mul_output_0_Mul_slope_table_bf16")
#loc559 = loc("/model.21/m.0/cv1/act/Mul_output_0_Mul/model.21/m.0/cv1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc560 = loc("/model.21/m.0/cv1/act/Mul_output_0_Mul")
#loc561 = loc("/model.21/m.0/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc562 = loc("/model.21/m.0/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc563 = loc("/model.21/m.0/cv2/conv/Conv_output_0_Conv")
#loc564 = loc("/model.21/m.0/cv2/act/Mul_output_0_Mul/model.21/m.0/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc565 = loc("/model.21/m.0/cv2/act/Mul_output_0_Mul/model.21/m.0/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc566 = loc("/model.21/m.0/cv2/act/Mul_output_0_Mul")
#loc567 = loc("/model.21/Concat_output_0_Concat")
#loc568 = loc("/model.21/cv2/conv/Conv_output_0_Conv_filter_reordered")
#loc569 = loc("/model.21/cv2/conv/Conv_output_0_Conv_bias_reordered")
#loc570 = loc("/model.21/cv2/conv/Conv_output_0_Conv")
#loc571 = loc("/model.21/cv2/act/Mul_output_0_Mul/model.21/cv2/act/Mul_output_0_Mul_slope_table_bf16")
#loc572 = loc("/model.21/cv2/act/Mul_output_0_Mul/model.21/cv2/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc573 = loc("/model.21/cv2/act/Mul_output_0_Mul")
#loc574 = loc("/model.22/cv2.2/cv2.2.0/conv/Conv_output_0_Conv_filter_reordered")
#loc575 = loc("/model.22/cv2.2/cv2.2.0/conv/Conv_output_0_Conv_bias_reordered")
#loc576 = loc("/model.22/cv2.2/cv2.2.0/conv/Conv_output_0_Conv")
#loc577 = loc("/model.22/cv3.2/cv3.2.0/conv/Conv_output_0_Conv_filter_reordered")
#loc578 = loc("/model.22/cv3.2/cv3.2.0/conv/Conv_output_0_Conv_bias_reordered")
#loc579 = loc("/model.22/cv3.2/cv3.2.0/conv/Conv_output_0_Conv")
#loc580 = loc("/model.22/cv2.2/cv2.2.0/act/Mul_output_0_Mul/model.22/cv2.2/cv2.2.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc581 = loc("/model.22/cv2.2/cv2.2.0/act/Mul_output_0_Mul/model.22/cv2.2/cv2.2.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc582 = loc("/model.22/cv2.2/cv2.2.0/act/Mul_output_0_Mul")
#loc583 = loc("/model.22/cv3.2/cv3.2.0/act/Mul_output_0_Mul/model.22/cv3.2/cv3.2.0/act/Mul_output_0_Mul_slope_table_bf16")
#loc584 = loc("/model.22/cv3.2/cv3.2.0/act/Mul_output_0_Mul/model.22/cv3.2/cv3.2.0/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc585 = loc("/model.22/cv3.2/cv3.2.0/act/Mul_output_0_Mul")
#loc586 = loc("/model.22/cv2.2/cv2.2.1/conv/Conv_output_0_Conv_filter_reordered")
#loc587 = loc("/model.22/cv2.2/cv2.2.1/conv/Conv_output_0_Conv_bias_reordered")
#loc588 = loc("/model.22/cv3.2/cv3.2.1/conv/Conv_output_0_Conv_filter_reordered")
#loc589 = loc("/model.22/cv3.2/cv3.2.1/conv/Conv_output_0_Conv_bias_reordered")
#loc590 = loc("/model.22/cv2.2/cv2.2.1/conv/Conv_output_0_Conv")
#loc591 = loc("/model.22/cv3.2/cv3.2.1/conv/Conv_output_0_Conv")
#loc592 = loc("load_/model.22/cv2.2/cv2.2.0/act/Mul_output_0_Mul")
#loc593 = loc("load_/model.22/cv2.2/cv2.2.1/conv/Conv_output_0_Conv_filter_reordered")
#loc594 = loc("load_/model.22/cv2.2/cv2.2.1/conv/Conv_output_0_Conv_bias_reordered")
#loc595 = loc("load_/model.22/cv3.2/cv3.2.0/act/Mul_output_0_Mul")
#loc596 = loc("load_/model.22/cv3.2/cv3.2.1/conv/Conv_output_0_Conv_filter_reordered")
#loc597 = loc("load_/model.22/cv3.2/cv3.2.1/conv/Conv_output_0_Conv_bias_reordered")
#loc598 = loc("/model.22/cv2.2/cv2.2.1/act/Mul_output_0_Mul/model.22/cv2.2/cv2.2.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc599 = loc("/model.22/cv2.2/cv2.2.1/act/Mul_output_0_Mul/model.22/cv2.2/cv2.2.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc600 = loc("/model.22/cv2.2/cv2.2.1/act/Mul_output_0_Mul")
#loc601 = loc("/model.22/cv3.2/cv3.2.1/act/Mul_output_0_Mul/model.22/cv3.2/cv3.2.1/act/Mul_output_0_Mul_slope_table_bf16")
#loc602 = loc("/model.22/cv3.2/cv3.2.1/act/Mul_output_0_Mul/model.22/cv3.2/cv3.2.1/act/Mul_output_0_Mul_slope_slope_table_bf16")
#loc603 = loc("/model.22/cv3.2/cv3.2.1/act/Mul_output_0_Mul")
#loc604 = loc("/model.22/cv2.2/cv2.2.2/Conv_output_0_Conv_filter_reordered")
#loc605 = loc("/model.22/cv2.2/cv2.2.2/Conv_output_0_Conv_bias_reordered")
#loc606 = loc("/model.22/cv3.2/cv3.2.2/Conv_output_0_Conv_filter_reordered")
#loc607 = loc("/model.22/cv3.2/cv3.2.2/Conv_output_0_Conv_bias_reordered")
#loc608 = loc("/model.22/cv2.2/cv2.2.2/Conv_output_0_Conv")
#loc609 = loc("/model.22/cv3.2/cv3.2.2/Conv_output_0_Conv")
#loc610 = loc("load_/model.22/cv2.2/cv2.2.1/act/Mul_output_0_Mul")
#loc611 = loc("load_/model.22/cv2.2/cv2.2.2/Conv_output_0_Conv_filter_reordered")
#loc612 = loc("load_/model.22/cv2.2/cv2.2.2/Conv_output_0_Conv_bias_reordered")
#loc613 = loc("load_/model.22/cv3.2/cv3.2.1/act/Mul_output_0_Mul")
#loc614 = loc("load_/model.22/cv3.2/cv3.2.2/Conv_output_0_Conv_filter_reordered")
#loc615 = loc("load_/model.22/cv3.2/cv3.2.2/Conv_output_0_Conv_bias_reordered")
#loc616 = loc("/model.22/Concat_2_output_0_Concat")
#loc617 = loc("/model.22/Reshape_2_output_0_Reshape")
#loc618 = loc("/model.22/Concat_3_output_0_Concat")
#loc619 = loc("/model.22/Split_output_0_Split")
#loc620 = loc("/model.22/Split_output_1_Split")
#loc621 = loc("/model.22/dfl/Reshape_output_0_Reshape")
#loc622 = loc("/model.22/Sigmoid_output_0_Sigmoid/model.22/Sigmoid_output_0_Sigmoid_slope_table_bf16")
#loc623 = loc("/model.22/Sigmoid_output_0_Sigmoid/model.22/Sigmoid_output_0_Sigmoid_slope_slope_table_bf16")
#loc624 = loc("/model.22/Sigmoid_output_0_Sigmoid")
#loc625 = loc("/model.22/dfl/Softmax_output_0_Softmax/model.22/dfl/Softmax_output_0_Softmax_slope_table_bf16")
#loc626 = loc("/model.22/dfl/Softmax_output_0_Softmax/model.22/dfl/Softmax_output_0_Softmax_slope_slope_table_bf16")
#loc627 = loc("/model.22/dfl/Softmax_output_0_Softmax/model.22/dfl/Softmax_output_0_Softmax_pow_table_bf16")
#loc628 = loc("/model.22/dfl/Softmax_output_0_Softmax/model.22/dfl/Softmax_output_0_Softmax_pow_mantissa_table_bf16")
#loc629 = loc("/model.22/dfl/Softmax_output_0_Softmax_/model.22/dfl/Transpose_output_0_Transpose")
#loc630 = loc("/model.22/dfl/Transpose_output_0_Transpose_/model.22/dfl/Softmax_output_0_Softmax")
#loc631 = loc("/model.22/dfl/conv/Conv_output_0_Conv_filter_reordered")
#loc632 = loc("/model.22/dfl/conv/Conv_output_0_Conv")
#loc633 = loc("/model.22/Sigmoid_output_0_Sigmoid_f32")
#loc634 = loc("/model.22/dfl/conv/Conv_output_0_Conv_f32")
#loc635 = loc(fused[#loc261, #loc262, #loc263, #loc264])
#loc636 = loc(fused[#loc386, #loc387, #loc388])
#loc637 = loc(fused[#loc406, #loc407])
#loc638 = loc(fused[#loc423, #loc424, #loc425])
#loc639 = loc(fused[#loc439, #loc440])
#loc640 = loc(fused[#loc500, #loc501])
#loc641 = loc(fused[#loc513, #loc514])
#loc642 = loc(fused[#loc528, #loc529])
#loc643 = loc(fused[#loc543, #loc544])
#loc644 = loc(fused[#loc590, #loc591])
#loc645 = loc(fused[#loc608, #loc609])

